import {
  FlowGraphCoordinator
} from "./chunk-66E4XH6O.js";
import {
  FlowGraphEventBlock
} from "./chunk-IP2DQ76V.js";
import {
  FlowGraphExecutionBlock
} from "./chunk-Y46XVAPS.js";
import {
  RichType,
  defaultValueParseFunction,
  getRichTypeByFlowGraphType,
  needsPathConverter
} from "./chunk-ET3Y5ZV4.js";
import {
  Bone
} from "./chunk-CRKUXQ7L.js";
import {
  _SpatialAudioAttacherComponent,
  _SpatialWebAudioUpdaterComponent
} from "./chunk-AZMWNXZR.js";
import {
  AbstractAudioNode,
  _WebAudioParameterComponent
} from "./chunk-GA37H3AK.js";
import {
  _UpdateRGBDAsync
} from "./chunk-GPOCEXB4.js";
import {
  DecodeMesh,
  DecoderWorkerFunction,
  DracoCodec,
  MorphTarget,
  RawTexture,
  Scalar,
  TargetCamera,
  _IsConfigurationAvailable
} from "./chunk-JHEX2SWQ.js";
import {
  Animation,
  AnimationRange
} from "./chunk-TSMTS3RY.js";
import {
  ToHalfFloat
} from "./chunk-PMTD2I4J.js";
import {
  Geometry,
  Mesh,
  StandardMaterial,
  VertexData,
  createYieldingScheduler,
  runCoroutineAsync,
  runCoroutineSync
} from "./chunk-JPDS7OIY.js";
import {
  IntersectionInfo,
  MaterialDefines,
  PushMaterial,
  SubMesh
} from "./chunk-43CLNRDT.js";
import {
  Camera,
  EventConstants,
  KeyboardEventTypes,
  PickingInfo,
  Scene,
  SceneComponentConstants,
  _ImportHelper
} from "./chunk-VEFBIZWV.js";
import {
  Light,
  ShadowLight
} from "./chunk-DILINRTI.js";
import {
  PointerEventTypes
} from "./chunk-VJOELCDK.js";
import {
  AddClipPlaneUniforms,
  BindClipPlane,
  BindFogParameters,
  BindLogDepth,
  PrepareAttributesForInstances,
  PrepareDefinesForAttributes,
  PrepareDefinesForFrameBoundValues,
  PrepareDefinesForMisc,
  PrepareUniformsAndSamplersList
} from "./chunk-UCQRX3RS.js";
import {
  Node
} from "./chunk-5L7L3C5R.js";
import {
  SmartArray
} from "./chunk-A4D5JG2T.js";
import {
  BaseTexture,
  Texture
} from "./chunk-RLP7VL7I.js";
import {
  SerializationHelper
} from "./chunk-KEOAMMZ7.js";
import {
  __decorate,
  serialize,
  serializeAsColor3,
  serializeAsMatrix,
  serializeAsVector3
} from "./chunk-URVCX2UN.js";
import {
  Color3,
  Color4
} from "./chunk-5HS37WJT.js";
import {
  Matrix,
  Quaternion,
  TmpVectors,
  Vector2,
  Vector3,
  Vector4
} from "./chunk-H4PB4IWT.js";
import {
  BuildArray,
  Epsilon
} from "./chunk-JKI5MLKH.js";
import {
  VertexBuffer
} from "./chunk-LAFJMI44.js";
import {
  DeepCopier,
  Tools
} from "./chunk-V4HVSPHY.js";
import {
  Decode
} from "./chunk-XHCADOMZ.js";
import {
  GetClass,
  RegisterClass
} from "./chunk-S7NDMBDF.js";
import {
  AbstractEngine,
  _RetryWithInterval
} from "./chunk-5OVANEI2.js";
import {
  _WarnImport
} from "./chunk-OWCZTH5B.js";
import {
  PrecisionDate
} from "./chunk-AZNEH5GV.js";
import {
  EngineStore
} from "./chunk-WWEEGZBW.js";
import {
  Observable
} from "./chunk-2YUEJ7I2.js";
import {
  Logger
} from "./chunk-J4DZ2XK7.js";
import {
  RandomRange
} from "./chunk-QCCD6NMF.js";

// node_modules/@babylonjs/core/Animations/animationEvent.js
var AnimationEvent = class _AnimationEvent {
  /**
   * Initializes the animation event
   * @param frame The frame for which the event is triggered
   * @param action The event to perform when triggered
   * @param onlyOnce Specifies if the event should be triggered only once
   */
  constructor(frame, action, onlyOnce) {
    this.frame = frame;
    this.action = action;
    this.onlyOnce = onlyOnce;
    this.isDone = false;
  }
  /** @internal */
  _clone() {
    return new _AnimationEvent(this.frame, this.action, this.onlyOnce);
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/audioEngineV2.js
var Instances = [];
function LastCreatedAudioEngine() {
  if (Instances.length === 0) {
    return null;
  }
  return Instances[Instances.length - 1];
}
var AudioEngineV2 = class {
  constructor(options) {
    this._mainBuses = /* @__PURE__ */ new Set();
    this._nodes = /* @__PURE__ */ new Set();
    this._defaultMainBus = null;
    this._parameterRampDuration = 0.01;
    Instances.push(this);
    if (typeof options.parameterRampDuration === "number") {
      this.parameterRampDuration = options.parameterRampDuration;
    }
  }
  /**
   * The default main bus that will be used for audio buses and sounds if their `outBus` option is not set.
   * @see {@link IAudioBusOptions.outBus}
   * @see {@link IAbstractSoundOptions.outBus}
   */
  get defaultMainBus() {
    if (this._mainBuses.size === 0) {
      return null;
    }
    if (!this._defaultMainBus) {
      this._defaultMainBus = Array.from(this._mainBuses)[0];
    }
    return this._defaultMainBus;
  }
  /**
   * The smoothing duration to use when changing audio parameters, in seconds. Defaults to `0.01` (10 milliseconds).
   *
   * Due to limitations in some browsers, it is not recommended to set this value to longer than `0.01` seconds.
   *
   * Setting this value to longer than `0.01` seconds may result in errors being throw when setting audio parameters.
   */
  get parameterRampDuration() {
    return this._parameterRampDuration;
  }
  set parameterRampDuration(value) {
    this._parameterRampDuration = Math.max(0, value);
  }
  /**
   * Releases associated resources.
   */
  dispose() {
    if (Instances.includes(this)) {
      Instances.splice(Instances.indexOf(this), 1);
    }
    const nodeIt = this._nodes.values();
    for (let next = nodeIt.next(); !next.done; next = nodeIt.next()) {
      next.value.dispose();
    }
    this._mainBuses.clear();
    this._nodes.clear();
    this._defaultMainBus = null;
  }
  /**
   * Unlocks the audio engine if it is locked.
   * - Note that the returned promise may already be resolved if the audio engine is already unlocked.
   * @returns A promise that is resolved when the audio engine is unlocked.
   */
  // eslint-disable-next-line @typescript-eslint/promise-function-async, no-restricted-syntax
  unlockAsync() {
    return this.resumeAsync();
  }
  _addMainBus(mainBus) {
    this._mainBuses.add(mainBus);
    this._addNode(mainBus);
  }
  _removeMainBus(mainBus) {
    this._mainBuses.delete(mainBus);
    this._defaultMainBus = null;
    this._removeNode(mainBus);
  }
  _addNode(node) {
    this._nodes.add(node);
  }
  _removeNode(node) {
    this._nodes.delete(node);
  }
};
function _GetAudioEngine(engine) {
  if (!engine) {
    engine = LastCreatedAudioEngine();
  }
  if (engine) {
    return engine;
  }
  throw new Error("No audio engine.");
}
function CreateAudioBusAsync(name, options = {}, engine = null) {
  engine = _GetAudioEngine(engine);
  return engine.createBusAsync(name, options);
}
function CreateMainAudioBusAsync(name, options = {}, engine = null) {
  engine = _GetAudioEngine(engine);
  return engine.createMainBusAsync(name, options);
}
function CreateMicrophoneSoundSourceAsync(name, options = {}, engine = null) {
  engine = _GetAudioEngine(engine);
  return engine.createMicrophoneSoundSourceAsync(name, options);
}
function CreateSoundAsync(name, source, options = {}, engine = null) {
  engine = _GetAudioEngine(engine);
  return engine.createSoundAsync(name, source, options);
}
async function CreateSoundBufferAsync(source, options = {}, engine = null) {
  engine = _GetAudioEngine(engine);
  return await engine.createSoundBufferAsync(source, options);
}
function CreateSoundSourceAsync(name, source, options = {}, engine = null) {
  engine = _GetAudioEngine(engine);
  return engine.createSoundSourceAsync(name, source, options);
}
function CreateStreamingSoundAsync(name, source, options = {}, engine = null) {
  engine = _GetAudioEngine(engine);
  return engine.createStreamingSoundAsync(name, source, options);
}

// node_modules/@babylonjs/core/AudioV2/abstractAudio/subProperties/abstractSpatialAudioListener.js
var _SpatialAudioListenerDefaults = {
  position: Vector3.Zero(),
  rotation: Vector3.Zero(),
  rotationQuaternion: new Quaternion()
};
function _HasSpatialAudioListenerOptions(options) {
  return options.listenerEnabled || options.listenerMinUpdateTime !== void 0 || options.listenerPosition !== void 0 || options.listenerRotation !== void 0 || options.listenerRotationQuaternion !== void 0;
}
var AbstractSpatialAudioListener = class {
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/subProperties/spatialAudioListener.js
var _SpatialAudioListener = class extends AbstractSpatialAudioListener {
  constructor() {
    super();
    this._attacherComponent = null;
    this._attacherComponent = new _SpatialAudioAttacherComponent(this);
  }
  /** @internal */
  get isAttached() {
    return this._attacherComponent !== null && this._attacherComponent.isAttached;
  }
  /**
   * Attaches to a scene node.
   *
   * Detaches automatically before attaching to the given scene node.
   * If `sceneNode` is `null` it is the same as calling `detach()`.
   *
   * @param sceneNode The scene node to attach to, or `null` to detach.
   * @param useBoundingBox Whether to use the bounding box of the node for positioning. Defaults to `false`.
   * @param attachmentType Whether to attach to the node's position and/or rotation. Defaults to `PositionAndRotation`.
   */
  attach(sceneNode, useBoundingBox = false, attachmentType = 3) {
    if (!this._attacherComponent) {
      this._attacherComponent = new _SpatialAudioAttacherComponent(this);
    }
    this._attacherComponent.attach(sceneNode, useBoundingBox, attachmentType);
  }
  /**
   * Detaches from the scene node if attached.
   */
  detach() {
    this._attacherComponent?.detach();
  }
  /** @internal */
  dispose() {
    this._attacherComponent?.dispose();
    this._attacherComponent = null;
  }
  /** @internal */
  setOptions(options) {
    if (options.listenerMinUpdateTime !== void 0) {
      this.minUpdateTime = options.listenerMinUpdateTime;
    }
    if (options.listenerPosition) {
      this.position = options.listenerPosition.clone();
    }
    if (options.listenerRotationQuaternion) {
      this.rotationQuaternion = options.listenerRotationQuaternion.clone();
    } else if (options.listenerRotation) {
      this.rotation = options.listenerRotation.clone();
    } else {
      this.rotationQuaternion = _SpatialAudioListenerDefaults.rotationQuaternion.clone();
    }
    this.update();
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/subProperties/spatialWebAudioListener.js
var TmpMatrix = Matrix.Zero();
var TmpQuaternion = new Quaternion();
var TmpVector1 = Vector3.Zero();
var TmpVector2 = Vector3.Zero();
function _CreateSpatialAudioListener(engine, autoUpdate, minUpdateTime) {
  const listener = engine._audioContext.listener;
  if (listener.forwardX && listener.forwardY && listener.forwardZ && listener.positionX && listener.positionY && listener.positionZ && listener.upX && listener.upY && listener.upZ) {
    return new _SpatialWebAudioListener(engine, autoUpdate, minUpdateTime);
  } else {
    return new _SpatialWebAudioListenerFallback(engine, autoUpdate, minUpdateTime);
  }
}
var _AbstractSpatialWebAudioListener = class extends _SpatialAudioListener {
  /** @internal */
  constructor(engine, autoUpdate, minUpdateTime) {
    super();
    this._lastPosition = Vector3.Zero();
    this._lastRotation = Vector3.Zero();
    this._lastRotationQuaternion = new Quaternion();
    this.position = Vector3.Zero();
    this.rotation = Vector3.Zero();
    this.rotationQuaternion = new Quaternion();
    this._listener = engine._audioContext.listener;
    this.engine = engine;
    this._updaterComponent = new _SpatialWebAudioUpdaterComponent(this, autoUpdate, minUpdateTime);
  }
  /** @internal */
  dispose() {
    super.dispose();
    this._updaterComponent.dispose();
    this._updaterComponent = null;
  }
  /** @internal */
  get minUpdateTime() {
    return this._updaterComponent.minUpdateTime;
  }
  /** @internal */
  set minUpdateTime(value) {
    this._updaterComponent.minUpdateTime = value;
  }
  /** @internal */
  update() {
    if (this.isAttached) {
      this._attacherComponent?.update();
    } else {
      this._updatePosition();
      this._updateRotation();
    }
  }
  _updatePosition() {
    if (this._lastPosition.equalsWithEpsilon(this.position)) {
      return;
    }
    this._setWebAudioPosition(this.position);
    this._lastPosition.copyFrom(this.position);
  }
  _updateRotation() {
    if (!this._lastRotationQuaternion.equalsWithEpsilon(this.rotationQuaternion)) {
      TmpQuaternion.copyFrom(this.rotationQuaternion);
      this._lastRotationQuaternion.copyFrom(this.rotationQuaternion);
    } else if (!this._lastRotation.equalsWithEpsilon(this.rotation)) {
      Quaternion.FromEulerAnglesToRef(this.rotation.x, this.rotation.y, this.rotation.z, TmpQuaternion);
      this._lastRotation.copyFrom(this.rotation);
    } else {
      return;
    }
    Matrix.FromQuaternionToRef(TmpQuaternion, TmpMatrix);
    Vector3.TransformNormalToRef(Vector3.RightHandedForwardReadOnly, TmpMatrix, TmpVector1);
    Vector3.TransformNormalToRef(Vector3.Up(), TmpMatrix, TmpVector2);
    this._setWebAudioOrientation(TmpVector1, TmpVector2);
  }
};
var _SpatialWebAudioListener = class extends _AbstractSpatialWebAudioListener {
  constructor(engine, autoUpdate, minUpdateTime) {
    super(engine, autoUpdate, minUpdateTime);
    const listener = engine._audioContext.listener;
    this._forwardX = new _WebAudioParameterComponent(engine, listener.forwardX);
    this._forwardY = new _WebAudioParameterComponent(engine, listener.forwardY);
    this._forwardZ = new _WebAudioParameterComponent(engine, listener.forwardZ);
    this._positionX = new _WebAudioParameterComponent(engine, listener.positionX);
    this._positionY = new _WebAudioParameterComponent(engine, listener.positionY);
    this._positionZ = new _WebAudioParameterComponent(engine, listener.positionZ);
    this._upX = new _WebAudioParameterComponent(engine, listener.upX);
    this._upY = new _WebAudioParameterComponent(engine, listener.upY);
    this._upZ = new _WebAudioParameterComponent(engine, listener.upZ);
  }
  _setWebAudioPosition(position) {
    if (this.isAttached && (this._positionX.isRamping || this._positionY.isRamping || this._positionZ.isRamping)) {
      return;
    }
    this._positionX.targetValue = position.x;
    this._positionY.targetValue = position.y;
    this._positionZ.targetValue = position.z;
  }
  _setWebAudioOrientation(forward, up) {
    if (this.isAttached && (this._forwardX.isRamping || this._forwardY.isRamping || this._forwardZ.isRamping || this._upX.isRamping || this._upY.isRamping || this._upZ.isRamping)) {
      return;
    }
    this._forwardX.targetValue = forward.x;
    this._forwardY.targetValue = forward.y;
    this._forwardZ.targetValue = forward.z;
    this._upX.targetValue = up.x;
    this._upY.targetValue = up.y;
    this._upZ.targetValue = up.z;
  }
};
var _SpatialWebAudioListenerFallback = class extends _AbstractSpatialWebAudioListener {
  _setWebAudioPosition(position) {
    this._listener.setPosition(position.x, position.y, position.z);
  }
  _setWebAudioOrientation(forward, up) {
    this._listener.setOrientation(forward.x, forward.y, forward.z, up.x, up.y, up.z);
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/mainAudioOut.js
var _MainAudioOut = class extends AbstractAudioNode {
  constructor(engine) {
    super(
      engine,
      1
      /* AudioNodeType.HAS_INPUTS */
    );
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/webAudioMainOut.js
var _WebAudioMainOut = class extends _MainAudioOut {
  /** @internal */
  constructor(engine) {
    super(engine);
    this._setGainNode(new GainNode(engine._audioContext));
  }
  /** @internal */
  dispose() {
    super.dispose();
    this._volume.dispose();
    this._gainNode.disconnect();
    this._destinationNode.disconnect();
  }
  /** @internal */
  get _inNode() {
    return this._gainNode;
  }
  set _inNode(value) {
    if (this._gainNode === value) {
      return;
    }
    this._setGainNode(value);
  }
  /** @internal */
  get volume() {
    return this._volume.targetValue;
  }
  /** @internal */
  set volume(value) {
    this._volume.targetValue = value;
  }
  get _destinationNode() {
    return this.engine._audioDestination;
  }
  /** @internal */
  getClassName() {
    return "_WebAudioMainOut";
  }
  /** @internal */
  setVolume(value, options = null) {
    this._volume.setTargetValue(value, options);
  }
  _setGainNode(gainNode) {
    if (this._gainNode === gainNode) {
      return;
    }
    this._gainNode?.disconnect();
    gainNode.connect(this._destinationNode);
    this._volume = new _WebAudioParameterComponent(this.engine, gainNode.gain);
    this._gainNode = gainNode;
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/webAudioUnmuteUI.js
var _WebAudioUnmuteUI = class {
  /** @internal */
  constructor(engine, parentElement) {
    this._button = null;
    this._enabled = true;
    this._style = null;
    this._onStateChanged = () => {
      if (!this._button) {
        return;
      }
      if (this._engine.state === "running") {
        this._hide();
      } else {
        this._show();
      }
    };
    this._engine = engine;
    const parent = parentElement || EngineStore.LastCreatedEngine?.getInputElement()?.parentElement || document.body;
    const top = (parent?.offsetTop || 0) + 20;
    this._style = document.createElement("style");
    this._style.appendChild(document.createTextNode(`.babylonUnmute{position:absolute;top:${top}px;margin-left:20px;height:40px;width:60px;background-color:rgba(51,51,51,0.7);background-image:url("data:image/svg+xml;charset=UTF-8,%3Csvg%20version%3D%221.1%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2239%22%20height%3D%2232%22%20viewBox%3D%220%200%2039%2032%22%3E%3Cpath%20fill%3D%22white%22%20d%3D%22M9.625%2018.938l-0.031%200.016h-4.953q-0.016%200-0.031-0.016v-12.453q0-0.016%200.031-0.016h4.953q0.031%200%200.031%200.016v12.453zM12.125%207.688l8.719-8.703v27.453l-8.719-8.719-0.016-0.047v-9.938zM23.359%207.875l1.406-1.406%204.219%204.203%204.203-4.203%201.422%201.406-4.219%204.219%204.219%204.203-1.484%201.359-4.141-4.156-4.219%204.219-1.406-1.422%204.219-4.203z%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E");background-size:80%;background-repeat:no-repeat;background-position:center;background-position-y:4px;border:none;outline:none;transition:transform 0.125s ease-out;cursor:pointer;z-index:9999;}.babylonUnmute:hover{transform:scale(1.05)}`));
    document.head.appendChild(this._style);
    this._button = document.createElement("button");
    this._button.className = "babylonUnmute";
    this._button.id = "babylonUnmuteButton";
    this._button.addEventListener("click", () => {
      this._engine.unlockAsync();
    });
    parent.appendChild(this._button);
    this._engine.stateChangedObservable.add(this._onStateChanged);
  }
  /** @internal */
  dispose() {
    this._button?.remove();
    this._button = null;
    this._style?.remove();
    this._style = null;
    this._engine.stateChangedObservable.removeCallback(this._onStateChanged);
  }
  /** @internal */
  get enabled() {
    return this._enabled;
  }
  set enabled(value) {
    this._enabled = value;
    if (value) {
      if (this._engine.state !== "running") {
        this._show();
      }
    } else {
      this._hide();
    }
  }
  _show() {
    if (!this._button) {
      return;
    }
    this._button.style.display = "block";
  }
  _hide() {
    if (!this._button) {
      return;
    }
    this._button.style.display = "none";
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/webAudioEngine.js
async function CreateAudioEngineAsync(options = {}) {
  const engine = new _WebAudioEngine(options);
  await engine._initAsync(options);
  return engine;
}
var FormatMimeTypes = {
  aac: "audio/aac",
  ac3: "audio/ac3",
  flac: "audio/flac",
  m4a: "audio/mp4",
  mp3: 'audio/mpeg; codecs="mp3"',
  mp4: "audio/mp4",
  ogg: 'audio/ogg; codecs="vorbis"',
  wav: "audio/wav",
  webm: 'audio/webm; codecs="vorbis"'
};
var _WebAudioEngine = class extends AudioEngineV2 {
  /** @internal */
  constructor(options = {}) {
    super(options);
    this._audioContextStarted = false;
    this._destinationNode = null;
    this._invalidFormats = /* @__PURE__ */ new Set();
    this._isUpdating = false;
    this._listener = null;
    this._listenerAutoUpdate = true;
    this._listenerMinUpdateTime = 0;
    this._pauseCalled = false;
    this._resumeOnInteraction = true;
    this._resumeOnPause = true;
    this._resumeOnPauseRetryInterval = 1e3;
    this._resumeOnPauseTimerId = null;
    this._resumePromise = null;
    this._silentHtmlAudio = null;
    this._unmuteUI = null;
    this._updateObservable = null;
    this._validFormats = /* @__PURE__ */ new Set();
    this._volume = 1;
    this._isUsingOfflineAudioContext = false;
    this.isReadyPromise = new Promise((resolve) => {
      this._resolveIsReadyPromise = resolve;
    });
    this.stateChangedObservable = new Observable();
    this.userGestureObservable = new Observable();
    this._initAudioContextAsync = async () => {
      this._audioContext.addEventListener("statechange", this._onAudioContextStateChange);
      this._mainOut = new _WebAudioMainOut(this);
      this._mainOut.volume = this._volume;
      await this.createMainBusAsync("default");
    };
    this._onAudioContextStateChange = () => {
      if (this.state === "running") {
        clearInterval(this._resumeOnPauseTimerId);
        this._audioContextStarted = true;
        this._resumePromise = null;
      }
      if (this.state === "suspended" || this.state === "interrupted") {
        if (this._audioContextStarted && this._resumeOnPause && !this._pauseCalled) {
          clearInterval(this._resumeOnPauseTimerId);
          this._resumeOnPauseTimerId = setInterval(() => {
            this.resumeAsync();
          }, this._resumeOnPauseRetryInterval);
        }
      }
      this.stateChangedObservable.notifyObservers(this.state);
    };
    this._onUserGestureAsync = async () => {
      if (this._resumeOnInteraction) {
        await this._audioContext.resume();
      }
      if (!this._silentHtmlAudio) {
        this._silentHtmlAudio = document.createElement("audio");
        const audio = this._silentHtmlAudio;
        audio.controls = false;
        audio.preload = "auto";
        audio.loop = true;
        audio.src = "data:audio/wav;base64,UklGRjAAAABXQVZFZm10IBAAAAABAAEAgLsAAAB3AQACABAAZGF0YQwAAAAAAAEA/v8CAP//AQA=";
        audio.play();
      }
      this.userGestureObservable.notifyObservers();
    };
    this._startUpdating = () => {
      if (this._isUpdating) {
        return;
      }
      this._isUpdating = true;
      if (this.state === "running") {
        this._update();
      } else {
        const callback = () => {
          if (this.state === "running") {
            this._update();
            this.stateChangedObservable.removeCallback(callback);
          }
        };
        this.stateChangedObservable.add(callback);
      }
    };
    this._update = () => {
      if (this._updateObservable?.hasObservers()) {
        this._updateObservable.notifyObservers();
        requestAnimationFrame(this._update);
      } else {
        this._isUpdating = false;
      }
    };
    if (typeof options.listenerAutoUpdate === "boolean") {
      this._listenerAutoUpdate = options.listenerAutoUpdate;
    }
    if (typeof options.listenerMinUpdateTime === "number") {
      this._listenerMinUpdateTime = options.listenerMinUpdateTime;
    }
    this._volume = options.volume ?? 1;
    if (options.audioContext) {
      this._isUsingOfflineAudioContext = options.audioContext instanceof OfflineAudioContext;
      this._audioContext = options.audioContext;
    } else {
      this._audioContext = new AudioContext();
    }
    if (!options.disableDefaultUI) {
      this._unmuteUI = new _WebAudioUnmuteUI(this, options.defaultUIParentElement);
    }
  }
  /** @internal */
  async _initAsync(options) {
    this._resumeOnInteraction = typeof options.resumeOnInteraction === "boolean" ? options.resumeOnInteraction : true;
    this._resumeOnPause = typeof options.resumeOnPause === "boolean" ? options.resumeOnPause : true;
    this._resumeOnPauseRetryInterval = options.resumeOnPauseRetryInterval ?? 1e3;
    document.addEventListener("click", this._onUserGestureAsync);
    await this._initAudioContextAsync();
    if (_HasSpatialAudioListenerOptions(options)) {
      this._listener = _CreateSpatialAudioListener(this, this._listenerAutoUpdate, this._listenerMinUpdateTime);
      this._listener.setOptions(options);
    }
    this._resolveIsReadyPromise();
  }
  /** @internal */
  get currentTime() {
    return this._audioContext.currentTime ?? 0;
  }
  /** @internal */
  get _inNode() {
    return this._audioContext.destination;
  }
  /** @internal */
  get mainOut() {
    return this._mainOut;
  }
  /** @internal */
  get listener() {
    return this._listener ?? (this._listener = _CreateSpatialAudioListener(this, this._listenerAutoUpdate, this._listenerMinUpdateTime));
  }
  /** @internal */
  get state() {
    return this._isUsingOfflineAudioContext ? "running" : this._audioContext.state;
  }
  /** @internal */
  get volume() {
    return this._volume;
  }
  /** @internal */
  set volume(value) {
    if (this._volume === value) {
      return;
    }
    this._volume = value;
    if (this._mainOut) {
      this._mainOut.volume = value;
    }
  }
  /**
   * This property should only be used by the legacy audio engine.
   * @internal
   * */
  get _audioDestination() {
    return this._destinationNode ? this._destinationNode : this._destinationNode = this._audioContext.destination;
  }
  set _audioDestination(value) {
    this._destinationNode = value;
  }
  /**
   * This property should only be used by the legacy audio engine.
   * @internal
   */
  get _unmuteUIEnabled() {
    return this._unmuteUI ? this._unmuteUI.enabled : false;
  }
  set _unmuteUIEnabled(value) {
    if (this._unmuteUI) {
      this._unmuteUI.enabled = value;
    }
  }
  /** @internal */
  async createBusAsync(name, options = {}) {
    const module = await import("./webAudioBus-3P4E3FBF.js");
    const bus = new module._WebAudioBus(name, this, options);
    await bus._initAsync(options);
    return bus;
  }
  /** @internal */
  async createMainBusAsync(name, options = {}) {
    const module = await import("./webAudioMainBus-QRC2QZYT.js");
    const bus = new module._WebAudioMainBus(name, this);
    await bus._initAsync(options);
    return bus;
  }
  /** @internal */
  async createMicrophoneSoundSourceAsync(name, options) {
    let mediaStream;
    try {
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    } catch (e) {
      throw new Error("Unable to access microphone: " + e);
    }
    return await this.createSoundSourceAsync(name, new MediaStreamAudioSourceNode(this._audioContext, { mediaStream }), {
      outBusAutoDefault: false,
      ...options
    });
  }
  /** @internal */
  async createSoundAsync(name, source, options = {}) {
    const module = await import("./webAudioStaticSound-4ESR4XKQ.js");
    const sound = new module._WebAudioStaticSound(name, this, options);
    await sound._initAsync(source, options);
    return sound;
  }
  /** @internal */
  async createSoundBufferAsync(source, options = {}) {
    const module = await import("./webAudioStaticSound-4ESR4XKQ.js");
    const soundBuffer = new module._WebAudioStaticSoundBuffer(this);
    await soundBuffer._initAsync(source, options);
    return soundBuffer;
  }
  /** @internal */
  async createSoundSourceAsync(name, source, options = {}) {
    const module = await import("./webAudioSoundSource-SPBZGMDL.js");
    const soundSource = new module._WebAudioSoundSource(name, source, this, options);
    await soundSource._initAsync(options);
    return soundSource;
  }
  /** @internal */
  async createStreamingSoundAsync(name, source, options = {}) {
    const module = await import("./webAudioStreamingSound-WR52ERTB.js");
    const sound = new module._WebAudioStreamingSound(name, this, options);
    await sound._initAsync(source, options);
    return sound;
  }
  /** @internal */
  dispose() {
    super.dispose();
    this._listener?.dispose();
    this._listener = null;
    if (this._audioContext.state !== "closed" && !this._isUsingOfflineAudioContext) {
      this._audioContext.close();
    }
    document.removeEventListener("click", this._onUserGestureAsync);
    this._audioContext.removeEventListener("statechange", this._onAudioContextStateChange);
    this._silentHtmlAudio?.remove();
    this._updateObservable?.clear();
    this._updateObservable = null;
    this._unmuteUI?.dispose();
    this._unmuteUI = null;
    this.stateChangedObservable.clear();
  }
  /** @internal */
  flagInvalidFormat(format) {
    this._invalidFormats.add(format);
  }
  /** @internal */
  isFormatValid(format) {
    if (this._validFormats.has(format)) {
      return true;
    }
    if (this._invalidFormats.has(format)) {
      return false;
    }
    const mimeType = FormatMimeTypes[format];
    if (mimeType === void 0) {
      return false;
    }
    const audio = new Audio();
    if (audio.canPlayType(mimeType) === "") {
      this._invalidFormats.add(format);
      return false;
    }
    this._validFormats.add(format);
    return true;
  }
  /** @internal */
  async pauseAsync() {
    await this._audioContext.suspend();
    this._pauseCalled = true;
  }
  /** @internal */
  // eslint-disable-next-line @typescript-eslint/promise-function-async, no-restricted-syntax
  resumeAsync() {
    this._pauseCalled = false;
    if (this._resumePromise) {
      return this._resumePromise;
    }
    this._resumePromise = this._audioContext.resume();
    return this._resumePromise;
  }
  /** @internal */
  setVolume(value, options = null) {
    if (this._mainOut) {
      this._mainOut.setVolume(value, options);
    } else {
      throw new Error("Main output not initialized yet.");
    }
  }
  /** @internal */
  _addMainBus(mainBus) {
    super._addMainBus(mainBus);
  }
  /** @internal */
  _removeMainBus(mainBus) {
    super._removeMainBus(mainBus);
  }
  /** @internal */
  _addNode(node) {
    super._addNode(node);
  }
  /** @internal */
  _removeNode(node) {
    super._removeNode(node);
  }
  /** @internal */
  _addUpdateObserver(callback) {
    if (!this._updateObservable) {
      this._updateObservable = new Observable();
    }
    this._updateObservable.add(callback);
    this._startUpdating();
  }
  _removeUpdateObserver(callback) {
    if (this._updateObservable) {
      this._updateObservable.removeCallback(callback);
    }
  }
};

// node_modules/@babylonjs/core/Audio/audioEngine.js
AbstractEngine.AudioEngineFactory = (hostElement, audioContext, audioDestination) => {
  return new AudioEngine(hostElement, audioContext, audioDestination);
};
var AudioEngine = class {
  /**
   * The master gain node defines the global audio volume of your audio engine.
   */
  get masterGain() {
    return this._masterGain;
  }
  set masterGain(value) {
    this._masterGain = this._v2.mainOut._inNode = value;
  }
  /**
   * Defines if the audio engine relies on a custom unlocked button.
   * In this case, the embedded button will not be displayed.
   */
  get useCustomUnlockedButton() {
    return this._useCustomUnlockedButton;
  }
  set useCustomUnlockedButton(value) {
    this._useCustomUnlockedButton = value;
    this._v2._unmuteUIEnabled = !value;
  }
  /**
   * Gets the current AudioContext if available.
   */
  get audioContext() {
    if (this._v2.state === "running") {
      this._triggerRunningStateAsync();
    }
    return this._v2._audioContext;
  }
  /**
   * Instantiates a new audio engine.
   *
   * @param hostElement defines the host element where to display the mute icon if necessary
   * @param audioContext defines the audio context to be used by the audio engine
   * @param audioDestination defines the audio destination node to be used by audio engine
   */
  constructor(hostElement = null, audioContext = null, audioDestination = null) {
    this._audioContext = null;
    this._tryToRun = false;
    this._useCustomUnlockedButton = false;
    this.canUseWebAudio = true;
    this.WarnedWebAudioUnsupported = false;
    this.isMP3supported = false;
    this.isOGGsupported = false;
    this.unlocked = false;
    this.onAudioUnlockedObservable = new Observable();
    this.onAudioLockedObservable = new Observable();
    const v2 = new _WebAudioEngine({
      audioContext: audioContext ? audioContext : void 0,
      defaultUIParentElement: hostElement?.parentElement ? hostElement.parentElement : void 0
    });
    v2._unmuteUIEnabled = false;
    this._masterGain = new GainNode(v2._audioContext);
    v2._audioDestination = audioDestination;
    v2.stateChangedObservable.add((state) => {
      if (state === "running") {
        this.unlocked = true;
        this.onAudioUnlockedObservable.notifyObservers(this);
      } else {
        this.unlocked = false;
        this.onAudioLockedObservable.notifyObservers(this);
      }
    });
    v2._initAsync({ resumeOnInteraction: false }).then(() => {
      const mainBusOutNode = v2.defaultMainBus._outNode;
      if (mainBusOutNode) {
        mainBusOutNode.disconnect(v2.mainOut._inNode);
        mainBusOutNode.connect(this._masterGain);
      }
      v2.mainOut._inNode = this._masterGain;
      v2.stateChangedObservable.notifyObservers(v2.state);
    });
    this.isMP3supported = v2.isFormatValid("mp3");
    this.isOGGsupported = v2.isFormatValid("ogg");
    this._v2 = v2;
  }
  /**
   * Flags the audio engine in Locked state.
   * This happens due to new browser policies preventing audio to autoplay.
   */
  lock() {
    this._v2._audioContext.suspend();
    if (!this._useCustomUnlockedButton) {
      this._v2._unmuteUIEnabled = true;
    }
  }
  /**
   * Unlocks the audio engine once a user action has been done on the dom.
   * This is helpful to resume play once browser policies have been satisfied.
   */
  unlock() {
    if (this._audioContext?.state === "running") {
      if (!this.unlocked) {
        this.unlocked = true;
        this.onAudioUnlockedObservable.notifyObservers(this);
      }
      return;
    }
    this._triggerRunningStateAsync();
  }
  /** @internal */
  _resumeAudioContextOnStateChange() {
    this._audioContext?.addEventListener("statechange", () => {
      if (this.unlocked && this._audioContext?.state !== "running") {
        this._resumeAudioContextAsync();
      }
    }, {
      once: true,
      passive: true,
      signal: AbortSignal.timeout(3e3)
    });
  }
  // eslint-disable-next-line @typescript-eslint/promise-function-async, no-restricted-syntax
  _resumeAudioContextAsync() {
    if (this._v2._isUsingOfflineAudioContext) {
      return Promise.resolve();
    }
    return this._v2._audioContext.resume();
  }
  /**
   * Destroy and release the resources associated with the audio context.
   */
  dispose() {
    this._v2.dispose();
    this.onAudioUnlockedObservable.clear();
    this.onAudioLockedObservable.clear();
  }
  /**
   * Gets the global volume sets on the master gain.
   * @returns the global volume if set or -1 otherwise
   */
  getGlobalVolume() {
    return this.masterGain.gain.value;
  }
  /**
   * Sets the global volume of your experience (sets on the master gain).
   * @param newVolume Defines the new global volume of the application
   */
  setGlobalVolume(newVolume) {
    this.masterGain.gain.value = newVolume;
  }
  /**
   * Connect the audio engine to an audio analyser allowing some amazing
   * synchronization between the sounds/music and your visualization (VuMeter for instance).
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#using-the-analyser
   * @param analyser The analyser to connect to the engine
   */
  connectToAnalyser(analyser) {
    if (this._connectedAnalyser) {
      this._connectedAnalyser.stopDebugCanvas();
    }
    this._connectedAnalyser = analyser;
    this.masterGain.disconnect();
    this._connectedAnalyser.connectAudioNodes(this.masterGain, this._v2._audioContext.destination);
  }
  async _triggerRunningStateAsync() {
    if (this._tryToRun) {
      return;
    }
    this._tryToRun = true;
    await this._resumeAudioContextAsync();
    this._tryToRun = false;
    this.unlocked = true;
    this.onAudioUnlockedObservable.notifyObservers(this);
  }
};

// node_modules/@babylonjs/core/Audio/sound.js
var Sound = class _Sound {
  /**
   * Does the sound loop after it finishes playing once.
   */
  get loop() {
    return this._loop;
  }
  set loop(value) {
    if (value === this._loop) {
      return;
    }
    this._loop = value;
    this.updateOptions({ loop: value });
  }
  /**
   * Gets the current time for the sound.
   */
  get currentTime() {
    if (this._htmlAudioElement) {
      return this._htmlAudioElement.currentTime;
    }
    if (AbstractEngine.audioEngine?.audioContext && (this.isPlaying || this.isPaused)) {
      const timeSinceLastStart = this.isPaused ? 0 : AbstractEngine.audioEngine.audioContext.currentTime - this._startTime;
      return this._currentTime + timeSinceLastStart;
    }
    return 0;
  }
  /**
   * Does this sound enables spatial sound.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
   */
  get spatialSound() {
    return this._spatialSound;
  }
  /**
   * Does this sound enables spatial sound.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
   */
  set spatialSound(newValue) {
    if (newValue == this._spatialSound) {
      return;
    }
    const wasPlaying = this.isPlaying;
    this.pause();
    if (newValue) {
      this._spatialSound = newValue;
      this._updateSpatialParameters();
    } else {
      this._disableSpatialSound();
    }
    if (wasPlaying) {
      this.play();
    }
  }
  /**
   * Create a sound and attach it to a scene
   * @param name Name of your sound
   * @param urlOrArrayBuffer Url to the sound to load async or ArrayBuffer, it also works with MediaStreams and AudioBuffers
   * @param scene defines the scene the sound belongs to
   * @param readyToPlayCallback Provide a callback function if you'd like to load your code once the sound is ready to be played
   * @param options Objects to provide with the current available options: autoplay, loop, volume, spatialSound, maxDistance, rolloffFactor, refDistance, distanceModel, panningModel, streaming
   */
  constructor(name, urlOrArrayBuffer, scene, readyToPlayCallback = null, options) {
    this.autoplay = false;
    this._loop = false;
    this.useCustomAttenuation = false;
    this.isPlaying = false;
    this.isPaused = false;
    this.refDistance = 1;
    this.rolloffFactor = 1;
    this.maxDistance = 100;
    this.distanceModel = "linear";
    this.metadata = null;
    this.onEndedObservable = new Observable();
    this._spatialSound = false;
    this._panningModel = "equalpower";
    this._playbackRate = 1;
    this._streaming = false;
    this._startTime = 0;
    this._currentTime = 0;
    this._position = Vector3.Zero();
    this._localDirection = new Vector3(1, 0, 0);
    this._volume = 1;
    this._isReadyToPlay = false;
    this._isDirectional = false;
    this._coneInnerAngle = 360;
    this._coneOuterAngle = 360;
    this._coneOuterGain = 0;
    this._isOutputConnected = false;
    this._urlType = "Unknown";
    this.name = name;
    scene = scene || EngineStore.LastCreatedScene;
    if (!scene) {
      return;
    }
    this._scene = scene;
    _Sound._SceneComponentInitialization(scene);
    this._readyToPlayCallback = readyToPlayCallback;
    this._customAttenuationFunction = (currentVolume, currentDistance, maxDistance, refDistance, rolloffFactor) => {
      if (currentDistance < maxDistance) {
        return currentVolume * (1 - currentDistance / maxDistance);
      } else {
        return 0;
      }
    };
    if (options) {
      this.autoplay = options.autoplay || false;
      this._loop = options.loop || false;
      if (options.volume !== void 0) {
        this._volume = options.volume;
      }
      this._spatialSound = options.spatialSound ?? false;
      this.maxDistance = options.maxDistance ?? 100;
      this.useCustomAttenuation = options.useCustomAttenuation ?? false;
      this.rolloffFactor = options.rolloffFactor || 1;
      this.refDistance = options.refDistance || 1;
      this.distanceModel = options.distanceModel || "linear";
      this._playbackRate = options.playbackRate || 1;
      this._streaming = options.streaming ?? false;
      this._length = options.length;
      this._offset = options.offset;
    }
    if (AbstractEngine.audioEngine?.canUseWebAudio && AbstractEngine.audioEngine.audioContext) {
      this._soundGain = AbstractEngine.audioEngine.audioContext.createGain();
      this._soundGain.gain.value = this._volume;
      this._inputAudioNode = this._soundGain;
      this._outputAudioNode = this._soundGain;
      if (this._spatialSound) {
        this._createSpatialParameters();
      }
      this._scene.mainSoundTrack.addSound(this);
      let validParameter = true;
      if (urlOrArrayBuffer) {
        try {
          if (typeof urlOrArrayBuffer === "string") {
            this._urlType = "String";
            this._url = urlOrArrayBuffer;
          } else if (urlOrArrayBuffer instanceof ArrayBuffer) {
            this._urlType = "ArrayBuffer";
          } else if (urlOrArrayBuffer instanceof HTMLMediaElement) {
            this._urlType = "MediaElement";
          } else if (urlOrArrayBuffer instanceof MediaStream) {
            this._urlType = "MediaStream";
          } else if (urlOrArrayBuffer instanceof AudioBuffer) {
            this._urlType = "AudioBuffer";
          } else if (Array.isArray(urlOrArrayBuffer)) {
            this._urlType = "Array";
          }
          let urls = [];
          let codecSupportedFound = false;
          switch (this._urlType) {
            case "MediaElement":
              this._streaming = true;
              this._isReadyToPlay = true;
              this._streamingSource = AbstractEngine.audioEngine.audioContext.createMediaElementSource(urlOrArrayBuffer);
              if (this.autoplay) {
                this.play(0, this._offset, this._length);
              }
              if (this._readyToPlayCallback) {
                this._readyToPlayCallback();
              }
              break;
            case "MediaStream":
              this._streaming = true;
              this._isReadyToPlay = true;
              this._streamingSource = AbstractEngine.audioEngine.audioContext.createMediaStreamSource(urlOrArrayBuffer);
              if (this.autoplay) {
                this.play(0, this._offset, this._length);
              }
              if (this._readyToPlayCallback) {
                this._readyToPlayCallback();
              }
              break;
            case "ArrayBuffer":
              if (urlOrArrayBuffer.byteLength > 0) {
                codecSupportedFound = true;
                this._soundLoaded(urlOrArrayBuffer);
              }
              break;
            case "AudioBuffer":
              this._audioBufferLoaded(urlOrArrayBuffer);
              break;
            case "String":
              urls.push(urlOrArrayBuffer);
            // eslint-disable-next-line no-fallthrough
            case "Array":
              if (urls.length === 0) {
                urls = urlOrArrayBuffer;
              }
              for (let i = 0; i < urls.length; i++) {
                const url = urls[i];
                codecSupportedFound = options && options.skipCodecCheck || url.indexOf(".mp3", url.length - 4) !== -1 && AbstractEngine.audioEngine.isMP3supported || url.indexOf(".ogg", url.length - 4) !== -1 && AbstractEngine.audioEngine.isOGGsupported || url.indexOf(".wav", url.length - 4) !== -1 || url.indexOf(".m4a", url.length - 4) !== -1 || url.indexOf(".mp4", url.length - 4) !== -1 || url.indexOf("blob:") !== -1;
                if (codecSupportedFound) {
                  if (!this._streaming) {
                    this._scene._loadFile(url, (data) => {
                      this._soundLoaded(data);
                    }, void 0, true, true, (exception) => {
                      if (exception) {
                        Logger.Error("XHR " + exception.status + " error on: " + url + ".");
                      }
                      Logger.Error("Sound creation aborted.");
                      this._scene.mainSoundTrack.removeSound(this);
                    });
                  } else {
                    this._htmlAudioElement = new Audio(url);
                    this._htmlAudioElement.controls = false;
                    this._htmlAudioElement.loop = this.loop;
                    Tools.SetCorsBehavior(url, this._htmlAudioElement);
                    this._htmlAudioElement.preload = "auto";
                    this._htmlAudioElement.addEventListener("canplaythrough", () => {
                      this._isReadyToPlay = true;
                      if (this.autoplay) {
                        this.play(0, this._offset, this._length);
                      }
                      if (this._readyToPlayCallback) {
                        this._readyToPlayCallback();
                      }
                    }, { once: true });
                    document.body.appendChild(this._htmlAudioElement);
                    this._htmlAudioElement.load();
                  }
                  break;
                }
              }
              break;
            default:
              validParameter = false;
              break;
          }
          if (!validParameter) {
            Logger.Error("Parameter must be a URL to the sound, an Array of URLs (.mp3 & .ogg) or an ArrayBuffer of the sound.");
          } else {
            if (!codecSupportedFound) {
              this._isReadyToPlay = true;
              if (this._readyToPlayCallback) {
                setTimeout(() => {
                  if (this._readyToPlayCallback) {
                    this._readyToPlayCallback();
                  }
                }, 1e3);
              }
            }
          }
        } catch (ex) {
          Logger.Error("Unexpected error. Sound creation aborted.");
          this._scene.mainSoundTrack.removeSound(this);
        }
      }
    } else {
      this._scene.mainSoundTrack.addSound(this);
      if (AbstractEngine.audioEngine && !AbstractEngine.audioEngine.WarnedWebAudioUnsupported) {
        Logger.Error("Web Audio is not supported by your browser.");
        AbstractEngine.audioEngine.WarnedWebAudioUnsupported = true;
      }
      if (this._readyToPlayCallback) {
        setTimeout(() => {
          if (this._readyToPlayCallback) {
            this._readyToPlayCallback();
          }
        }, 1e3);
      }
    }
  }
  /**
   * Release the sound and its associated resources
   */
  dispose() {
    if (AbstractEngine.audioEngine?.canUseWebAudio) {
      if (this.isPlaying) {
        this.stop();
      }
      this._isReadyToPlay = false;
      if (this.soundTrackId === -1) {
        this._scene.mainSoundTrack.removeSound(this);
      } else if (this._scene.soundTracks) {
        this._scene.soundTracks[this.soundTrackId].removeSound(this);
      }
      if (this._soundGain) {
        this._soundGain.disconnect();
        this._soundGain = null;
      }
      if (this._soundPanner) {
        this._soundPanner.disconnect();
        this._soundPanner = null;
      }
      if (this._soundSource) {
        this._soundSource.disconnect();
        this._soundSource = null;
      }
      this._audioBuffer = null;
      if (this._htmlAudioElement) {
        this._htmlAudioElement.pause();
        this._htmlAudioElement.src = "";
        document.body.removeChild(this._htmlAudioElement);
        this._htmlAudioElement = null;
      }
      if (this._streamingSource) {
        this._streamingSource.disconnect();
        this._streamingSource = null;
      }
      if (this._connectedTransformNode && this._registerFunc) {
        this._connectedTransformNode.unregisterAfterWorldMatrixUpdate(this._registerFunc);
        this._connectedTransformNode = null;
      }
      this._clearTimeoutsAndObservers();
    }
  }
  /**
   * Gets if the sounds is ready to be played or not.
   * @returns true if ready, otherwise false
   */
  isReady() {
    return this._isReadyToPlay;
  }
  /**
   * Get the current class name.
   * @returns current class name
   */
  getClassName() {
    return "Sound";
  }
  _audioBufferLoaded(buffer) {
    if (!AbstractEngine.audioEngine?.audioContext) {
      return;
    }
    this._audioBuffer = buffer;
    this._isReadyToPlay = true;
    if (this.autoplay) {
      this.play(0, this._offset, this._length);
    }
    if (this._readyToPlayCallback) {
      this._readyToPlayCallback();
    }
  }
  _soundLoaded(audioData) {
    if (!AbstractEngine.audioEngine?.audioContext) {
      return;
    }
    AbstractEngine.audioEngine.audioContext.decodeAudioData(audioData, (buffer) => {
      this._audioBufferLoaded(buffer);
    }, (err) => {
      Logger.Error("Error while decoding audio data for: " + this.name + " / Error: " + err);
    });
  }
  /**
   * Sets the data of the sound from an audiobuffer
   * @param audioBuffer The audioBuffer containing the data
   */
  setAudioBuffer(audioBuffer) {
    if (AbstractEngine.audioEngine?.canUseWebAudio) {
      this._audioBuffer = audioBuffer;
      this._isReadyToPlay = true;
    }
  }
  /**
   * Updates the current sounds options such as maxdistance, loop...
   * @param options A JSON object containing values named as the object properties
   */
  updateOptions(options) {
    if (options) {
      this.loop = options.loop ?? this.loop;
      this.maxDistance = options.maxDistance ?? this.maxDistance;
      this.useCustomAttenuation = options.useCustomAttenuation ?? this.useCustomAttenuation;
      this.rolloffFactor = options.rolloffFactor ?? this.rolloffFactor;
      this.refDistance = options.refDistance ?? this.refDistance;
      this.distanceModel = options.distanceModel ?? this.distanceModel;
      this._playbackRate = options.playbackRate ?? this._playbackRate;
      this._length = options.length ?? void 0;
      this.spatialSound = options.spatialSound ?? this._spatialSound;
      this._setOffset(options.offset ?? void 0);
      this.setVolume(options.volume ?? this._volume);
      this._updateSpatialParameters();
      if (this.isPlaying) {
        if (this._streaming && this._htmlAudioElement) {
          this._htmlAudioElement.playbackRate = this._playbackRate;
          if (this._htmlAudioElement.loop !== this.loop) {
            this._htmlAudioElement.loop = this.loop;
          }
        } else {
          if (this._soundSource) {
            this._soundSource.playbackRate.value = this._playbackRate;
            if (this._soundSource.loop !== this.loop) {
              this._soundSource.loop = this.loop;
            }
            if (this._offset !== void 0 && this._soundSource.loopStart !== this._offset) {
              this._soundSource.loopStart = this._offset;
            }
            if (this._length !== void 0 && this._length !== this._soundSource.loopEnd) {
              this._soundSource.loopEnd = (this._offset | 0) + this._length;
            }
          }
        }
      }
    }
  }
  _createSpatialParameters() {
    if (AbstractEngine.audioEngine?.canUseWebAudio && AbstractEngine.audioEngine.audioContext) {
      if (this._scene.headphone) {
        this._panningModel = "HRTF";
      }
      this._soundPanner = this._soundPanner ?? AbstractEngine.audioEngine.audioContext.createPanner();
      if (this._soundPanner && this._outputAudioNode) {
        this._updateSpatialParameters();
        this._soundPanner.connect(this._outputAudioNode);
        this._inputAudioNode = this._soundPanner;
      }
    }
  }
  _disableSpatialSound() {
    if (!this._spatialSound) {
      return;
    }
    this._inputAudioNode = this._soundGain;
    this._soundPanner?.disconnect();
    this._soundPanner = null;
    this._spatialSound = false;
  }
  _updateSpatialParameters() {
    if (!this._spatialSound) {
      return;
    }
    if (this._soundPanner) {
      if (this.useCustomAttenuation) {
        this._soundPanner.distanceModel = "linear";
        this._soundPanner.maxDistance = Number.MAX_VALUE;
        this._soundPanner.refDistance = 1;
        this._soundPanner.rolloffFactor = 1;
        this._soundPanner.panningModel = this._panningModel;
      } else {
        this._soundPanner.distanceModel = this.distanceModel;
        this._soundPanner.maxDistance = this.maxDistance;
        this._soundPanner.refDistance = this.refDistance;
        this._soundPanner.rolloffFactor = this.rolloffFactor;
        this._soundPanner.panningModel = this._panningModel;
      }
    } else {
      this._createSpatialParameters();
    }
  }
  /**
   * Switch the panning model to HRTF:
   * Renders a stereo output of higher quality than equalpower  it uses a convolution with measured impulse responses from human subjects.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
   */
  switchPanningModelToHRTF() {
    this._panningModel = "HRTF";
    this._switchPanningModel();
  }
  /**
   * Switch the panning model to Equal Power:
   * Represents the equal-power panning algorithm, generally regarded as simple and efficient. equalpower is the default value.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
   */
  switchPanningModelToEqualPower() {
    this._panningModel = "equalpower";
    this._switchPanningModel();
  }
  _switchPanningModel() {
    if (AbstractEngine.audioEngine?.canUseWebAudio && this._spatialSound && this._soundPanner) {
      this._soundPanner.panningModel = this._panningModel;
    }
  }
  /**
   * Connect this sound to a sound track audio node like gain...
   * @param soundTrackAudioNode the sound track audio node to connect to
   */
  connectToSoundTrackAudioNode(soundTrackAudioNode) {
    if (AbstractEngine.audioEngine?.canUseWebAudio && this._outputAudioNode) {
      if (this._isOutputConnected) {
        this._outputAudioNode.disconnect();
      }
      this._outputAudioNode.connect(soundTrackAudioNode);
      this._isOutputConnected = true;
    }
  }
  /**
   * Transform this sound into a directional source
   * @param coneInnerAngle Size of the inner cone in degree
   * @param coneOuterAngle Size of the outer cone in degree
   * @param coneOuterGain Volume of the sound outside the outer cone (between 0.0 and 1.0)
   */
  setDirectionalCone(coneInnerAngle, coneOuterAngle, coneOuterGain) {
    if (coneOuterAngle < coneInnerAngle) {
      Logger.Error("setDirectionalCone(): outer angle of the cone must be superior or equal to the inner angle.");
      return;
    }
    this._coneInnerAngle = coneInnerAngle;
    this._coneOuterAngle = coneOuterAngle;
    this._coneOuterGain = coneOuterGain;
    this._isDirectional = true;
    if (this.isPlaying && this.loop) {
      this.stop();
      this.play(0, this._offset, this._length);
    }
  }
  /**
   * Gets or sets the inner angle for the directional cone.
   */
  get directionalConeInnerAngle() {
    return this._coneInnerAngle;
  }
  /**
   * Gets or sets the inner angle for the directional cone.
   */
  set directionalConeInnerAngle(value) {
    if (value != this._coneInnerAngle) {
      if (this._coneOuterAngle < value) {
        Logger.Error("directionalConeInnerAngle: outer angle of the cone must be superior or equal to the inner angle.");
        return;
      }
      this._coneInnerAngle = value;
      if (AbstractEngine.audioEngine?.canUseWebAudio && this._spatialSound && this._soundPanner) {
        this._soundPanner.coneInnerAngle = this._coneInnerAngle;
      }
    }
  }
  /**
   * Gets or sets the outer angle for the directional cone.
   */
  get directionalConeOuterAngle() {
    return this._coneOuterAngle;
  }
  /**
   * Gets or sets the outer angle for the directional cone.
   */
  set directionalConeOuterAngle(value) {
    if (value != this._coneOuterAngle) {
      if (value < this._coneInnerAngle) {
        Logger.Error("directionalConeOuterAngle: outer angle of the cone must be superior or equal to the inner angle.");
        return;
      }
      this._coneOuterAngle = value;
      if (AbstractEngine.audioEngine?.canUseWebAudio && this._spatialSound && this._soundPanner) {
        this._soundPanner.coneOuterAngle = this._coneOuterAngle;
      }
    }
  }
  /**
   * Sets the position of the emitter if spatial sound is enabled
   * @param newPosition Defines the new position
   */
  setPosition(newPosition) {
    if (newPosition.equals(this._position)) {
      return;
    }
    this._position.copyFrom(newPosition);
    if (AbstractEngine.audioEngine?.canUseWebAudio && this._spatialSound && this._soundPanner && !isNaN(this._position.x) && !isNaN(this._position.y) && !isNaN(this._position.z)) {
      this._soundPanner.positionX.value = this._position.x;
      this._soundPanner.positionY.value = this._position.y;
      this._soundPanner.positionZ.value = this._position.z;
    }
  }
  /**
   * Sets the local direction of the emitter if spatial sound is enabled
   * @param newLocalDirection Defines the new local direction
   */
  setLocalDirectionToMesh(newLocalDirection) {
    this._localDirection = newLocalDirection;
    if (AbstractEngine.audioEngine?.canUseWebAudio && this._connectedTransformNode && this.isPlaying) {
      this._updateDirection();
    }
  }
  _updateDirection() {
    if (!this._connectedTransformNode || !this._soundPanner) {
      return;
    }
    const mat = this._connectedTransformNode.getWorldMatrix();
    const direction = Vector3.TransformNormal(this._localDirection, mat);
    direction.normalize();
    this._soundPanner.orientationX.value = direction.x;
    this._soundPanner.orientationY.value = direction.y;
    this._soundPanner.orientationZ.value = direction.z;
  }
  /** @internal */
  updateDistanceFromListener() {
    if (AbstractEngine.audioEngine?.canUseWebAudio && this._connectedTransformNode && this.useCustomAttenuation && this._soundGain && this._scene.activeCamera) {
      const distance = this._scene.audioListenerPositionProvider ? this._connectedTransformNode.position.subtract(this._scene.audioListenerPositionProvider()).length() : this._connectedTransformNode.getDistanceToCamera(this._scene.activeCamera);
      this._soundGain.gain.value = this._customAttenuationFunction(this._volume, distance, this.maxDistance, this.refDistance, this.rolloffFactor);
    }
  }
  /**
   * Sets a new custom attenuation function for the sound.
   * @param callback Defines the function used for the attenuation
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-your-own-custom-attenuation-function
   */
  setAttenuationFunction(callback) {
    this._customAttenuationFunction = callback;
  }
  /**
   * Play the sound
   * @param time (optional) Start the sound after X seconds. Start immediately (0) by default.
   * @param offset (optional) Start the sound at a specific time in seconds
   * @param length (optional) Sound duration (in seconds)
   */
  play(time, offset, length) {
    if (this._isReadyToPlay && this._scene.audioEnabled && AbstractEngine.audioEngine?.audioContext) {
      try {
        this._clearTimeoutsAndObservers();
        let startTime = time ? AbstractEngine.audioEngine?.audioContext.currentTime + time : AbstractEngine.audioEngine?.audioContext.currentTime;
        if (!this._soundSource || !this._streamingSource) {
          if (this._spatialSound && this._soundPanner) {
            if (!isNaN(this._position.x) && !isNaN(this._position.y) && !isNaN(this._position.z)) {
              this._soundPanner.positionX.value = this._position.x;
              this._soundPanner.positionY.value = this._position.y;
              this._soundPanner.positionZ.value = this._position.z;
            }
            if (this._isDirectional) {
              this._soundPanner.coneInnerAngle = this._coneInnerAngle;
              this._soundPanner.coneOuterAngle = this._coneOuterAngle;
              this._soundPanner.coneOuterGain = this._coneOuterGain;
              if (this._connectedTransformNode) {
                this._updateDirection();
              } else {
                this._soundPanner.setOrientation(this._localDirection.x, this._localDirection.y, this._localDirection.z);
              }
            }
          }
        }
        if (this._streaming) {
          if (!this._streamingSource && this._htmlAudioElement) {
            this._streamingSource = AbstractEngine.audioEngine.audioContext.createMediaElementSource(this._htmlAudioElement);
            this._htmlAudioElement.onended = () => {
              this._onended();
            };
            this._htmlAudioElement.playbackRate = this._playbackRate;
          }
          if (this._streamingSource) {
            this._streamingSource.disconnect();
            if (this._inputAudioNode) {
              this._streamingSource.connect(this._inputAudioNode);
            }
          }
          if (this._htmlAudioElement) {
            const tryToPlay = () => {
              if (AbstractEngine.audioEngine?.unlocked) {
                if (!this._htmlAudioElement) {
                  return;
                }
                this._htmlAudioElement.currentTime = offset ?? 0;
                const playPromise = this._htmlAudioElement.play();
                if (playPromise !== void 0) {
                  playPromise.catch(() => {
                    AbstractEngine.audioEngine?.lock();
                    if (this.loop || this.autoplay) {
                      this._audioUnlockedObserver = AbstractEngine.audioEngine?.onAudioUnlockedObservable.addOnce(() => {
                        tryToPlay();
                      });
                    }
                  });
                }
              } else {
                if (this.loop || this.autoplay) {
                  this._audioUnlockedObserver = AbstractEngine.audioEngine?.onAudioUnlockedObservable.addOnce(() => {
                    tryToPlay();
                  });
                }
              }
            };
            tryToPlay();
          }
        } else {
          const tryToPlay = () => {
            if (AbstractEngine.audioEngine?.audioContext) {
              length = length || this._length;
              if (offset !== void 0) {
                this._setOffset(offset);
              }
              if (this._soundSource) {
                const oldSource = this._soundSource;
                oldSource.onended = () => {
                  oldSource.disconnect();
                };
              }
              this._soundSource = AbstractEngine.audioEngine?.audioContext.createBufferSource();
              if (this._soundSource && this._inputAudioNode) {
                this._soundSource.buffer = this._audioBuffer;
                this._soundSource.connect(this._inputAudioNode);
                this._soundSource.loop = this.loop;
                if (offset !== void 0) {
                  this._soundSource.loopStart = offset;
                }
                if (length !== void 0) {
                  this._soundSource.loopEnd = (offset | 0) + length;
                }
                this._soundSource.playbackRate.value = this._playbackRate;
                this._soundSource.onended = () => {
                  this._onended();
                };
                startTime = time ? AbstractEngine.audioEngine?.audioContext.currentTime + time : AbstractEngine.audioEngine.audioContext.currentTime;
                const actualOffset = ((this.isPaused ? this.currentTime : 0) + (this._offset ?? 0)) % this._soundSource.buffer.duration;
                this._soundSource.start(startTime, actualOffset, this.loop ? void 0 : length);
              }
            }
          };
          if (AbstractEngine.audioEngine?.audioContext.state === "suspended") {
            this._tryToPlayTimeout = setTimeout(() => {
              if (AbstractEngine.audioEngine?.audioContext.state === "suspended") {
                AbstractEngine.audioEngine.lock();
                if (this.loop || this.autoplay) {
                  this._audioUnlockedObserver = AbstractEngine.audioEngine.onAudioUnlockedObservable.addOnce(() => {
                    tryToPlay();
                  });
                }
              } else {
                tryToPlay();
              }
            }, 500);
          } else {
            tryToPlay();
          }
        }
        this._startTime = startTime;
        this.isPlaying = true;
        this.isPaused = false;
      } catch (ex) {
        Logger.Error("Error while trying to play audio: " + this.name + ", " + ex.message);
      }
    }
  }
  _onended() {
    this.isPlaying = false;
    this._startTime = 0;
    this._currentTime = 0;
    if (this.onended) {
      this.onended();
    }
    this.onEndedObservable.notifyObservers(this);
  }
  /**
   * Stop the sound
   * @param time (optional) Stop the sound after X seconds. Stop immediately (0) by default.
   */
  stop(time) {
    if (this.isPlaying) {
      this._clearTimeoutsAndObservers();
      if (this._streaming) {
        if (this._htmlAudioElement) {
          this._htmlAudioElement.pause();
          if (this._htmlAudioElement.currentTime > 0) {
            this._htmlAudioElement.currentTime = 0;
          }
        } else {
          this._streamingSource?.disconnect();
        }
        this.isPlaying = false;
      } else if (AbstractEngine.audioEngine?.audioContext && this._soundSource) {
        const stopTime = time ? AbstractEngine.audioEngine.audioContext.currentTime + time : void 0;
        this._soundSource.onended = () => {
          this.isPlaying = false;
          this.isPaused = false;
          this._startTime = 0;
          this._currentTime = 0;
          if (this._soundSource) {
            this._soundSource.onended = () => void 0;
          }
          this._onended();
        };
        this._soundSource.stop(stopTime);
      } else {
        this.isPlaying = false;
      }
    } else if (this.isPaused) {
      this.isPaused = false;
      this._startTime = 0;
      this._currentTime = 0;
    }
  }
  /**
   * Put the sound in pause
   */
  pause() {
    if (this.isPlaying) {
      this._clearTimeoutsAndObservers();
      if (this._streaming) {
        if (this._htmlAudioElement) {
          this._htmlAudioElement.pause();
        } else {
          this._streamingSource?.disconnect();
        }
        this.isPlaying = false;
        this.isPaused = true;
      } else if (AbstractEngine.audioEngine?.audioContext && this._soundSource) {
        this._soundSource.onended = () => void 0;
        this._soundSource.stop();
        this.isPlaying = false;
        this.isPaused = true;
        this._currentTime += AbstractEngine.audioEngine.audioContext.currentTime - this._startTime;
      }
    }
  }
  /**
   * Sets a dedicated volume for this sounds
   * @param newVolume Define the new volume of the sound
   * @param time Define time for gradual change to new volume
   */
  setVolume(newVolume, time) {
    if (AbstractEngine.audioEngine?.canUseWebAudio && this._soundGain) {
      if (time && AbstractEngine.audioEngine.audioContext) {
        this._soundGain.gain.cancelScheduledValues(AbstractEngine.audioEngine.audioContext.currentTime);
        this._soundGain.gain.setValueAtTime(this._soundGain.gain.value, AbstractEngine.audioEngine.audioContext.currentTime);
        this._soundGain.gain.linearRampToValueAtTime(newVolume, AbstractEngine.audioEngine.audioContext.currentTime + time);
      } else {
        this._soundGain.gain.value = newVolume;
      }
    }
    this._volume = newVolume;
  }
  /**
   * Set the sound play back rate
   * @param newPlaybackRate Define the playback rate the sound should be played at
   */
  setPlaybackRate(newPlaybackRate) {
    this._playbackRate = newPlaybackRate;
    if (this.isPlaying) {
      if (this._streaming && this._htmlAudioElement) {
        this._htmlAudioElement.playbackRate = this._playbackRate;
      } else if (this._soundSource) {
        this._soundSource.playbackRate.value = this._playbackRate;
      }
    }
  }
  /**
   * Gets the sound play back rate.
   * @returns the  play back rate of the sound
   */
  getPlaybackRate() {
    return this._playbackRate;
  }
  /**
   * Gets the volume of the sound.
   * @returns the volume of the sound
   */
  getVolume() {
    return this._volume;
  }
  /**
   * Attach the sound to a dedicated mesh
   * @param transformNode The transform node to connect the sound with
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#attaching-a-sound-to-a-mesh
   */
  attachToMesh(transformNode) {
    if (this._connectedTransformNode && this._registerFunc) {
      this._connectedTransformNode.unregisterAfterWorldMatrixUpdate(this._registerFunc);
      this._registerFunc = null;
    }
    this._connectedTransformNode = transformNode;
    if (!this._spatialSound) {
      this._spatialSound = true;
      this._createSpatialParameters();
      if (this.isPlaying && this.loop) {
        this.stop();
        this.play(0, this._offset, this._length);
      }
    }
    this._onRegisterAfterWorldMatrixUpdate(this._connectedTransformNode);
    this._registerFunc = (transformNode2) => this._onRegisterAfterWorldMatrixUpdate(transformNode2);
    this._connectedTransformNode.registerAfterWorldMatrixUpdate(this._registerFunc);
  }
  /**
   * Detach the sound from the previously attached mesh
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#attaching-a-sound-to-a-mesh
   */
  detachFromMesh() {
    if (this._connectedTransformNode && this._registerFunc) {
      this._connectedTransformNode.unregisterAfterWorldMatrixUpdate(this._registerFunc);
      this._registerFunc = null;
      this._connectedTransformNode = null;
    }
  }
  _onRegisterAfterWorldMatrixUpdate(node) {
    if (!node.getBoundingInfo) {
      this.setPosition(node.absolutePosition);
    } else {
      const mesh = node;
      const boundingInfo = mesh.getBoundingInfo();
      this.setPosition(boundingInfo.boundingSphere.centerWorld);
    }
    if (AbstractEngine.audioEngine?.canUseWebAudio && this._isDirectional && this.isPlaying) {
      this._updateDirection();
    }
  }
  /**
   * Clone the current sound in the scene.
   * @returns the new sound clone
   */
  clone() {
    if (!this._streaming) {
      const setBufferAndRun = () => {
        _RetryWithInterval(() => this._isReadyToPlay, () => {
          clonedSound._audioBuffer = this.getAudioBuffer();
          clonedSound._isReadyToPlay = true;
          if (clonedSound.autoplay) {
            clonedSound.play(0, this._offset, this._length);
          }
        }, void 0, 300);
      };
      const currentOptions = {
        autoplay: this.autoplay,
        loop: this.loop,
        volume: this._volume,
        spatialSound: this._spatialSound,
        maxDistance: this.maxDistance,
        useCustomAttenuation: this.useCustomAttenuation,
        rolloffFactor: this.rolloffFactor,
        refDistance: this.refDistance,
        distanceModel: this.distanceModel
      };
      const clonedSound = new _Sound(this.name + "_cloned", new ArrayBuffer(0), this._scene, null, currentOptions);
      if (this.useCustomAttenuation) {
        clonedSound.setAttenuationFunction(this._customAttenuationFunction);
      }
      clonedSound.setPosition(this._position);
      clonedSound.setPlaybackRate(this._playbackRate);
      setBufferAndRun();
      return clonedSound;
    } else {
      return null;
    }
  }
  /**
   * Gets the current underlying audio buffer containing the data
   * @returns the audio buffer
   */
  getAudioBuffer() {
    return this._audioBuffer;
  }
  /**
   * Gets the WebAudio AudioBufferSourceNode, lets you keep track of and stop instances of this Sound.
   * @returns the source node
   */
  getSoundSource() {
    return this._soundSource;
  }
  /**
   * Gets the WebAudio GainNode, gives you precise control over the gain of instances of this Sound.
   * @returns the gain node
   */
  getSoundGain() {
    return this._soundGain;
  }
  /**
   * Serializes the Sound in a JSON representation
   * @returns the JSON representation of the sound
   */
  serialize() {
    const serializationObject = {
      name: this.name,
      url: this._url,
      autoplay: this.autoplay,
      loop: this.loop,
      volume: this._volume,
      spatialSound: this._spatialSound,
      maxDistance: this.maxDistance,
      rolloffFactor: this.rolloffFactor,
      refDistance: this.refDistance,
      distanceModel: this.distanceModel,
      playbackRate: this._playbackRate,
      panningModel: this._panningModel,
      soundTrackId: this.soundTrackId,
      metadata: this.metadata
    };
    if (this._spatialSound) {
      if (this._connectedTransformNode) {
        serializationObject.connectedMeshId = this._connectedTransformNode.id;
      }
      serializationObject.position = this._position.asArray();
      serializationObject.refDistance = this.refDistance;
      serializationObject.distanceModel = this.distanceModel;
      serializationObject.isDirectional = this._isDirectional;
      serializationObject.localDirectionToMesh = this._localDirection.asArray();
      serializationObject.coneInnerAngle = this._coneInnerAngle;
      serializationObject.coneOuterAngle = this._coneOuterAngle;
      serializationObject.coneOuterGain = this._coneOuterGain;
    }
    return serializationObject;
  }
  /**
   * Parse a JSON representation of a sound to instantiate in a given scene
   * @param parsedSound Define the JSON representation of the sound (usually coming from the serialize method)
   * @param scene Define the scene the new parsed sound should be created in
   * @param rootUrl Define the rooturl of the load in case we need to fetch relative dependencies
   * @param sourceSound Define a sound place holder if do not need to instantiate a new one
   * @returns the newly parsed sound
   */
  static Parse(parsedSound, scene, rootUrl, sourceSound) {
    const soundName = parsedSound.name;
    let soundUrl;
    if (parsedSound.url) {
      soundUrl = rootUrl + parsedSound.url;
    } else {
      soundUrl = rootUrl + soundName;
    }
    const options = {
      autoplay: parsedSound.autoplay,
      loop: parsedSound.loop,
      volume: parsedSound.volume,
      spatialSound: parsedSound.spatialSound,
      maxDistance: parsedSound.maxDistance,
      rolloffFactor: parsedSound.rolloffFactor,
      refDistance: parsedSound.refDistance,
      distanceModel: parsedSound.distanceModel,
      playbackRate: parsedSound.playbackRate
    };
    let newSound;
    if (!sourceSound) {
      newSound = new _Sound(soundName, soundUrl, scene, () => {
        scene.removePendingData(newSound);
      }, options);
      scene.addPendingData(newSound);
    } else {
      const setBufferAndRun = () => {
        _RetryWithInterval(() => sourceSound._isReadyToPlay, () => {
          newSound._audioBuffer = sourceSound.getAudioBuffer();
          newSound._isReadyToPlay = true;
          if (newSound.autoplay) {
            newSound.play(0, newSound._offset, newSound._length);
          }
        }, void 0, 300);
      };
      newSound = new _Sound(soundName, new ArrayBuffer(0), scene, null, options);
      setBufferAndRun();
    }
    if (parsedSound.position) {
      const soundPosition = Vector3.FromArray(parsedSound.position);
      newSound.setPosition(soundPosition);
    }
    if (parsedSound.isDirectional) {
      newSound.setDirectionalCone(parsedSound.coneInnerAngle || 360, parsedSound.coneOuterAngle || 360, parsedSound.coneOuterGain || 0);
      if (parsedSound.localDirectionToMesh) {
        const localDirectionToMesh = Vector3.FromArray(parsedSound.localDirectionToMesh);
        newSound.setLocalDirectionToMesh(localDirectionToMesh);
      }
    }
    if (parsedSound.connectedMeshId) {
      const connectedMesh = scene.getMeshById(parsedSound.connectedMeshId);
      if (connectedMesh) {
        newSound.attachToMesh(connectedMesh);
      }
    }
    if (parsedSound.metadata) {
      newSound.metadata = parsedSound.metadata;
    }
    return newSound;
  }
  _setOffset(value) {
    if (this._offset === value) {
      return;
    }
    if (this.isPaused) {
      this.stop();
      this.isPaused = false;
    }
    this._offset = value;
  }
  _clearTimeoutsAndObservers() {
    if (this._tryToPlayTimeout) {
      clearTimeout(this._tryToPlayTimeout);
      this._tryToPlayTimeout = null;
    }
    if (this._audioUnlockedObserver) {
      AbstractEngine.audioEngine?.onAudioUnlockedObservable.remove(this._audioUnlockedObserver);
      this._audioUnlockedObserver = null;
    }
  }
};
Sound._SceneComponentInitialization = (_) => {
  throw _WarnImport("AudioSceneComponent");
};
RegisterClass("BABYLON.Sound", Sound);

// node_modules/@babylonjs/core/Audio/soundTrack.js
var SoundTrack = class {
  /**
   * Creates a new sound track.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#using-sound-tracks
   * @param scene Define the scene the sound track belongs to
   * @param options
   */
  constructor(scene, options = {}) {
    this.id = -1;
    this._isInitialized = false;
    scene = scene || EngineStore.LastCreatedScene;
    if (!scene) {
      return;
    }
    this._scene = scene;
    this.soundCollection = [];
    this._options = options;
    if (!this._options.mainTrack && this._scene.soundTracks) {
      this._scene.soundTracks.push(this);
      this.id = this._scene.soundTracks.length - 1;
    }
  }
  _initializeSoundTrackAudioGraph() {
    if (AbstractEngine.audioEngine?.canUseWebAudio && AbstractEngine.audioEngine.audioContext) {
      this._outputAudioNode = AbstractEngine.audioEngine.audioContext.createGain();
      this._outputAudioNode.connect(AbstractEngine.audioEngine.masterGain);
      if (this._options) {
        if (this._options.volume) {
          this._outputAudioNode.gain.value = this._options.volume;
        }
      }
      this._isInitialized = true;
    }
  }
  /**
   * Release the sound track and its associated resources
   */
  dispose() {
    if (AbstractEngine.audioEngine && AbstractEngine.audioEngine.canUseWebAudio) {
      if (this._connectedAnalyser) {
        this._connectedAnalyser.stopDebugCanvas();
      }
      while (this.soundCollection.length) {
        this.soundCollection[0].dispose();
      }
      if (this._outputAudioNode) {
        this._outputAudioNode.disconnect();
      }
      this._outputAudioNode = null;
    }
  }
  /**
   * Adds a sound to this sound track
   * @param sound define the sound to add
   * @ignoreNaming
   */
  addSound(sound) {
    if (!this._isInitialized) {
      this._initializeSoundTrackAudioGraph();
    }
    if (AbstractEngine.audioEngine?.canUseWebAudio && this._outputAudioNode) {
      sound.connectToSoundTrackAudioNode(this._outputAudioNode);
    }
    if (sound.soundTrackId !== void 0) {
      if (sound.soundTrackId === -1) {
        this._scene.mainSoundTrack.removeSound(sound);
      } else if (this._scene.soundTracks) {
        this._scene.soundTracks[sound.soundTrackId].removeSound(sound);
      }
    }
    this.soundCollection.push(sound);
    sound.soundTrackId = this.id;
  }
  /**
   * Removes a sound to this sound track
   * @param sound define the sound to remove
   * @ignoreNaming
   */
  removeSound(sound) {
    const index = this.soundCollection.indexOf(sound);
    if (index !== -1) {
      this.soundCollection.splice(index, 1);
    }
  }
  /**
   * Set a global volume for the full sound track.
   * @param newVolume Define the new volume of the sound track
   */
  setVolume(newVolume) {
    if (AbstractEngine.audioEngine?.canUseWebAudio && this._outputAudioNode) {
      this._outputAudioNode.gain.value = newVolume;
    }
  }
  /**
   * Switch the panning model to HRTF:
   * Renders a stereo output of higher quality than equalpower  it uses a convolution with measured impulse responses from human subjects.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
   */
  switchPanningModelToHRTF() {
    if (AbstractEngine.audioEngine?.canUseWebAudio) {
      for (let i = 0; i < this.soundCollection.length; i++) {
        this.soundCollection[i].switchPanningModelToHRTF();
      }
    }
  }
  /**
   * Switch the panning model to Equal Power:
   * Represents the equal-power panning algorithm, generally regarded as simple and efficient. equalpower is the default value.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
   */
  switchPanningModelToEqualPower() {
    if (AbstractEngine.audioEngine?.canUseWebAudio) {
      for (let i = 0; i < this.soundCollection.length; i++) {
        this.soundCollection[i].switchPanningModelToEqualPower();
      }
    }
  }
  /**
   * Connect the sound track to an audio analyser allowing some amazing
   * synchronization between the sounds/music and your visualization (VuMeter for instance).
   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#using-the-analyser
   * @param analyser The analyser to connect to the engine
   */
  connectToAnalyser(analyser) {
    if (this._connectedAnalyser) {
      this._connectedAnalyser.stopDebugCanvas();
    }
    this._connectedAnalyser = analyser;
    if (AbstractEngine.audioEngine?.canUseWebAudio && this._outputAudioNode) {
      this._outputAudioNode.disconnect();
      this._connectedAnalyser.connectAudioNodes(this._outputAudioNode, AbstractEngine.audioEngine.masterGain);
    }
  }
};

// node_modules/@babylonjs/core/Loading/Plugins/babylonFileParser.function.js
var BabylonFileParsers = {};
var IndividualBabylonFileParsers = {};
function AddParser(name, parser) {
  BabylonFileParsers[name] = parser;
}
function GetParser(name) {
  if (BabylonFileParsers[name]) {
    return BabylonFileParsers[name];
  }
  return null;
}
function AddIndividualParser(name, parser) {
  IndividualBabylonFileParsers[name] = parser;
}
function GetIndividualParser(name) {
  if (IndividualBabylonFileParsers[name]) {
    return IndividualBabylonFileParsers[name];
  }
  return null;
}
function Parse(jsonData, scene, container, rootUrl) {
  for (const parserName in BabylonFileParsers) {
    if (Object.prototype.hasOwnProperty.call(BabylonFileParsers, parserName)) {
      BabylonFileParsers[parserName](jsonData, scene, container, rootUrl);
    }
  }
}

// node_modules/@babylonjs/core/Audio/audioSceneComponent.js
AddParser(SceneComponentConstants.NAME_AUDIO, (parsedData, scene, container, rootUrl) => {
  let loadedSounds = [];
  let loadedSound;
  container.sounds = container.sounds || [];
  if (parsedData.sounds !== void 0 && parsedData.sounds !== null) {
    for (let index = 0, cache = parsedData.sounds.length; index < cache; index++) {
      const parsedSound = parsedData.sounds[index];
      if (AbstractEngine.audioEngine?.canUseWebAudio) {
        if (!parsedSound.url) {
          parsedSound.url = parsedSound.name;
        }
        if (!loadedSounds[parsedSound.url]) {
          loadedSound = Sound.Parse(parsedSound, scene, rootUrl);
          loadedSounds[parsedSound.url] = loadedSound;
          container.sounds.push(loadedSound);
        } else {
          container.sounds.push(Sound.Parse(parsedSound, scene, rootUrl, loadedSounds[parsedSound.url]));
        }
      } else {
        container.sounds.push(new Sound(parsedSound.name, null, scene));
      }
    }
  }
  loadedSounds = [];
});
Object.defineProperty(Scene.prototype, "mainSoundTrack", {
  get: function() {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    if (!this._mainSoundTrack) {
      this._mainSoundTrack = new SoundTrack(this, { mainTrack: true });
    }
    return this._mainSoundTrack;
  },
  enumerable: true,
  configurable: true
});
Scene.prototype.getSoundByName = function(name) {
  let index;
  for (index = 0; index < this.mainSoundTrack.soundCollection.length; index++) {
    if (this.mainSoundTrack.soundCollection[index].name === name) {
      return this.mainSoundTrack.soundCollection[index];
    }
  }
  if (this.soundTracks) {
    for (let sdIndex = 0; sdIndex < this.soundTracks.length; sdIndex++) {
      for (index = 0; index < this.soundTracks[sdIndex].soundCollection.length; index++) {
        if (this.soundTracks[sdIndex].soundCollection[index].name === name) {
          return this.soundTracks[sdIndex].soundCollection[index];
        }
      }
    }
  }
  return null;
};
Object.defineProperty(Scene.prototype, "audioEnabled", {
  get: function() {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    return compo.audioEnabled;
  },
  set: function(value) {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    if (value) {
      compo.enableAudio();
    } else {
      compo.disableAudio();
    }
  },
  enumerable: true,
  configurable: true
});
Object.defineProperty(Scene.prototype, "headphone", {
  get: function() {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    return compo.headphone;
  },
  set: function(value) {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    if (value) {
      compo.switchAudioModeForHeadphones();
    } else {
      compo.switchAudioModeForNormalSpeakers();
    }
  },
  enumerable: true,
  configurable: true
});
Object.defineProperty(Scene.prototype, "audioListenerPositionProvider", {
  get: function() {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    return compo.audioListenerPositionProvider;
  },
  set: function(value) {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    if (value && typeof value !== "function") {
      throw new Error("The value passed to [Scene.audioListenerPositionProvider] must be a function that returns a Vector3");
    } else {
      compo.audioListenerPositionProvider = value;
    }
  },
  enumerable: true,
  configurable: true
});
Object.defineProperty(Scene.prototype, "audioListenerRotationProvider", {
  get: function() {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    return compo.audioListenerRotationProvider;
  },
  set: function(value) {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    if (value && typeof value !== "function") {
      throw new Error("The value passed to [Scene.audioListenerRotationProvider] must be a function that returns a Vector3");
    } else {
      compo.audioListenerRotationProvider = value;
    }
  },
  enumerable: true,
  configurable: true
});
Object.defineProperty(Scene.prototype, "audioPositioningRefreshRate", {
  get: function() {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    return compo.audioPositioningRefreshRate;
  },
  set: function(value) {
    let compo = this._getComponent(SceneComponentConstants.NAME_AUDIO);
    if (!compo) {
      compo = new AudioSceneComponent(this);
      this._addComponent(compo);
    }
    compo.audioPositioningRefreshRate = value;
  },
  enumerable: true,
  configurable: true
});
var AudioSceneComponent = class _AudioSceneComponent {
  /**
   * Gets whether audio is enabled or not.
   * Please use related enable/disable method to switch state.
   */
  get audioEnabled() {
    return this._audioEnabled;
  }
  /**
   * Gets whether audio is outputting to headphone or not.
   * Please use the according Switch methods to change output.
   */
  get headphone() {
    return this._headphone;
  }
  /**
   * Creates a new instance of the component for the given scene
   * @param scene Defines the scene to register the component in
   */
  constructor(scene) {
    this.name = SceneComponentConstants.NAME_AUDIO;
    this._audioEnabled = true;
    this._headphone = false;
    this.audioPositioningRefreshRate = 500;
    this.audioListenerPositionProvider = null;
    this.audioListenerRotationProvider = null;
    this._cachedCameraDirection = new Vector3();
    this._cachedCameraPosition = new Vector3();
    this._lastCheck = 0;
    this._invertMatrixTemp = new Matrix();
    this._cameraDirectionTemp = new Vector3();
    scene = scene || EngineStore.LastCreatedScene;
    if (!scene) {
      return;
    }
    this.scene = scene;
    scene.soundTracks = [];
    scene.sounds = [];
  }
  /**
   * Registers the component in a given scene
   */
  register() {
    this.scene._afterRenderStage.registerStep(SceneComponentConstants.STEP_AFTERRENDER_AUDIO, this, this._afterRender);
  }
  /**
   * Rebuilds the elements related to this component in case of
   * context lost for instance.
   */
  rebuild() {
  }
  /**
   * Serializes the component data to the specified json object
   * @param serializationObject The object to serialize to
   */
  serialize(serializationObject) {
    serializationObject.sounds = [];
    if (this.scene.soundTracks) {
      for (let index = 0; index < this.scene.soundTracks.length; index++) {
        const soundtrack = this.scene.soundTracks[index];
        for (let soundId = 0; soundId < soundtrack.soundCollection.length; soundId++) {
          serializationObject.sounds.push(soundtrack.soundCollection[soundId].serialize());
        }
      }
    }
  }
  /**
   * Adds all the elements from the container to the scene
   * @param container the container holding the elements
   */
  addFromContainer(container) {
    if (!container.sounds) {
      return;
    }
    for (const sound of container.sounds) {
      sound.play();
      sound.autoplay = true;
      this.scene.mainSoundTrack.addSound(sound);
    }
  }
  /**
   * Removes all the elements in the container from the scene
   * @param container contains the elements to remove
   * @param dispose if the removed element should be disposed (default: false)
   */
  removeFromContainer(container, dispose = false) {
    if (!container.sounds) {
      return;
    }
    for (const sound of container.sounds) {
      sound.stop();
      sound.autoplay = false;
      this.scene.mainSoundTrack.removeSound(sound);
      if (dispose) {
        sound.dispose();
      }
    }
  }
  /**
   * Disposes the component and the associated resources.
   */
  dispose() {
    const scene = this.scene;
    if (scene._mainSoundTrack) {
      scene.mainSoundTrack.dispose();
    }
    if (scene.soundTracks) {
      for (let scIndex = 0; scIndex < scene.soundTracks.length; scIndex++) {
        scene.soundTracks[scIndex].dispose();
      }
    }
  }
  /**
   * Disables audio in the associated scene.
   */
  disableAudio() {
    const scene = this.scene;
    this._audioEnabled = false;
    if (AbstractEngine.audioEngine && AbstractEngine.audioEngine.audioContext) {
      AbstractEngine.audioEngine.audioContext.suspend();
    }
    let i;
    for (i = 0; i < scene.mainSoundTrack.soundCollection.length; i++) {
      scene.mainSoundTrack.soundCollection[i].pause();
    }
    if (scene.soundTracks) {
      for (i = 0; i < scene.soundTracks.length; i++) {
        for (let j = 0; j < scene.soundTracks[i].soundCollection.length; j++) {
          scene.soundTracks[i].soundCollection[j].pause();
        }
      }
    }
  }
  /**
   * Enables audio in the associated scene.
   */
  enableAudio() {
    const scene = this.scene;
    this._audioEnabled = true;
    if (AbstractEngine.audioEngine && AbstractEngine.audioEngine.audioContext) {
      AbstractEngine.audioEngine.audioContext.resume();
    }
    let i;
    for (i = 0; i < scene.mainSoundTrack.soundCollection.length; i++) {
      if (scene.mainSoundTrack.soundCollection[i].isPaused) {
        scene.mainSoundTrack.soundCollection[i].play();
      }
    }
    if (scene.soundTracks) {
      for (i = 0; i < scene.soundTracks.length; i++) {
        for (let j = 0; j < scene.soundTracks[i].soundCollection.length; j++) {
          if (scene.soundTracks[i].soundCollection[j].isPaused) {
            scene.soundTracks[i].soundCollection[j].play();
          }
        }
      }
    }
  }
  /**
   * Switch audio to headphone output.
   */
  switchAudioModeForHeadphones() {
    const scene = this.scene;
    this._headphone = true;
    scene.mainSoundTrack.switchPanningModelToHRTF();
    if (scene.soundTracks) {
      for (let i = 0; i < scene.soundTracks.length; i++) {
        scene.soundTracks[i].switchPanningModelToHRTF();
      }
    }
  }
  /**
   * Switch audio to normal speakers.
   */
  switchAudioModeForNormalSpeakers() {
    const scene = this.scene;
    this._headphone = false;
    scene.mainSoundTrack.switchPanningModelToEqualPower();
    if (scene.soundTracks) {
      for (let i = 0; i < scene.soundTracks.length; i++) {
        scene.soundTracks[i].switchPanningModelToEqualPower();
      }
    }
  }
  _afterRender() {
    const now = PrecisionDate.Now;
    if (this._lastCheck && now - this._lastCheck < this.audioPositioningRefreshRate) {
      return;
    }
    this._lastCheck = now;
    const scene = this.scene;
    if (!this._audioEnabled || !scene._mainSoundTrack || !scene.soundTracks || scene._mainSoundTrack.soundCollection.length === 0 && scene.soundTracks.length === 1) {
      return;
    }
    const audioEngine = AbstractEngine.audioEngine;
    if (!audioEngine) {
      return;
    }
    if (audioEngine.audioContext) {
      let listeningCamera = scene.activeCamera;
      if (scene.activeCameras && scene.activeCameras.length > 0) {
        listeningCamera = scene.activeCameras[0];
      }
      if (this.audioListenerPositionProvider) {
        const position = this.audioListenerPositionProvider();
        audioEngine.audioContext.listener.setPosition(position.x || 0, position.y || 0, position.z || 0);
      } else if (listeningCamera) {
        if (!this._cachedCameraPosition.equals(listeningCamera.globalPosition)) {
          this._cachedCameraPosition.copyFrom(listeningCamera.globalPosition);
          audioEngine.audioContext.listener.setPosition(listeningCamera.globalPosition.x, listeningCamera.globalPosition.y, listeningCamera.globalPosition.z);
        }
      } else {
        audioEngine.audioContext.listener.setPosition(0, 0, 0);
      }
      if (this.audioListenerRotationProvider) {
        const rotation = this.audioListenerRotationProvider();
        audioEngine.audioContext.listener.setOrientation(rotation.x || 0, rotation.y || 0, rotation.z || 0, 0, 1, 0);
      } else if (listeningCamera) {
        if (listeningCamera.rigCameras && listeningCamera.rigCameras.length > 0) {
          listeningCamera = listeningCamera.rigCameras[0];
        }
        listeningCamera.getViewMatrix().invertToRef(this._invertMatrixTemp);
        Vector3.TransformNormalToRef(_AudioSceneComponent._CameraDirection, this._invertMatrixTemp, this._cameraDirectionTemp);
        this._cameraDirectionTemp.normalize();
        if (!isNaN(this._cameraDirectionTemp.x) && !isNaN(this._cameraDirectionTemp.y) && !isNaN(this._cameraDirectionTemp.z)) {
          if (!this._cachedCameraDirection.equals(this._cameraDirectionTemp)) {
            this._cachedCameraDirection.copyFrom(this._cameraDirectionTemp);
            audioEngine.audioContext.listener.setOrientation(this._cameraDirectionTemp.x, this._cameraDirectionTemp.y, this._cameraDirectionTemp.z, 0, 1, 0);
          }
        }
      } else {
        audioEngine.audioContext.listener.setOrientation(0, 0, 0, 0, 1, 0);
      }
      let i;
      for (i = 0; i < scene.mainSoundTrack.soundCollection.length; i++) {
        const sound = scene.mainSoundTrack.soundCollection[i];
        if (sound.useCustomAttenuation) {
          sound.updateDistanceFromListener();
        }
      }
      if (scene.soundTracks) {
        for (i = 0; i < scene.soundTracks.length; i++) {
          for (let j = 0; j < scene.soundTracks[i].soundCollection.length; j++) {
            const sound = scene.soundTracks[i].soundCollection[j];
            if (sound.useCustomAttenuation) {
              sound.updateDistanceFromListener();
            }
          }
        }
      }
    }
  }
};
AudioSceneComponent._CameraDirection = new Vector3(0, 0, -1);
Sound._SceneComponentInitialization = (scene) => {
  let compo = scene._getComponent(SceneComponentConstants.NAME_AUDIO);
  if (!compo) {
    compo = new AudioSceneComponent(scene);
    scene._addComponent(compo);
  }
};

// node_modules/@babylonjs/core/Audio/weightedsound.js
var WeightedSound = class {
  /**
   * Creates a new WeightedSound from the list of sounds given.
   * @param loop When true a Sound will be selected and played when the current playing Sound completes.
   * @param sounds Array of Sounds that will be selected from.
   * @param weights Array of number values for selection weights; length must equal sounds, values will be normalized to 1
   */
  constructor(loop, sounds, weights) {
    this.loop = false;
    this._coneInnerAngle = 360;
    this._coneOuterAngle = 360;
    this._volume = 1;
    this.isPlaying = false;
    this.isPaused = false;
    this._sounds = [];
    this._weights = [];
    if (sounds.length !== weights.length) {
      throw new Error("Sounds length does not equal weights length");
    }
    this.loop = loop;
    this._weights = weights;
    let weightSum = 0;
    for (const weight of weights) {
      weightSum += weight;
    }
    const invWeightSum = weightSum > 0 ? 1 / weightSum : 0;
    for (let i = 0; i < this._weights.length; i++) {
      this._weights[i] *= invWeightSum;
    }
    this._sounds = sounds;
    for (const sound of this._sounds) {
      sound.onEndedObservable.add(() => {
        this._onended();
      });
    }
  }
  /**
   * The size of cone in degrees for a directional sound in which there will be no attenuation.
   */
  get directionalConeInnerAngle() {
    return this._coneInnerAngle;
  }
  /**
   * The size of cone in degrees for a directional sound in which there will be no attenuation.
   */
  set directionalConeInnerAngle(value) {
    if (value !== this._coneInnerAngle) {
      if (this._coneOuterAngle < value) {
        Logger.Error("directionalConeInnerAngle: outer angle of the cone must be superior or equal to the inner angle.");
        return;
      }
      this._coneInnerAngle = value;
      for (const sound of this._sounds) {
        sound.directionalConeInnerAngle = value;
      }
    }
  }
  /**
   * Size of cone in degrees for a directional sound outside of which there will be no sound.
   * Listener angles between innerAngle and outerAngle will falloff linearly.
   */
  get directionalConeOuterAngle() {
    return this._coneOuterAngle;
  }
  /**
   * Size of cone in degrees for a directional sound outside of which there will be no sound.
   * Listener angles between innerAngle and outerAngle will falloff linearly.
   */
  set directionalConeOuterAngle(value) {
    if (value !== this._coneOuterAngle) {
      if (value < this._coneInnerAngle) {
        Logger.Error("directionalConeOuterAngle: outer angle of the cone must be superior or equal to the inner angle.");
        return;
      }
      this._coneOuterAngle = value;
      for (const sound of this._sounds) {
        sound.directionalConeOuterAngle = value;
      }
    }
  }
  /**
   * Playback volume.
   */
  get volume() {
    return this._volume;
  }
  /**
   * Playback volume.
   */
  set volume(value) {
    if (value !== this._volume) {
      for (const sound of this._sounds) {
        sound.setVolume(value);
      }
    }
  }
  _onended() {
    if (this._currentIndex !== void 0) {
      this._sounds[this._currentIndex].autoplay = false;
    }
    if (this.loop && this.isPlaying) {
      this.play();
    } else {
      this.isPlaying = false;
    }
  }
  /**
   * Suspend playback
   */
  pause() {
    if (this.isPlaying) {
      this.isPaused = true;
      if (this._currentIndex !== void 0) {
        this._sounds[this._currentIndex].pause();
      }
    }
  }
  /**
   * Stop playback
   */
  stop() {
    this.isPlaying = false;
    if (this._currentIndex !== void 0) {
      this._sounds[this._currentIndex].stop();
    }
  }
  /**
   * Start playback.
   * @param startOffset Position the clip head at a specific time in seconds.
   */
  play(startOffset) {
    if (!this.isPaused) {
      this.stop();
      const randomValue = Math.random();
      let total = 0;
      for (let i = 0; i < this._weights.length; i++) {
        total += this._weights[i];
        if (randomValue <= total) {
          this._currentIndex = i;
          break;
        }
      }
    }
    const sound = this._sounds[this._currentIndex ?? 0];
    if (sound.isReady()) {
      sound.play(0, this.isPaused ? void 0 : startOffset);
    } else {
      sound.autoplay = true;
    }
    this.isPlaying = true;
    this.isPaused = false;
  }
};

// node_modules/@babylonjs/core/Bones/skeleton.js
var Skeleton = class _Skeleton {
  /**
   * Gets or sets a boolean indicating that bone matrices should be stored as a texture instead of using shader uniforms (default is true).
   * Please note that this option is not available if the hardware does not support it
   */
  get useTextureToStoreBoneMatrices() {
    return this._useTextureToStoreBoneMatrices;
  }
  set useTextureToStoreBoneMatrices(value) {
    this._useTextureToStoreBoneMatrices = value;
    this._markAsDirty();
  }
  /**
   * Gets or sets the animation properties override
   */
  get animationPropertiesOverride() {
    if (!this._animationPropertiesOverride) {
      return this._scene.animationPropertiesOverride;
    }
    return this._animationPropertiesOverride;
  }
  set animationPropertiesOverride(value) {
    this._animationPropertiesOverride = value;
  }
  /**
   * Gets a boolean indicating that the skeleton effectively stores matrices into a texture
   */
  get isUsingTextureForMatrices() {
    return this.useTextureToStoreBoneMatrices && this._canUseTextureForBones;
  }
  /**
   * Gets the unique ID of this skeleton
   */
  get uniqueId() {
    return this._uniqueId;
  }
  /**
   * Creates a new skeleton
   * @param name defines the skeleton name
   * @param id defines the skeleton Id
   * @param scene defines the hosting scene
   */
  constructor(name, id, scene) {
    this.name = name;
    this.id = id;
    this.bones = [];
    this.needInitialSkinMatrix = false;
    this._isDirty = true;
    this._meshesWithPoseMatrix = new Array();
    this._identity = Matrix.Identity();
    this._currentRenderId = -1;
    this._ranges = {};
    this._absoluteTransformIsDirty = true;
    this._canUseTextureForBones = false;
    this._uniqueId = 0;
    this._numBonesWithLinkedTransformNode = 0;
    this._hasWaitingData = null;
    this._parentContainer = null;
    this.doNotSerialize = false;
    this._useTextureToStoreBoneMatrices = true;
    this._animationPropertiesOverride = null;
    this.onBeforeComputeObservable = new Observable();
    this.metadata = null;
    this.bones = [];
    this._scene = scene || EngineStore.LastCreatedScene;
    this._uniqueId = this._scene.getUniqueId();
    this._scene.addSkeleton(this);
    this._isDirty = true;
    const engineCaps = this._scene.getEngine().getCaps();
    this._canUseTextureForBones = engineCaps.textureFloat && engineCaps.maxVertexTextureImageUnits > 0;
  }
  /**
   * Gets the current object class name.
   * @returns the class name
   */
  getClassName() {
    return "Skeleton";
  }
  /**
   * Returns an array containing the root bones
   * @returns an array containing the root bones
   */
  getChildren() {
    return this.bones.filter((b) => !b.getParent());
  }
  // Members
  /**
   * Gets the list of transform matrices to send to shaders (one matrix per bone)
   * @param mesh defines the mesh to use to get the root matrix (if needInitialSkinMatrix === true)
   * @returns a Float32Array containing matrices data
   */
  getTransformMatrices(mesh) {
    if (this.needInitialSkinMatrix) {
      if (!mesh) {
        throw new Error("getTransformMatrices: When using the needInitialSkinMatrix flag, a mesh must be provided");
      }
      if (!mesh._bonesTransformMatrices) {
        this.prepare(true);
      }
      return mesh._bonesTransformMatrices;
    }
    if (!this._transformMatrices || this._isDirty) {
      this.prepare(!this._transformMatrices);
    }
    return this._transformMatrices;
  }
  /**
   * Gets the list of transform matrices to send to shaders inside a texture (one matrix per bone)
   * @param mesh defines the mesh to use to get the root matrix (if needInitialSkinMatrix === true)
   * @returns a raw texture containing the data
   */
  getTransformMatrixTexture(mesh) {
    if (this.needInitialSkinMatrix && mesh._transformMatrixTexture) {
      return mesh._transformMatrixTexture;
    }
    return this._transformMatrixTexture;
  }
  /**
   * Gets the current hosting scene
   * @returns a scene object
   */
  getScene() {
    return this._scene;
  }
  // Methods
  /**
   * Gets a string representing the current skeleton data
   * @param fullDetails defines a boolean indicating if we want a verbose version
   * @returns a string representing the current skeleton data
   */
  toString(fullDetails) {
    let ret = `Name: ${this.name}, nBones: ${this.bones.length}`;
    ret += `, nAnimationRanges: ${this._ranges ? Object.keys(this._ranges).length : "none"}`;
    if (fullDetails) {
      ret += ", Ranges: {";
      let first = true;
      for (const name in this._ranges) {
        if (first) {
          ret += ", ";
          first = false;
        }
        ret += name;
      }
      ret += "}";
    }
    return ret;
  }
  /**
   * Get bone's index searching by name
   * @param name defines bone's name to search for
   * @returns the indice of the bone. Returns -1 if not found
   */
  getBoneIndexByName(name) {
    for (let boneIndex = 0, cache = this.bones.length; boneIndex < cache; boneIndex++) {
      if (this.bones[boneIndex].name === name) {
        return boneIndex;
      }
    }
    return -1;
  }
  /**
   * Create a new animation range
   * @param name defines the name of the range
   * @param from defines the start key
   * @param to defines the end key
   */
  createAnimationRange(name, from, to) {
    if (!this._ranges[name]) {
      this._ranges[name] = new AnimationRange(name, from, to);
      for (let i = 0, nBones = this.bones.length; i < nBones; i++) {
        if (this.bones[i].animations[0]) {
          this.bones[i].animations[0].createRange(name, from, to);
        }
      }
    }
  }
  /**
   * Delete a specific animation range
   * @param name defines the name of the range
   * @param deleteFrames defines if frames must be removed as well
   */
  deleteAnimationRange(name, deleteFrames = true) {
    for (let i = 0, nBones = this.bones.length; i < nBones; i++) {
      if (this.bones[i].animations[0]) {
        this.bones[i].animations[0].deleteRange(name, deleteFrames);
      }
    }
    this._ranges[name] = null;
  }
  /**
   * Gets a specific animation range
   * @param name defines the name of the range to look for
   * @returns the requested animation range or null if not found
   */
  getAnimationRange(name) {
    return this._ranges[name] || null;
  }
  /**
   * Gets the list of all animation ranges defined on this skeleton
   * @returns an array
   */
  getAnimationRanges() {
    const animationRanges = [];
    let name;
    for (name in this._ranges) {
      animationRanges.push(this._ranges[name]);
    }
    return animationRanges;
  }
  /**
   * Copy animation range from a source skeleton.
   * This is not for a complete retargeting, only between very similar skeleton's with only possible bone length differences
   * @param source defines the source skeleton
   * @param name defines the name of the range to copy
   * @param rescaleAsRequired defines if rescaling must be applied if required
   * @returns true if operation was successful
   */
  copyAnimationRange(source, name, rescaleAsRequired = false) {
    if (this._ranges[name] || !source.getAnimationRange(name)) {
      return false;
    }
    let ret = true;
    const frameOffset = this._getHighestAnimationFrame() + 1;
    const boneDict = {};
    const sourceBones = source.bones;
    let nBones;
    let i;
    for (i = 0, nBones = sourceBones.length; i < nBones; i++) {
      boneDict[sourceBones[i].name] = sourceBones[i];
    }
    if (this.bones.length !== sourceBones.length) {
      Logger.Warn(`copyAnimationRange: this rig has ${this.bones.length} bones, while source as ${sourceBones.length}`);
      ret = false;
    }
    const skelDimensionsRatio = rescaleAsRequired && this.dimensionsAtRest && source.dimensionsAtRest ? this.dimensionsAtRest.divide(source.dimensionsAtRest) : null;
    for (i = 0, nBones = this.bones.length; i < nBones; i++) {
      const boneName = this.bones[i].name;
      const sourceBone = boneDict[boneName];
      if (sourceBone) {
        ret = ret && this.bones[i].copyAnimationRange(sourceBone, name, frameOffset, rescaleAsRequired, skelDimensionsRatio);
      } else {
        Logger.Warn("copyAnimationRange: not same rig, missing source bone " + boneName);
        ret = false;
      }
    }
    const range = source.getAnimationRange(name);
    if (range) {
      this._ranges[name] = new AnimationRange(name, range.from + frameOffset, range.to + frameOffset);
    }
    return ret;
  }
  /**
   * Forces the skeleton to go to rest pose
   */
  returnToRest() {
    for (const bone of this.bones) {
      if (bone._index !== -1) {
        bone.returnToRest();
      }
    }
  }
  _getHighestAnimationFrame() {
    let ret = 0;
    for (let i = 0, nBones = this.bones.length; i < nBones; i++) {
      if (this.bones[i].animations[0]) {
        const highest = this.bones[i].animations[0].getHighestFrame();
        if (ret < highest) {
          ret = highest;
        }
      }
    }
    return ret;
  }
  /**
   * Begin a specific animation range
   * @param name defines the name of the range to start
   * @param loop defines if looping must be turned on (false by default)
   * @param speedRatio defines the speed ratio to apply (1 by default)
   * @param onAnimationEnd defines a callback which will be called when animation will end
   * @returns a new animatable
   */
  beginAnimation(name, loop, speedRatio, onAnimationEnd) {
    const range = this.getAnimationRange(name);
    if (!range) {
      return null;
    }
    return this._scene.beginAnimation(this, range.from, range.to, loop, speedRatio, onAnimationEnd);
  }
  /**
   * Convert the keyframes for a range of animation on a skeleton to be relative to a given reference frame.
   * @param skeleton defines the Skeleton containing the animation range to convert
   * @param referenceFrame defines the frame that keyframes in the range will be relative to
   * @param range defines the name of the AnimationRange belonging to the Skeleton to convert
   * @returns the original skeleton
   */
  static MakeAnimationAdditive(skeleton, referenceFrame = 0, range) {
    const rangeValue = skeleton.getAnimationRange(range);
    if (!rangeValue) {
      return null;
    }
    const sceneAnimatables = skeleton._scene.getAllAnimatablesByTarget(skeleton);
    let rangeAnimatable = null;
    for (let index = 0; index < sceneAnimatables.length; index++) {
      const sceneAnimatable = sceneAnimatables[index];
      if (sceneAnimatable.fromFrame === rangeValue?.from && sceneAnimatable.toFrame === rangeValue?.to) {
        rangeAnimatable = sceneAnimatable;
        break;
      }
    }
    const animatables = skeleton.getAnimatables();
    for (let index = 0; index < animatables.length; index++) {
      const animatable = animatables[index];
      const animations = animatable.animations;
      if (!animations) {
        continue;
      }
      for (let animIndex = 0; animIndex < animations.length; animIndex++) {
        Animation.MakeAnimationAdditive(animations[animIndex], referenceFrame, range);
      }
    }
    if (rangeAnimatable) {
      rangeAnimatable.isAdditive = true;
    }
    return skeleton;
  }
  /** @internal */
  _markAsDirty() {
    this._isDirty = true;
    this._absoluteTransformIsDirty = true;
  }
  /**
   * @internal
   */
  _registerMeshWithPoseMatrix(mesh) {
    this._meshesWithPoseMatrix.push(mesh);
  }
  /**
   * @internal
   */
  _unregisterMeshWithPoseMatrix(mesh) {
    const index = this._meshesWithPoseMatrix.indexOf(mesh);
    if (index > -1) {
      this._meshesWithPoseMatrix.splice(index, 1);
    }
  }
  _computeTransformMatrices(targetMatrix, initialSkinMatrix) {
    this.onBeforeComputeObservable.notifyObservers(this);
    for (let index = 0; index < this.bones.length; index++) {
      const bone = this.bones[index];
      bone._childUpdateId++;
      const parentBone = bone.getParent();
      if (parentBone) {
        bone.getLocalMatrix().multiplyToRef(parentBone.getFinalMatrix(), bone.getFinalMatrix());
      } else {
        if (initialSkinMatrix) {
          bone.getLocalMatrix().multiplyToRef(initialSkinMatrix, bone.getFinalMatrix());
        } else {
          bone.getFinalMatrix().copyFrom(bone.getLocalMatrix());
        }
      }
      if (bone._index !== -1) {
        const mappedIndex = bone._index === null ? index : bone._index;
        bone.getAbsoluteInverseBindMatrix().multiplyToArray(bone.getFinalMatrix(), targetMatrix, mappedIndex * 16);
      }
    }
    this._identity.copyToArray(targetMatrix, this.bones.length * 16);
  }
  /**
   * Build all resources required to render a skeleton
   * @param dontCheckFrameId defines a boolean indicating if prepare should be run without checking first the current frame id (default: false)
   */
  prepare(dontCheckFrameId = false) {
    if (!dontCheckFrameId) {
      const currentRenderId = this.getScene().getRenderId();
      if (this._currentRenderId === currentRenderId) {
        return;
      }
      this._currentRenderId = currentRenderId;
    }
    if (this._numBonesWithLinkedTransformNode > 0) {
      for (const bone of this.bones) {
        if (bone._linkedTransformNode) {
          const node = bone._linkedTransformNode;
          bone.position = node.position;
          if (node.rotationQuaternion) {
            bone.rotationQuaternion = node.rotationQuaternion;
          } else {
            bone.rotation = node.rotation;
          }
          bone.scaling = node.scaling;
        }
      }
    }
    if (this.needInitialSkinMatrix) {
      for (const mesh of this._meshesWithPoseMatrix) {
        const poseMatrix = mesh.getPoseMatrix();
        let needsUpdate = this._isDirty;
        if (!mesh._bonesTransformMatrices || mesh._bonesTransformMatrices.length !== 16 * (this.bones.length + 1)) {
          mesh._bonesTransformMatrices = new Float32Array(16 * (this.bones.length + 1));
          needsUpdate = true;
        }
        if (!needsUpdate) {
          continue;
        }
        if (this._synchronizedWithMesh !== mesh) {
          this._synchronizedWithMesh = mesh;
          for (const bone of this.bones) {
            if (!bone.getParent()) {
              const matrix = bone.getBindMatrix();
              matrix.multiplyToRef(poseMatrix, TmpVectors.Matrix[1]);
              bone._updateAbsoluteBindMatrices(TmpVectors.Matrix[1]);
            }
          }
          if (this.isUsingTextureForMatrices) {
            const textureWidth = (this.bones.length + 1) * 4;
            if (!mesh._transformMatrixTexture || mesh._transformMatrixTexture.getSize().width !== textureWidth) {
              if (mesh._transformMatrixTexture) {
                mesh._transformMatrixTexture.dispose();
              }
              mesh._transformMatrixTexture = RawTexture.CreateRGBATexture(mesh._bonesTransformMatrices, (this.bones.length + 1) * 4, 1, this._scene, false, false, 1, 1);
            }
          }
        }
        this._computeTransformMatrices(mesh._bonesTransformMatrices, poseMatrix);
        if (this.isUsingTextureForMatrices && mesh._transformMatrixTexture) {
          mesh._transformMatrixTexture.update(mesh._bonesTransformMatrices);
        }
      }
    } else {
      if (!this._isDirty) {
        return;
      }
      if (!this._transformMatrices || this._transformMatrices.length !== 16 * (this.bones.length + 1)) {
        this._transformMatrices = new Float32Array(16 * (this.bones.length + 1));
        if (this.isUsingTextureForMatrices) {
          if (this._transformMatrixTexture) {
            this._transformMatrixTexture.dispose();
          }
          this._transformMatrixTexture = RawTexture.CreateRGBATexture(this._transformMatrices, (this.bones.length + 1) * 4, 1, this._scene, false, false, 1, 1);
        }
      }
      this._computeTransformMatrices(this._transformMatrices, null);
      if (this.isUsingTextureForMatrices && this._transformMatrixTexture) {
        this._transformMatrixTexture.update(this._transformMatrices);
      }
    }
    this._isDirty = false;
  }
  /**
   * Gets the list of animatables currently running for this skeleton
   * @returns an array of animatables
   */
  getAnimatables() {
    if (!this._animatables || this._animatables.length !== this.bones.length) {
      this._animatables = [];
      for (let index = 0; index < this.bones.length; index++) {
        this._animatables.push(this.bones[index]);
      }
    }
    return this._animatables;
  }
  /**
   * Clone the current skeleton
   * @param name defines the name of the new skeleton
   * @param id defines the id of the new skeleton
   * @returns the new skeleton
   */
  clone(name, id) {
    const result = new _Skeleton(name, id || name, this._scene);
    result.needInitialSkinMatrix = this.needInitialSkinMatrix;
    result.metadata = this.metadata;
    for (let index = 0; index < this.bones.length; index++) {
      const source = this.bones[index];
      let parentBone = null;
      const parent = source.getParent();
      if (parent) {
        const parentIndex = this.bones.indexOf(parent);
        parentBone = result.bones[parentIndex];
      }
      const bone = new Bone(source.name, result, parentBone, source.getBindMatrix().clone(), source.getRestMatrix().clone());
      bone._index = source._index;
      if (source._linkedTransformNode) {
        bone.linkTransformNode(source._linkedTransformNode);
      }
      DeepCopier.DeepCopy(source.animations, bone.animations);
    }
    if (this._ranges) {
      result._ranges = {};
      for (const rangeName in this._ranges) {
        const range = this._ranges[rangeName];
        if (range) {
          result._ranges[rangeName] = range.clone();
        }
      }
    }
    this._isDirty = true;
    result.prepare(true);
    return result;
  }
  /**
   * Enable animation blending for this skeleton
   * @param blendingSpeed defines the blending speed to apply
   * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#animation-blending
   */
  enableBlending(blendingSpeed = 0.01) {
    for (const bone of this.bones) {
      for (const animation of bone.animations) {
        animation.enableBlending = true;
        animation.blendingSpeed = blendingSpeed;
      }
    }
  }
  /**
   * Releases all resources associated with the current skeleton
   */
  dispose() {
    this._meshesWithPoseMatrix.length = 0;
    this.metadata = null;
    this.getScene().stopAnimation(this);
    this.getScene().removeSkeleton(this);
    if (this._parentContainer) {
      const index = this._parentContainer.skeletons.indexOf(this);
      if (index > -1) {
        this._parentContainer.skeletons.splice(index, 1);
      }
      this._parentContainer = null;
    }
    if (this._transformMatrixTexture) {
      this._transformMatrixTexture.dispose();
      this._transformMatrixTexture = null;
    }
  }
  /**
   * Serialize the skeleton in a JSON object
   * @returns a JSON object
   */
  serialize() {
    const serializationObject = {};
    serializationObject.name = this.name;
    serializationObject.id = this.id;
    if (this.dimensionsAtRest) {
      serializationObject.dimensionsAtRest = this.dimensionsAtRest.asArray();
    }
    serializationObject.bones = [];
    serializationObject.needInitialSkinMatrix = this.needInitialSkinMatrix;
    if (this.metadata) {
      serializationObject.metadata = this.metadata;
    }
    for (let index = 0; index < this.bones.length; index++) {
      const bone = this.bones[index];
      const parent = bone.getParent();
      const serializedBone = {
        parentBoneIndex: parent ? this.bones.indexOf(parent) : -1,
        index: bone.getIndex(),
        name: bone.name,
        id: bone.id,
        matrix: bone.getBindMatrix().asArray(),
        rest: bone.getRestMatrix().asArray(),
        linkedTransformNodeId: bone.getTransformNode()?.id
      };
      serializationObject.bones.push(serializedBone);
      if (bone.length) {
        serializedBone.length = bone.length;
      }
      if (bone.metadata) {
        serializedBone.metadata = bone.metadata;
      }
      if (bone.animations && bone.animations.length > 0) {
        serializedBone.animation = bone.animations[0].serialize();
      }
      serializationObject.ranges = [];
      for (const name in this._ranges) {
        const source = this._ranges[name];
        if (!source) {
          continue;
        }
        const range = {};
        range.name = name;
        range.from = source.from;
        range.to = source.to;
        serializationObject.ranges.push(range);
      }
    }
    return serializationObject;
  }
  /**
   * Creates a new skeleton from serialized data
   * @param parsedSkeleton defines the serialized data
   * @param scene defines the hosting scene
   * @returns a new skeleton
   */
  static Parse(parsedSkeleton, scene) {
    const skeleton = new _Skeleton(parsedSkeleton.name, parsedSkeleton.id, scene);
    if (parsedSkeleton.dimensionsAtRest) {
      skeleton.dimensionsAtRest = Vector3.FromArray(parsedSkeleton.dimensionsAtRest);
    }
    skeleton.needInitialSkinMatrix = parsedSkeleton.needInitialSkinMatrix;
    if (parsedSkeleton.metadata) {
      skeleton.metadata = parsedSkeleton.metadata;
    }
    let index;
    for (index = 0; index < parsedSkeleton.bones.length; index++) {
      const parsedBone = parsedSkeleton.bones[index];
      const parsedBoneIndex = parsedSkeleton.bones[index].index;
      let parentBone = null;
      if (parsedBone.parentBoneIndex > -1) {
        parentBone = skeleton.bones[parsedBone.parentBoneIndex];
      }
      const rest = parsedBone.rest ? Matrix.FromArray(parsedBone.rest) : null;
      const bone = new Bone(parsedBone.name, skeleton, parentBone, Matrix.FromArray(parsedBone.matrix), rest, null, parsedBoneIndex);
      if (parsedBone.id !== void 0 && parsedBone.id !== null) {
        bone.id = parsedBone.id;
      }
      if (parsedBone.length) {
        bone.length = parsedBone.length;
      }
      if (parsedBone.metadata) {
        bone.metadata = parsedBone.metadata;
      }
      if (parsedBone.animation) {
        bone.animations.push(Animation.Parse(parsedBone.animation));
      }
      if (parsedBone.linkedTransformNodeId !== void 0 && parsedBone.linkedTransformNodeId !== null) {
        skeleton._hasWaitingData = true;
        bone._waitingTransformNodeId = parsedBone.linkedTransformNodeId;
      }
    }
    if (parsedSkeleton.ranges) {
      for (index = 0; index < parsedSkeleton.ranges.length; index++) {
        const data = parsedSkeleton.ranges[index];
        skeleton.createAnimationRange(data.name, data.from, data.to);
      }
    }
    return skeleton;
  }
  /**
   * Compute all node absolute matrices
   * @param forceUpdate defines if computation must be done even if cache is up to date
   */
  computeAbsoluteMatrices(forceUpdate = false) {
    if (this._absoluteTransformIsDirty || forceUpdate) {
      this.bones[0].computeAbsoluteMatrices();
      this._absoluteTransformIsDirty = false;
    }
  }
  /**
   * Compute all node absolute matrices
   * @param forceUpdate defines if computation must be done even if cache is up to date
   * @deprecated Please use computeAbsoluteMatrices instead
   */
  computeAbsoluteTransforms(forceUpdate = false) {
    this.computeAbsoluteMatrices(forceUpdate);
  }
  /**
   * Gets the root pose matrix
   * @returns a matrix
   */
  getPoseMatrix() {
    let poseMatrix = null;
    if (this._meshesWithPoseMatrix.length > 0) {
      poseMatrix = this._meshesWithPoseMatrix[0].getPoseMatrix();
    }
    return poseMatrix;
  }
  /**
   * Sorts bones per internal index
   */
  sortBones() {
    const bones = [];
    const visited = new Array(this.bones.length);
    for (let index = 0; index < this.bones.length; index++) {
      this._sortBones(index, bones, visited);
    }
    this.bones = bones;
  }
  _sortBones(index, bones, visited) {
    if (visited[index]) {
      return;
    }
    visited[index] = true;
    const bone = this.bones[index];
    if (!bone) {
      return;
    }
    if (bone._index === void 0) {
      bone._index = index;
    }
    const parentBone = bone.getParent();
    if (parentBone) {
      this._sortBones(this.bones.indexOf(parentBone), bones, visited);
    }
    bones.push(bone);
  }
  /**
   * Set the current local matrix as the restPose for all bones in the skeleton.
   */
  setCurrentPoseAsRest() {
    for (const b of this.bones) {
      b.setCurrentPoseAsRest();
    }
  }
};

// node_modules/@babylonjs/core/Culling/ray.core.js
var PickingCustomization = {
  internalPickerForMesh: void 0
};
var Ray = class _Ray {
  /**
   * Creates a new ray
   * @param origin origin point
   * @param direction direction
   * @param length length of the ray
   * @param epsilon The epsilon value to use when calculating the ray/triangle intersection (default: Epsilon from math constants)
   */
  constructor(origin, direction, length = Number.MAX_VALUE, epsilon = Epsilon) {
    this.origin = origin;
    this.direction = direction;
    this.length = length;
    this.epsilon = epsilon;
  }
  // Methods
  /**
   * Clone the current ray
   * @returns a new ray
   */
  clone() {
    return new _Ray(this.origin.clone(), this.direction.clone(), this.length);
  }
  /**
   * Checks if the ray intersects a box
   * This does not account for the ray length by design to improve perfs.
   * @param minimum bound of the box
   * @param maximum bound of the box
   * @param intersectionTreshold extra extend to be added to the box in all direction
   * @returns if the box was hit
   */
  intersectsBoxMinMax(minimum, maximum, intersectionTreshold = 0) {
    const newMinimum = _Ray._TmpVector3[0].copyFromFloats(minimum.x - intersectionTreshold, minimum.y - intersectionTreshold, minimum.z - intersectionTreshold);
    const newMaximum = _Ray._TmpVector3[1].copyFromFloats(maximum.x + intersectionTreshold, maximum.y + intersectionTreshold, maximum.z + intersectionTreshold);
    let d = 0;
    let maxValue = Number.MAX_VALUE;
    let inv;
    let min;
    let max;
    let temp;
    if (Math.abs(this.direction.x) < 1e-7) {
      if (this.origin.x < newMinimum.x || this.origin.x > newMaximum.x) {
        return false;
      }
    } else {
      inv = 1 / this.direction.x;
      min = (newMinimum.x - this.origin.x) * inv;
      max = (newMaximum.x - this.origin.x) * inv;
      if (max === -Infinity) {
        max = Infinity;
      }
      if (min > max) {
        temp = min;
        min = max;
        max = temp;
      }
      d = Math.max(min, d);
      maxValue = Math.min(max, maxValue);
      if (d > maxValue) {
        return false;
      }
    }
    if (Math.abs(this.direction.y) < 1e-7) {
      if (this.origin.y < newMinimum.y || this.origin.y > newMaximum.y) {
        return false;
      }
    } else {
      inv = 1 / this.direction.y;
      min = (newMinimum.y - this.origin.y) * inv;
      max = (newMaximum.y - this.origin.y) * inv;
      if (max === -Infinity) {
        max = Infinity;
      }
      if (min > max) {
        temp = min;
        min = max;
        max = temp;
      }
      d = Math.max(min, d);
      maxValue = Math.min(max, maxValue);
      if (d > maxValue) {
        return false;
      }
    }
    if (Math.abs(this.direction.z) < 1e-7) {
      if (this.origin.z < newMinimum.z || this.origin.z > newMaximum.z) {
        return false;
      }
    } else {
      inv = 1 / this.direction.z;
      min = (newMinimum.z - this.origin.z) * inv;
      max = (newMaximum.z - this.origin.z) * inv;
      if (max === -Infinity) {
        max = Infinity;
      }
      if (min > max) {
        temp = min;
        min = max;
        max = temp;
      }
      d = Math.max(min, d);
      maxValue = Math.min(max, maxValue);
      if (d > maxValue) {
        return false;
      }
    }
    return true;
  }
  /**
   * Checks if the ray intersects a box
   * This does not account for the ray length by design to improve perfs.
   * @param box the bounding box to check
   * @param intersectionTreshold extra extend to be added to the BoundingBox in all direction
   * @returns if the box was hit
   */
  intersectsBox(box, intersectionTreshold = 0) {
    return this.intersectsBoxMinMax(box.minimum, box.maximum, intersectionTreshold);
  }
  /**
   * If the ray hits a sphere
   * @param sphere the bounding sphere to check
   * @param intersectionTreshold extra extend to be added to the BoundingSphere in all direction
   * @returns true if it hits the sphere
   */
  intersectsSphere(sphere, intersectionTreshold = 0) {
    const x = sphere.center.x - this.origin.x;
    const y = sphere.center.y - this.origin.y;
    const z = sphere.center.z - this.origin.z;
    const pyth = x * x + y * y + z * z;
    const radius = sphere.radius + intersectionTreshold;
    const rr = radius * radius;
    if (pyth <= rr) {
      return true;
    }
    const dot = x * this.direction.x + y * this.direction.y + z * this.direction.z;
    if (dot < 0) {
      return false;
    }
    const temp = pyth - dot * dot;
    return temp <= rr;
  }
  /**
   * If the ray hits a triange
   * @param vertex0 triangle vertex
   * @param vertex1 triangle vertex
   * @param vertex2 triangle vertex
   * @returns intersection information if hit
   */
  intersectsTriangle(vertex0, vertex1, vertex2) {
    const edge1 = _Ray._TmpVector3[0];
    const edge2 = _Ray._TmpVector3[1];
    const pvec = _Ray._TmpVector3[2];
    const tvec = _Ray._TmpVector3[3];
    const qvec = _Ray._TmpVector3[4];
    vertex1.subtractToRef(vertex0, edge1);
    vertex2.subtractToRef(vertex0, edge2);
    Vector3.CrossToRef(this.direction, edge2, pvec);
    const det = Vector3.Dot(edge1, pvec);
    if (det === 0) {
      return null;
    }
    const invdet = 1 / det;
    this.origin.subtractToRef(vertex0, tvec);
    const bv = Vector3.Dot(tvec, pvec) * invdet;
    if (bv < -this.epsilon || bv > 1 + this.epsilon) {
      return null;
    }
    Vector3.CrossToRef(tvec, edge1, qvec);
    const bw = Vector3.Dot(this.direction, qvec) * invdet;
    if (bw < -this.epsilon || bv + bw > 1 + this.epsilon) {
      return null;
    }
    const distance = Vector3.Dot(edge2, qvec) * invdet;
    if (distance > this.length) {
      return null;
    }
    return new IntersectionInfo(1 - bv - bw, bv, distance);
  }
  /**
   * Checks if ray intersects a plane
   * @param plane the plane to check
   * @returns the distance away it was hit
   */
  intersectsPlane(plane) {
    let distance;
    const result1 = Vector3.Dot(plane.normal, this.direction);
    if (Math.abs(result1) < 999999997475243e-21) {
      return null;
    } else {
      const result2 = Vector3.Dot(plane.normal, this.origin);
      distance = (-plane.d - result2) / result1;
      if (distance < 0) {
        if (distance < -999999997475243e-21) {
          return null;
        } else {
          return 0;
        }
      }
      return distance;
    }
  }
  /**
   * Calculate the intercept of a ray on a given axis
   * @param axis to check 'x' | 'y' | 'z'
   * @param offset from axis interception (i.e. an offset of 1y is intercepted above ground)
   * @returns a vector containing the coordinates where 'axis' is equal to zero (else offset), or null if there is no intercept.
   */
  intersectsAxis(axis, offset = 0) {
    switch (axis) {
      case "y": {
        const t = (this.origin.y - offset) / this.direction.y;
        if (t > 0) {
          return null;
        }
        return new Vector3(this.origin.x + this.direction.x * -t, offset, this.origin.z + this.direction.z * -t);
      }
      case "x": {
        const t = (this.origin.x - offset) / this.direction.x;
        if (t > 0) {
          return null;
        }
        return new Vector3(offset, this.origin.y + this.direction.y * -t, this.origin.z + this.direction.z * -t);
      }
      case "z": {
        const t = (this.origin.z - offset) / this.direction.z;
        if (t > 0) {
          return null;
        }
        return new Vector3(this.origin.x + this.direction.x * -t, this.origin.y + this.direction.y * -t, offset);
      }
      default:
        return null;
    }
  }
  /**
   * Checks if ray intersects a mesh. The ray is defined in WORLD space. A mesh triangle can be picked both from its front and back sides,
   * irrespective of orientation.
   * @param mesh the mesh to check
   * @param fastCheck defines if the first intersection will be used (and not the closest)
   * @param trianglePredicate defines an optional predicate used to select faces when a mesh intersection is detected
   * @param onlyBoundingInfo defines a boolean indicating if picking should only happen using bounding info (false by default)
   * @param worldToUse defines the world matrix to use to get the world coordinate of the intersection point
   * @param skipBoundingInfo a boolean indicating if we should skip the bounding info check
   * @returns picking info of the intersection
   */
  intersectsMesh(mesh, fastCheck, trianglePredicate, onlyBoundingInfo = false, worldToUse, skipBoundingInfo = false) {
    const tm = TmpVectors.Matrix[0];
    mesh.getWorldMatrix().invertToRef(tm);
    if (this._tmpRay) {
      _Ray.TransformToRef(this, tm, this._tmpRay);
    } else {
      this._tmpRay = _Ray.Transform(this, tm);
    }
    return mesh.intersects(this._tmpRay, fastCheck, trianglePredicate, onlyBoundingInfo, worldToUse, skipBoundingInfo);
  }
  /**
   * Checks if ray intersects a mesh
   * @param meshes the meshes to check
   * @param fastCheck defines if the first intersection will be used (and not the closest)
   * @param results array to store result in
   * @returns Array of picking infos
   */
  intersectsMeshes(meshes, fastCheck, results) {
    if (results) {
      results.length = 0;
    } else {
      results = [];
    }
    for (let i = 0; i < meshes.length; i++) {
      const pickInfo = this.intersectsMesh(meshes[i], fastCheck);
      if (pickInfo.hit) {
        results.push(pickInfo);
      }
    }
    results.sort(this._comparePickingInfo);
    return results;
  }
  _comparePickingInfo(pickingInfoA, pickingInfoB) {
    if (pickingInfoA.distance < pickingInfoB.distance) {
      return -1;
    } else if (pickingInfoA.distance > pickingInfoB.distance) {
      return 1;
    } else {
      return 0;
    }
  }
  /**
   * Intersection test between the ray and a given segment within a given tolerance (threshold)
   * @param sega the first point of the segment to test the intersection against
   * @param segb the second point of the segment to test the intersection against
   * @param threshold the tolerance margin, if the ray doesn't intersect the segment but is close to the given threshold, the intersection is successful
   * @returns the distance from the ray origin to the intersection point if there's intersection, or -1 if there's no intersection
   */
  intersectionSegment(sega, segb, threshold) {
    const o = this.origin;
    const u = TmpVectors.Vector3[0];
    const rsegb = TmpVectors.Vector3[1];
    const v = TmpVectors.Vector3[2];
    const w = TmpVectors.Vector3[3];
    segb.subtractToRef(sega, u);
    this.direction.scaleToRef(_Ray._Rayl, v);
    o.addToRef(v, rsegb);
    sega.subtractToRef(o, w);
    const a = Vector3.Dot(u, u);
    const b = Vector3.Dot(u, v);
    const c = Vector3.Dot(v, v);
    const d = Vector3.Dot(u, w);
    const e = Vector3.Dot(v, w);
    const discriminant = a * c - b * b;
    let sN, sD = discriminant;
    let tN, tD = discriminant;
    if (discriminant < _Ray._Smallnum) {
      sN = 0;
      sD = 1;
      tN = e;
      tD = c;
    } else {
      sN = b * e - c * d;
      tN = a * e - b * d;
      if (sN < 0) {
        sN = 0;
        tN = e;
        tD = c;
      } else if (sN > sD) {
        sN = sD;
        tN = e + b;
        tD = c;
      }
    }
    if (tN < 0) {
      tN = 0;
      if (-d < 0) {
        sN = 0;
      } else if (-d > a) {
        sN = sD;
      } else {
        sN = -d;
        sD = a;
      }
    } else if (tN > tD) {
      tN = tD;
      if (-d + b < 0) {
        sN = 0;
      } else if (-d + b > a) {
        sN = sD;
      } else {
        sN = -d + b;
        sD = a;
      }
    }
    const sc = Math.abs(sN) < _Ray._Smallnum ? 0 : sN / sD;
    const tc = Math.abs(tN) < _Ray._Smallnum ? 0 : tN / tD;
    const qtc = TmpVectors.Vector3[4];
    v.scaleToRef(tc, qtc);
    const qsc = TmpVectors.Vector3[5];
    u.scaleToRef(sc, qsc);
    qsc.addInPlace(w);
    const dP = TmpVectors.Vector3[6];
    qsc.subtractToRef(qtc, dP);
    const isIntersected = tc > 0 && tc <= this.length && dP.lengthSquared() < threshold * threshold;
    if (isIntersected) {
      return qsc.length();
    }
    return -1;
  }
  /**
   * Update the ray from viewport position
   * @param x position
   * @param y y position
   * @param viewportWidth viewport width
   * @param viewportHeight viewport height
   * @param world world matrix
   * @param view view matrix
   * @param projection projection matrix
   * @param enableDistantPicking defines if picking should handle large values for mesh position/scaling (false by default)
   * @returns this ray updated
   */
  update(x, y, viewportWidth, viewportHeight, world, view, projection, enableDistantPicking = false) {
    if (enableDistantPicking) {
      if (!_Ray._RayDistant) {
        _Ray._RayDistant = _Ray.Zero();
      }
      _Ray._RayDistant.unprojectRayToRef(x, y, viewportWidth, viewportHeight, Matrix.IdentityReadOnly, view, projection);
      const tm = TmpVectors.Matrix[0];
      world.invertToRef(tm);
      _Ray.TransformToRef(_Ray._RayDistant, tm, this);
    } else {
      this.unprojectRayToRef(x, y, viewportWidth, viewportHeight, world, view, projection);
    }
    return this;
  }
  // Statics
  /**
   * Creates a ray with origin and direction of 0,0,0
   * @returns the new ray
   */
  static Zero() {
    return new _Ray(Vector3.Zero(), Vector3.Zero());
  }
  /**
   * Creates a new ray from screen space and viewport
   * @param x position
   * @param y y position
   * @param viewportWidth viewport width
   * @param viewportHeight viewport height
   * @param world world matrix
   * @param view view matrix
   * @param projection projection matrix
   * @returns new ray
   */
  static CreateNew(x, y, viewportWidth, viewportHeight, world, view, projection) {
    const result = _Ray.Zero();
    return result.update(x, y, viewportWidth, viewportHeight, world, view, projection);
  }
  /**
   * Function will create a new transformed ray starting from origin and ending at the end point. Ray's length will be set, and ray will be
   * transformed to the given world matrix.
   * @param origin The origin point
   * @param end The end point
   * @param world a matrix to transform the ray to. Default is the identity matrix.
   * @returns the new ray
   */
  static CreateNewFromTo(origin, end, world = Matrix.IdentityReadOnly) {
    const result = new _Ray(new Vector3(0, 0, 0), new Vector3(0, 0, 0));
    return _Ray.CreateFromToToRef(origin, end, result, world);
  }
  /**
   * Function will update a transformed ray starting from origin and ending at the end point. Ray's length will be set, and ray will be
   * transformed to the given world matrix.
   * @param origin The origin point
   * @param end The end point
   * @param result the object to store the result
   * @param world a matrix to transform the ray to. Default is the identity matrix.
   * @returns the ref ray
   */
  static CreateFromToToRef(origin, end, result, world = Matrix.IdentityReadOnly) {
    result.origin.copyFrom(origin);
    const direction = end.subtractToRef(origin, result.direction);
    const length = Math.sqrt(direction.x * direction.x + direction.y * direction.y + direction.z * direction.z);
    result.length = length;
    result.direction.normalize();
    return _Ray.TransformToRef(result, world, result);
  }
  /**
   * Transforms a ray by a matrix
   * @param ray ray to transform
   * @param matrix matrix to apply
   * @returns the resulting new ray
   */
  static Transform(ray, matrix) {
    const result = new _Ray(new Vector3(0, 0, 0), new Vector3(0, 0, 0));
    _Ray.TransformToRef(ray, matrix, result);
    return result;
  }
  /**
   * Transforms a ray by a matrix
   * @param ray ray to transform
   * @param matrix matrix to apply
   * @param result ray to store result in
   * @returns the updated result ray
   */
  static TransformToRef(ray, matrix, result) {
    Vector3.TransformCoordinatesToRef(ray.origin, matrix, result.origin);
    Vector3.TransformNormalToRef(ray.direction, matrix, result.direction);
    result.length = ray.length;
    result.epsilon = ray.epsilon;
    const dir = result.direction;
    const len = dir.length();
    if (!(len === 0 || len === 1)) {
      const num = 1 / len;
      dir.x *= num;
      dir.y *= num;
      dir.z *= num;
      result.length *= len;
    }
    return result;
  }
  /**
   * Unproject a ray from screen space to object space
   * @param sourceX defines the screen space x coordinate to use
   * @param sourceY defines the screen space y coordinate to use
   * @param viewportWidth defines the current width of the viewport
   * @param viewportHeight defines the current height of the viewport
   * @param world defines the world matrix to use (can be set to Identity to go to world space)
   * @param view defines the view matrix to use
   * @param projection defines the projection matrix to use
   */
  unprojectRayToRef(sourceX, sourceY, viewportWidth, viewportHeight, world, view, projection) {
    const matrix = TmpVectors.Matrix[0];
    world.multiplyToRef(view, matrix);
    matrix.multiplyToRef(projection, matrix);
    matrix.invert();
    const engine = EngineStore.LastCreatedEngine;
    const nearScreenSource = TmpVectors.Vector3[0];
    nearScreenSource.x = sourceX / viewportWidth * 2 - 1;
    nearScreenSource.y = -(sourceY / viewportHeight * 2 - 1);
    nearScreenSource.z = engine?.useReverseDepthBuffer ? 1 : engine?.isNDCHalfZRange ? 0 : -1;
    const farScreenSource = TmpVectors.Vector3[1].copyFromFloats(nearScreenSource.x, nearScreenSource.y, 1 - 1e-8);
    const nearVec3 = TmpVectors.Vector3[2];
    const farVec3 = TmpVectors.Vector3[3];
    Vector3.TransformCoordinatesToRef(nearScreenSource, matrix, nearVec3);
    Vector3.TransformCoordinatesToRef(farScreenSource, matrix, farVec3);
    this.origin.copyFrom(nearVec3);
    farVec3.subtractToRef(nearVec3, this.direction);
    this.direction.normalize();
  }
};
Ray._TmpVector3 = BuildArray(6, Vector3.Zero);
Ray._RayDistant = Ray.Zero();
Ray._Smallnum = 1e-8;
Ray._Rayl = 1e9;
function CreatePickingRay(scene, x, y, world, camera, cameraViewSpace = false) {
  const result = Ray.Zero();
  CreatePickingRayToRef(scene, x, y, world, result, camera, cameraViewSpace);
  return result;
}
function CreatePickingRayToRef(scene, x, y, world, result, camera, cameraViewSpace = false, enableDistantPicking = false) {
  const engine = scene.getEngine();
  if (!camera && !(camera = scene.activeCamera)) {
    return scene;
  }
  const cameraViewport = camera.viewport;
  const renderHeight = engine.getRenderHeight();
  const { x: vx, y: vy, width, height } = cameraViewport.toGlobal(engine.getRenderWidth(), renderHeight);
  const levelInv = 1 / engine.getHardwareScalingLevel();
  x = x * levelInv - vx;
  y = y * levelInv - (renderHeight - vy - height);
  result.update(x, y, width, height, world ? world : Matrix.IdentityReadOnly, cameraViewSpace ? Matrix.IdentityReadOnly : camera.getViewMatrix(), camera.getProjectionMatrix(), enableDistantPicking);
  return scene;
}
function CreatePickingRayInCameraSpace(scene, x, y, camera) {
  const result = Ray.Zero();
  CreatePickingRayInCameraSpaceToRef(scene, x, y, result, camera);
  return result;
}
function CreatePickingRayInCameraSpaceToRef(scene, x, y, result, camera) {
  if (!PickingInfo) {
    return scene;
  }
  const engine = scene.getEngine();
  if (!camera && !(camera = scene.activeCamera)) {
    throw new Error("Active camera not set");
  }
  const cameraViewport = camera.viewport;
  const renderHeight = engine.getRenderHeight();
  const { x: vx, y: vy, width, height } = cameraViewport.toGlobal(engine.getRenderWidth(), renderHeight);
  const identity = Matrix.Identity();
  const levelInv = 1 / engine.getHardwareScalingLevel();
  x = x * levelInv - vx;
  y = y * levelInv - (renderHeight - vy - height);
  result.update(x, y, width, height, identity, identity, camera.getProjectionMatrix());
  return scene;
}
function InternalPickForMesh(pickingInfo, rayFunction, mesh, world, fastCheck, onlyBoundingInfo, trianglePredicate, skipBoundingInfo) {
  const ray = rayFunction(world, mesh.enableDistantPicking);
  const result = mesh.intersects(ray, fastCheck, trianglePredicate, onlyBoundingInfo, world, skipBoundingInfo);
  if (!result || !result.hit) {
    return null;
  }
  if (!fastCheck && pickingInfo != null && result.distance >= pickingInfo.distance) {
    return null;
  }
  return result;
}
function InternalPick(scene, rayFunction, predicate, fastCheck, onlyBoundingInfo, trianglePredicate) {
  let pickingInfo = null;
  const computeWorldMatrixForCamera = !!(scene.activeCameras && scene.activeCameras.length > 1 && scene.cameraToUseForPointers !== scene.activeCamera);
  const currentCamera = scene.cameraToUseForPointers || scene.activeCamera;
  const picker = PickingCustomization.internalPickerForMesh || InternalPickForMesh;
  for (let meshIndex = 0; meshIndex < scene.meshes.length; meshIndex++) {
    const mesh = scene.meshes[meshIndex];
    if (predicate) {
      if (!predicate(mesh, -1)) {
        continue;
      }
    } else if (!mesh.isEnabled() || !mesh.isVisible || !mesh.isPickable) {
      continue;
    }
    const forceCompute = computeWorldMatrixForCamera && mesh.isWorldMatrixCameraDependent();
    const world = mesh.computeWorldMatrix(forceCompute, currentCamera);
    if (mesh.hasThinInstances && mesh.thinInstanceEnablePicking) {
      const result = picker(pickingInfo, rayFunction, mesh, world, true, true, trianglePredicate);
      if (result) {
        if (onlyBoundingInfo) {
          return result;
        }
        const tmpMatrix = TmpVectors.Matrix[1];
        const thinMatrices = mesh.thinInstanceGetWorldMatrices();
        for (let index = 0; index < thinMatrices.length; index++) {
          if (predicate && !predicate(mesh, index)) {
            continue;
          }
          const thinMatrix = thinMatrices[index];
          thinMatrix.multiplyToRef(world, tmpMatrix);
          const result2 = picker(pickingInfo, rayFunction, mesh, tmpMatrix, fastCheck, onlyBoundingInfo, trianglePredicate, true);
          if (result2) {
            pickingInfo = result2;
            pickingInfo.thinInstanceIndex = index;
            if (fastCheck) {
              return pickingInfo;
            }
          }
        }
      }
    } else {
      const result = picker(pickingInfo, rayFunction, mesh, world, fastCheck, onlyBoundingInfo, trianglePredicate);
      if (result) {
        pickingInfo = result;
        if (fastCheck) {
          return pickingInfo;
        }
      }
    }
  }
  return pickingInfo || new PickingInfo();
}
function InternalMultiPick(scene, rayFunction, predicate, trianglePredicate) {
  if (!PickingInfo) {
    return null;
  }
  const pickingInfos = [];
  const computeWorldMatrixForCamera = !!(scene.activeCameras && scene.activeCameras.length > 1 && scene.cameraToUseForPointers !== scene.activeCamera);
  const currentCamera = scene.cameraToUseForPointers || scene.activeCamera;
  const picker = PickingCustomization.internalPickerForMesh || InternalPickForMesh;
  for (let meshIndex = 0; meshIndex < scene.meshes.length; meshIndex++) {
    const mesh = scene.meshes[meshIndex];
    if (predicate) {
      if (!predicate(mesh, -1)) {
        continue;
      }
    } else if (!mesh.isEnabled() || !mesh.isVisible || !mesh.isPickable) {
      continue;
    }
    const forceCompute = computeWorldMatrixForCamera && mesh.isWorldMatrixCameraDependent();
    const world = mesh.computeWorldMatrix(forceCompute, currentCamera);
    if (mesh.hasThinInstances && mesh.thinInstanceEnablePicking) {
      const result = picker(null, rayFunction, mesh, world, true, true, trianglePredicate);
      if (result) {
        const tmpMatrix = TmpVectors.Matrix[1];
        const thinMatrices = mesh.thinInstanceGetWorldMatrices();
        for (let index = 0; index < thinMatrices.length; index++) {
          if (predicate && !predicate(mesh, index)) {
            continue;
          }
          const thinMatrix = thinMatrices[index];
          thinMatrix.multiplyToRef(world, tmpMatrix);
          const result2 = picker(null, rayFunction, mesh, tmpMatrix, false, false, trianglePredicate, true);
          if (result2) {
            result2.thinInstanceIndex = index;
            pickingInfos.push(result2);
          }
        }
      }
    } else {
      const result = picker(null, rayFunction, mesh, world, false, false, trianglePredicate);
      if (result) {
        pickingInfos.push(result);
      }
    }
  }
  return pickingInfos;
}
function PickWithBoundingInfo(scene, x, y, predicate, fastCheck, camera) {
  if (!PickingInfo) {
    return null;
  }
  const result = InternalPick(scene, (world) => {
    if (!scene._tempPickingRay) {
      scene._tempPickingRay = Ray.Zero();
    }
    CreatePickingRayToRef(scene, x, y, world, scene._tempPickingRay, camera || null);
    return scene._tempPickingRay;
  }, predicate, fastCheck, true);
  if (result) {
    result.ray = CreatePickingRay(scene, x, y, Matrix.Identity(), camera || null);
  }
  return result;
}
function Pick(scene, x, y, predicate, fastCheck, camera, trianglePredicate, _enableDistantPicking = false) {
  const result = InternalPick(scene, (world, enableDistantPicking) => {
    if (!scene._tempPickingRay) {
      scene._tempPickingRay = Ray.Zero();
    }
    CreatePickingRayToRef(scene, x, y, world, scene._tempPickingRay, camera || null, false, enableDistantPicking);
    return scene._tempPickingRay;
  }, predicate, fastCheck, false, trianglePredicate);
  if (result) {
    result.ray = CreatePickingRay(scene, x, y, Matrix.Identity(), camera || null);
  }
  return result;
}
function PickWithRay(scene, ray, predicate, fastCheck, trianglePredicate) {
  const result = InternalPick(scene, (world) => {
    if (!scene._pickWithRayInverseMatrix) {
      scene._pickWithRayInverseMatrix = Matrix.Identity();
    }
    world.invertToRef(scene._pickWithRayInverseMatrix);
    if (!scene._cachedRayForTransform) {
      scene._cachedRayForTransform = Ray.Zero();
    }
    Ray.TransformToRef(ray, scene._pickWithRayInverseMatrix, scene._cachedRayForTransform);
    return scene._cachedRayForTransform;
  }, predicate, fastCheck, false, trianglePredicate);
  if (result) {
    result.ray = ray;
  }
  return result;
}
function MultiPick(scene, x, y, predicate, camera, trianglePredicate) {
  return InternalMultiPick(scene, (world) => CreatePickingRay(scene, x, y, world, camera || null), predicate, trianglePredicate);
}
function MultiPickWithRay(scene, ray, predicate, trianglePredicate) {
  return InternalMultiPick(scene, (world) => {
    if (!scene._pickWithRayInverseMatrix) {
      scene._pickWithRayInverseMatrix = Matrix.Identity();
    }
    world.invertToRef(scene._pickWithRayInverseMatrix);
    if (!scene._cachedRayForTransform) {
      scene._cachedRayForTransform = Ray.Zero();
    }
    Ray.TransformToRef(ray, scene._pickWithRayInverseMatrix, scene._cachedRayForTransform);
    return scene._cachedRayForTransform;
  }, predicate, trianglePredicate);
}
function GetForwardRay(camera, length = 100, transform, origin) {
  return GetForwardRayToRef(camera, new Ray(Vector3.Zero(), Vector3.Zero(), length), length, transform, origin);
}
function GetForwardRayToRef(camera, refRay, length = 100, transform, origin) {
  if (!transform) {
    transform = camera.getWorldMatrix();
  }
  refRay.length = length;
  if (origin) {
    refRay.origin.copyFrom(origin);
  } else {
    refRay.origin.copyFrom(camera.position);
  }
  const forward = TmpVectors.Vector3[2];
  forward.set(0, 0, camera._scene.useRightHandedSystem ? -1 : 1);
  const worldForward = TmpVectors.Vector3[3];
  Vector3.TransformNormalToRef(forward, transform, worldForward);
  Vector3.NormalizeToRef(worldForward, refRay.direction);
  return refRay;
}
function AddRayExtensions(sceneClass, cameraClass) {
  if (cameraClass) {
    cameraClass.prototype.getForwardRay = function(length = 100, transform, origin) {
      return GetForwardRayToRef(this, new Ray(Vector3.Zero(), Vector3.Zero(), length), length, transform, origin);
    };
    cameraClass.prototype.getForwardRayToRef = function(refRay, length = 100, transform, origin) {
      return GetForwardRayToRef(this, refRay, length, transform, origin);
    };
  }
  if (!sceneClass) {
    return;
  }
  _ImportHelper._IsPickingAvailable = true;
  sceneClass.prototype.createPickingRay = function(x, y, world, camera, cameraViewSpace = false) {
    return CreatePickingRay(this, x, y, world, camera, cameraViewSpace);
  };
}

// node_modules/@babylonjs/core/Cameras/Inputs/BaseCameraMouseWheelInput.js
var BaseCameraMouseWheelInput = class {
  constructor() {
    this.wheelPrecisionX = 3;
    this.wheelPrecisionY = 3;
    this.wheelPrecisionZ = 3;
    this.onChangedObservable = new Observable();
    this._wheelDeltaX = 0;
    this._wheelDeltaY = 0;
    this._wheelDeltaZ = 0;
    this._ffMultiplier = 12;
    this._normalize = 120;
  }
  /**
   * Attach the input controls to a specific dom element to get the input from.
   * @param noPreventDefault Defines whether event caught by the controls
   *   should call preventdefault().
   *   (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
   */
  attachControl(noPreventDefault) {
    noPreventDefault = Tools.BackCompatCameraNoPreventDefault(arguments);
    this._wheel = (pointer) => {
      if (pointer.type !== PointerEventTypes.POINTERWHEEL) {
        return;
      }
      const event = pointer.event;
      const platformScale = event.deltaMode === EventConstants.DOM_DELTA_LINE ? this._ffMultiplier : 1;
      this._wheelDeltaX += this.wheelPrecisionX * platformScale * event.deltaX / this._normalize;
      this._wheelDeltaY -= this.wheelPrecisionY * platformScale * event.deltaY / this._normalize;
      this._wheelDeltaZ += this.wheelPrecisionZ * platformScale * event.deltaZ / this._normalize;
      if (event.preventDefault) {
        if (!noPreventDefault) {
          event.preventDefault();
        }
      }
    };
    this._observer = this.camera.getScene()._inputManager._addCameraPointerObserver(this._wheel, PointerEventTypes.POINTERWHEEL);
  }
  /**
   * Detach the current controls from the specified dom element.
   */
  detachControl() {
    if (this._observer) {
      this.camera.getScene()._inputManager._removeCameraPointerObserver(this._observer);
      this._observer = null;
      this._wheel = null;
    }
    if (this.onChangedObservable) {
      this.onChangedObservable.clear();
    }
  }
  /**
   * Called for each rendered frame.
   */
  checkInputs() {
    this.onChangedObservable.notifyObservers({
      wheelDeltaX: this._wheelDeltaX,
      wheelDeltaY: this._wheelDeltaY,
      wheelDeltaZ: this._wheelDeltaZ
    });
    this._wheelDeltaX = 0;
    this._wheelDeltaY = 0;
    this._wheelDeltaZ = 0;
  }
  /**
   * Gets the class name of the current input.
   * @returns the class name
   */
  getClassName() {
    return "BaseCameraMouseWheelInput";
  }
  /**
   * Get the friendly name associated with the input class.
   * @returns the input friendly name
   */
  getSimpleName() {
    return "mousewheel";
  }
};
__decorate([
  serialize()
], BaseCameraMouseWheelInput.prototype, "wheelPrecisionX", void 0);
__decorate([
  serialize()
], BaseCameraMouseWheelInput.prototype, "wheelPrecisionY", void 0);
__decorate([
  serialize()
], BaseCameraMouseWheelInput.prototype, "wheelPrecisionZ", void 0);

// node_modules/@babylonjs/core/Cameras/cameraInputsManager.js
var CameraInputTypes = {};
var CameraInputsManager = class {
  /**
   * Instantiate a new Camera Input Manager.
   * @param camera Defines the camera the input manager belongs to
   */
  constructor(camera) {
    this.attachedToElement = false;
    this.attached = {};
    this.camera = camera;
    this.checkInputs = () => {
    };
  }
  /**
   * Add an input method to a camera
   * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
   * @param input Camera input method
   */
  add(input) {
    const type = input.getSimpleName();
    if (this.attached[type]) {
      Logger.Warn("camera input of type " + type + " already exists on camera");
      return;
    }
    this.attached[type] = input;
    input.camera = this.camera;
    if (input.checkInputs) {
      this.checkInputs = this._addCheckInputs(input.checkInputs.bind(input));
    }
    if (this.attachedToElement) {
      input.attachControl(this.noPreventDefault);
    }
  }
  /**
   * Remove a specific input method from a camera
   * example: camera.inputs.remove(camera.inputs.attached.mouse);
   * @param inputToRemove camera input method
   */
  remove(inputToRemove) {
    for (const cam in this.attached) {
      const input = this.attached[cam];
      if (input === inputToRemove) {
        input.detachControl();
        input.camera = null;
        delete this.attached[cam];
        this.rebuildInputCheck();
        return;
      }
    }
  }
  /**
   * Remove a specific input type from a camera
   * example: camera.inputs.remove("ArcRotateCameraGamepadInput");
   * @param inputType the type of the input to remove
   */
  removeByType(inputType) {
    for (const cam in this.attached) {
      const input = this.attached[cam];
      if (input.getClassName() === inputType) {
        input.detachControl();
        input.camera = null;
        delete this.attached[cam];
        this.rebuildInputCheck();
      }
    }
  }
  _addCheckInputs(fn) {
    const current = this.checkInputs;
    return () => {
      current();
      fn();
    };
  }
  /**
   * Attach the input controls to the currently attached dom element to listen the events from.
   * @param input Defines the input to attach
   */
  attachInput(input) {
    if (this.attachedToElement) {
      input.attachControl(this.noPreventDefault);
    }
  }
  /**
   * Attach the current manager inputs controls to a specific dom element to listen the events from.
   * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
   */
  attachElement(noPreventDefault = false) {
    if (this.attachedToElement) {
      return;
    }
    noPreventDefault = Camera.ForceAttachControlToAlwaysPreventDefault ? false : noPreventDefault;
    this.attachedToElement = true;
    this.noPreventDefault = noPreventDefault;
    for (const cam in this.attached) {
      this.attached[cam].attachControl(noPreventDefault);
    }
  }
  /**
   * Detach the current manager inputs controls from a specific dom element.
   * @param disconnect Defines whether the input should be removed from the current list of attached inputs
   */
  detachElement(disconnect = false) {
    for (const cam in this.attached) {
      this.attached[cam].detachControl();
      if (disconnect) {
        this.attached[cam].camera = null;
      }
    }
    this.attachedToElement = false;
  }
  /**
   * Rebuild the dynamic inputCheck function from the current list of
   * defined inputs in the manager.
   */
  rebuildInputCheck() {
    this.checkInputs = () => {
    };
    for (const cam in this.attached) {
      const input = this.attached[cam];
      if (input.checkInputs) {
        this.checkInputs = this._addCheckInputs(input.checkInputs.bind(input));
      }
    }
  }
  /**
   * Remove all attached input methods from a camera
   */
  clear() {
    if (this.attachedToElement) {
      this.detachElement(true);
    }
    this.attached = {};
    this.attachedToElement = false;
    this.checkInputs = () => {
    };
  }
  /**
   * Serialize the current input manager attached to a camera.
   * This ensures than once parsed,
   * the input associated to the camera will be identical to the current ones
   * @param serializedCamera Defines the camera serialization JSON the input serialization should write to
   */
  serialize(serializedCamera) {
    const inputs = {};
    for (const cam in this.attached) {
      const input = this.attached[cam];
      const res = SerializationHelper.Serialize(input);
      inputs[input.getClassName()] = res;
    }
    serializedCamera.inputsmgr = inputs;
  }
  /**
   * Parses an input manager serialized JSON to restore the previous list of inputs
   * and states associated to a camera.
   * @param parsedCamera Defines the JSON to parse
   */
  parse(parsedCamera) {
    const parsedInputs = parsedCamera.inputsmgr;
    if (parsedInputs) {
      this.clear();
      for (const n in parsedInputs) {
        const construct = CameraInputTypes[n];
        if (construct) {
          const parsedinput = parsedInputs[n];
          const input = SerializationHelper.Parse(() => {
            return new construct();
          }, parsedinput, null);
          this.add(input);
        }
      }
    } else {
      for (const n in this.attached) {
        const construct = CameraInputTypes[this.attached[n].getClassName()];
        if (construct) {
          const input = SerializationHelper.Parse(() => {
            return new construct();
          }, parsedCamera, null);
          this.remove(this.attached[n]);
          this.add(input);
        }
      }
    }
  }
};

// node_modules/@babylonjs/core/Cameras/Inputs/freeCameraKeyboardMoveInput.js
var FreeCameraKeyboardMoveInput = class {
  constructor() {
    this.keysUp = [38];
    this.keysUpward = [33];
    this.keysDown = [40];
    this.keysDownward = [34];
    this.keysLeft = [37];
    this.keysRight = [39];
    this.rotationSpeed = 0.5;
    this.keysRotateLeft = [];
    this.keysRotateRight = [];
    this.keysRotateUp = [];
    this.keysRotateDown = [];
    this._keys = new Array();
  }
  /**
   * Attach the input controls to a specific dom element to get the input from.
   * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
   */
  attachControl(noPreventDefault) {
    noPreventDefault = Tools.BackCompatCameraNoPreventDefault(arguments);
    if (this._onCanvasBlurObserver) {
      return;
    }
    this._scene = this.camera.getScene();
    this._engine = this._scene.getEngine();
    this._onCanvasBlurObserver = this._engine.onCanvasBlurObservable.add(() => {
      this._keys.length = 0;
    });
    this._onKeyboardObserver = this._scene.onKeyboardObservable.add((info) => {
      const evt = info.event;
      if (!evt.metaKey) {
        if (info.type === KeyboardEventTypes.KEYDOWN) {
          if (this.keysUp.indexOf(evt.keyCode) !== -1 || this.keysDown.indexOf(evt.keyCode) !== -1 || this.keysLeft.indexOf(evt.keyCode) !== -1 || this.keysRight.indexOf(evt.keyCode) !== -1 || this.keysUpward.indexOf(evt.keyCode) !== -1 || this.keysDownward.indexOf(evt.keyCode) !== -1 || this.keysRotateLeft.indexOf(evt.keyCode) !== -1 || this.keysRotateRight.indexOf(evt.keyCode) !== -1 || this.keysRotateUp.indexOf(evt.keyCode) !== -1 || this.keysRotateDown.indexOf(evt.keyCode) !== -1) {
            const index = this._keys.indexOf(evt.keyCode);
            if (index === -1) {
              this._keys.push(evt.keyCode);
            }
            if (!noPreventDefault) {
              evt.preventDefault();
            }
          }
        } else {
          if (this.keysUp.indexOf(evt.keyCode) !== -1 || this.keysDown.indexOf(evt.keyCode) !== -1 || this.keysLeft.indexOf(evt.keyCode) !== -1 || this.keysRight.indexOf(evt.keyCode) !== -1 || this.keysUpward.indexOf(evt.keyCode) !== -1 || this.keysDownward.indexOf(evt.keyCode) !== -1 || this.keysRotateLeft.indexOf(evt.keyCode) !== -1 || this.keysRotateRight.indexOf(evt.keyCode) !== -1 || this.keysRotateUp.indexOf(evt.keyCode) !== -1 || this.keysRotateDown.indexOf(evt.keyCode) !== -1) {
            const index = this._keys.indexOf(evt.keyCode);
            if (index >= 0) {
              this._keys.splice(index, 1);
            }
            if (!noPreventDefault) {
              evt.preventDefault();
            }
          }
        }
      }
    });
  }
  /**
   * Detach the current controls from the specified dom element.
   */
  detachControl() {
    if (this._scene) {
      if (this._onKeyboardObserver) {
        this._scene.onKeyboardObservable.remove(this._onKeyboardObserver);
      }
      if (this._onCanvasBlurObserver) {
        this._engine.onCanvasBlurObservable.remove(this._onCanvasBlurObserver);
      }
      this._onKeyboardObserver = null;
      this._onCanvasBlurObserver = null;
    }
    this._keys.length = 0;
  }
  /**
   * Update the current camera state depending on the inputs that have been used this frame.
   * This is a dynamically created lambda to avoid the performance penalty of looping for inputs in the render loop.
   */
  checkInputs() {
    if (this._onKeyboardObserver) {
      const camera = this.camera;
      for (let index = 0; index < this._keys.length; index++) {
        const keyCode = this._keys[index];
        const speed = camera._computeLocalCameraSpeed();
        if (this.keysLeft.indexOf(keyCode) !== -1) {
          camera._localDirection.copyFromFloats(-speed, 0, 0);
        } else if (this.keysUp.indexOf(keyCode) !== -1) {
          camera._localDirection.copyFromFloats(0, 0, speed);
        } else if (this.keysRight.indexOf(keyCode) !== -1) {
          camera._localDirection.copyFromFloats(speed, 0, 0);
        } else if (this.keysDown.indexOf(keyCode) !== -1) {
          camera._localDirection.copyFromFloats(0, 0, -speed);
        } else if (this.keysUpward.indexOf(keyCode) !== -1) {
          camera._localDirection.copyFromFloats(0, speed, 0);
        } else if (this.keysDownward.indexOf(keyCode) !== -1) {
          camera._localDirection.copyFromFloats(0, -speed, 0);
        } else if (this.keysRotateLeft.indexOf(keyCode) !== -1) {
          camera._localDirection.copyFromFloats(0, 0, 0);
          camera.cameraRotation.y -= this._getLocalRotation();
        } else if (this.keysRotateRight.indexOf(keyCode) !== -1) {
          camera._localDirection.copyFromFloats(0, 0, 0);
          camera.cameraRotation.y += this._getLocalRotation();
        } else if (this.keysRotateUp.indexOf(keyCode) !== -1) {
          camera._localDirection.copyFromFloats(0, 0, 0);
          camera.cameraRotation.x -= this._getLocalRotation();
        } else if (this.keysRotateDown.indexOf(keyCode) !== -1) {
          camera._localDirection.copyFromFloats(0, 0, 0);
          camera.cameraRotation.x += this._getLocalRotation();
        }
        if (camera.getScene().useRightHandedSystem) {
          camera._localDirection.z *= -1;
        }
        camera.getViewMatrix().invertToRef(camera._cameraTransformMatrix);
        Vector3.TransformNormalToRef(camera._localDirection, camera._cameraTransformMatrix, camera._transformedDirection);
        camera.cameraDirection.addInPlace(camera._transformedDirection);
      }
    }
  }
  /**
   * Gets the class name of the current input.
   * @returns the class name
   */
  getClassName() {
    return "FreeCameraKeyboardMoveInput";
  }
  /** @internal */
  _onLostFocus() {
    this._keys.length = 0;
  }
  /**
   * Get the friendly name associated with the input class.
   * @returns the input friendly name
   */
  getSimpleName() {
    return "keyboard";
  }
  _getLocalRotation() {
    const handednessMultiplier = this.camera._calculateHandednessMultiplier();
    const rotation = this.rotationSpeed * this._engine.getDeltaTime() / 1e3 * handednessMultiplier;
    return rotation;
  }
};
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "keysUp", void 0);
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "keysUpward", void 0);
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "keysDown", void 0);
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "keysDownward", void 0);
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "keysLeft", void 0);
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "keysRight", void 0);
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "rotationSpeed", void 0);
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "keysRotateLeft", void 0);
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "keysRotateRight", void 0);
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "keysRotateUp", void 0);
__decorate([
  serialize()
], FreeCameraKeyboardMoveInput.prototype, "keysRotateDown", void 0);
CameraInputTypes["FreeCameraKeyboardMoveInput"] = FreeCameraKeyboardMoveInput;

// node_modules/@babylonjs/core/Cameras/Inputs/freeCameraMouseInput.js
var FreeCameraMouseInput = class {
  /**
   * Manage the mouse inputs to control the movement of a free camera.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
   * @param touchEnabled Defines if touch is enabled or not
   */
  constructor(touchEnabled = true) {
    this.touchEnabled = touchEnabled;
    this.buttons = [0, 1, 2];
    this.angularSensibility = 2e3;
    this._previousPosition = null;
    this.onPointerMovedObservable = new Observable();
    this._allowCameraRotation = true;
    this._currentActiveButton = -1;
    this._activePointerId = -1;
  }
  /**
   * Attach the input controls to a specific dom element to get the input from.
   * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
   */
  attachControl(noPreventDefault) {
    noPreventDefault = Tools.BackCompatCameraNoPreventDefault(arguments);
    const engine = this.camera.getEngine();
    const element = engine.getInputElement();
    if (!this._pointerInput) {
      this._pointerInput = (p) => {
        const evt = p.event;
        const isTouch = evt.pointerType === "touch";
        if (!this.touchEnabled && isTouch) {
          return;
        }
        if (p.type !== PointerEventTypes.POINTERMOVE && this.buttons.indexOf(evt.button) === -1) {
          return;
        }
        const srcElement = evt.target;
        if (p.type === PointerEventTypes.POINTERDOWN) {
          if (isTouch && this._activePointerId !== -1 || !isTouch && this._currentActiveButton !== -1) {
            return;
          }
          this._activePointerId = evt.pointerId;
          try {
            srcElement?.setPointerCapture(evt.pointerId);
          } catch (e) {
          }
          if (this._currentActiveButton === -1) {
            this._currentActiveButton = evt.button;
          }
          this._previousPosition = {
            x: evt.clientX,
            y: evt.clientY
          };
          if (!noPreventDefault) {
            evt.preventDefault();
            if (element) {
              element.focus();
            }
          }
          if (engine.isPointerLock && this._onMouseMove) {
            this._onMouseMove(p.event);
          }
        } else if (p.type === PointerEventTypes.POINTERUP) {
          if (isTouch && this._activePointerId !== evt.pointerId || !isTouch && this._currentActiveButton !== evt.button) {
            return;
          }
          try {
            srcElement?.releasePointerCapture(evt.pointerId);
          } catch (e) {
          }
          this._currentActiveButton = -1;
          this._previousPosition = null;
          if (!noPreventDefault) {
            evt.preventDefault();
          }
          this._activePointerId = -1;
        } else if (p.type === PointerEventTypes.POINTERMOVE && (this._activePointerId === evt.pointerId || !isTouch)) {
          if (engine.isPointerLock && this._onMouseMove) {
            this._onMouseMove(p.event);
          } else if (this._previousPosition) {
            const handednessMultiplier = this.camera._calculateHandednessMultiplier();
            const offsetX = (evt.clientX - this._previousPosition.x) * handednessMultiplier;
            const offsetY = (evt.clientY - this._previousPosition.y) * handednessMultiplier;
            if (this._allowCameraRotation) {
              this.camera.cameraRotation.y += offsetX / this.angularSensibility;
              this.camera.cameraRotation.x += offsetY / this.angularSensibility;
            }
            this.onPointerMovedObservable.notifyObservers({ offsetX, offsetY });
            this._previousPosition = {
              x: evt.clientX,
              y: evt.clientY
            };
            if (!noPreventDefault) {
              evt.preventDefault();
            }
          }
        }
      };
    }
    this._onMouseMove = (evt) => {
      if (!engine.isPointerLock) {
        return;
      }
      const handednessMultiplier = this.camera._calculateHandednessMultiplier();
      this.camera.cameraRotation.y += evt.movementX * handednessMultiplier / this.angularSensibility;
      this.camera.cameraRotation.x += evt.movementY * handednessMultiplier / this.angularSensibility;
      this._previousPosition = null;
      if (!noPreventDefault) {
        evt.preventDefault();
      }
    };
    this._observer = this.camera.getScene()._inputManager._addCameraPointerObserver(this._pointerInput, PointerEventTypes.POINTERDOWN | PointerEventTypes.POINTERUP | PointerEventTypes.POINTERMOVE);
    if (element) {
      this._contextMenuBind = (evt) => this.onContextMenu(evt);
      element.addEventListener("contextmenu", this._contextMenuBind, false);
    }
  }
  /**
   * Called on JS contextmenu event.
   * Override this method to provide functionality.
   * @param evt the context menu event
   */
  onContextMenu(evt) {
    evt.preventDefault();
  }
  /**
   * Detach the current controls from the specified dom element.
   */
  detachControl() {
    if (this._observer) {
      this.camera.getScene()._inputManager._removeCameraPointerObserver(this._observer);
      if (this._contextMenuBind) {
        const engine = this.camera.getEngine();
        const element = engine.getInputElement();
        if (element) {
          element.removeEventListener("contextmenu", this._contextMenuBind);
        }
      }
      if (this.onPointerMovedObservable) {
        this.onPointerMovedObservable.clear();
      }
      this._observer = null;
      this._onMouseMove = null;
      this._previousPosition = null;
    }
    this._activePointerId = -1;
    this._currentActiveButton = -1;
  }
  /**
   * Gets the class name of the current input.
   * @returns the class name
   */
  getClassName() {
    return "FreeCameraMouseInput";
  }
  /**
   * Get the friendly name associated with the input class.
   * @returns the input friendly name
   */
  getSimpleName() {
    return "mouse";
  }
};
__decorate([
  serialize()
], FreeCameraMouseInput.prototype, "buttons", void 0);
__decorate([
  serialize()
], FreeCameraMouseInput.prototype, "angularSensibility", void 0);
CameraInputTypes["FreeCameraMouseInput"] = FreeCameraMouseInput;

// node_modules/@babylonjs/core/Cameras/Inputs/freeCameraMouseWheelInput.js
var _CameraProperty;
(function(_CameraProperty2) {
  _CameraProperty2[_CameraProperty2["MoveRelative"] = 0] = "MoveRelative";
  _CameraProperty2[_CameraProperty2["RotateRelative"] = 1] = "RotateRelative";
  _CameraProperty2[_CameraProperty2["MoveScene"] = 2] = "MoveScene";
})(_CameraProperty || (_CameraProperty = {}));
var FreeCameraMouseWheelInput = class extends BaseCameraMouseWheelInput {
  constructor() {
    super(...arguments);
    this._moveRelative = Vector3.Zero();
    this._rotateRelative = Vector3.Zero();
    this._moveScene = Vector3.Zero();
    this._wheelXAction = _CameraProperty.MoveRelative;
    this._wheelXActionCoordinate = 0;
    this._wheelYAction = _CameraProperty.MoveRelative;
    this._wheelYActionCoordinate = 2;
    this._wheelZAction = null;
    this._wheelZActionCoordinate = null;
  }
  /**
   * Gets the class name of the current input.
   * @returns the class name
   */
  getClassName() {
    return "FreeCameraMouseWheelInput";
  }
  /**
   * Set which movement axis (relative to camera's orientation) the mouse
   * wheel's X axis controls.
   * @param axis The axis to be moved. Set null to clear.
   */
  set wheelXMoveRelative(axis) {
    if (axis === null && this._wheelXAction !== _CameraProperty.MoveRelative) {
      return;
    }
    this._wheelXAction = _CameraProperty.MoveRelative;
    this._wheelXActionCoordinate = axis;
  }
  /**
   * Get the configured movement axis (relative to camera's orientation) the
   * mouse wheel's X axis controls.
   * @returns The configured axis or null if none.
   */
  get wheelXMoveRelative() {
    if (this._wheelXAction !== _CameraProperty.MoveRelative) {
      return null;
    }
    return this._wheelXActionCoordinate;
  }
  /**
   * Set which movement axis (relative to camera's orientation) the mouse
   * wheel's Y axis controls.
   * @param axis The axis to be moved. Set null to clear.
   */
  set wheelYMoveRelative(axis) {
    if (axis === null && this._wheelYAction !== _CameraProperty.MoveRelative) {
      return;
    }
    this._wheelYAction = _CameraProperty.MoveRelative;
    this._wheelYActionCoordinate = axis;
  }
  /**
   * Get the configured movement axis (relative to camera's orientation) the
   * mouse wheel's Y axis controls.
   * @returns The configured axis or null if none.
   */
  get wheelYMoveRelative() {
    if (this._wheelYAction !== _CameraProperty.MoveRelative) {
      return null;
    }
    return this._wheelYActionCoordinate;
  }
  /**
   * Set which movement axis (relative to camera's orientation) the mouse
   * wheel's Z axis controls.
   * @param axis The axis to be moved. Set null to clear.
   */
  set wheelZMoveRelative(axis) {
    if (axis === null && this._wheelZAction !== _CameraProperty.MoveRelative) {
      return;
    }
    this._wheelZAction = _CameraProperty.MoveRelative;
    this._wheelZActionCoordinate = axis;
  }
  /**
   * Get the configured movement axis (relative to camera's orientation) the
   * mouse wheel's Z axis controls.
   * @returns The configured axis or null if none.
   */
  get wheelZMoveRelative() {
    if (this._wheelZAction !== _CameraProperty.MoveRelative) {
      return null;
    }
    return this._wheelZActionCoordinate;
  }
  /**
   * Set which rotation axis (relative to camera's orientation) the mouse
   * wheel's X axis controls.
   * @param axis The axis to be moved. Set null to clear.
   */
  set wheelXRotateRelative(axis) {
    if (axis === null && this._wheelXAction !== _CameraProperty.RotateRelative) {
      return;
    }
    this._wheelXAction = _CameraProperty.RotateRelative;
    this._wheelXActionCoordinate = axis;
  }
  /**
   * Get the configured rotation axis (relative to camera's orientation) the
   * mouse wheel's X axis controls.
   * @returns The configured axis or null if none.
   */
  get wheelXRotateRelative() {
    if (this._wheelXAction !== _CameraProperty.RotateRelative) {
      return null;
    }
    return this._wheelXActionCoordinate;
  }
  /**
   * Set which rotation axis (relative to camera's orientation) the mouse
   * wheel's Y axis controls.
   * @param axis The axis to be moved. Set null to clear.
   */
  set wheelYRotateRelative(axis) {
    if (axis === null && this._wheelYAction !== _CameraProperty.RotateRelative) {
      return;
    }
    this._wheelYAction = _CameraProperty.RotateRelative;
    this._wheelYActionCoordinate = axis;
  }
  /**
   * Get the configured rotation axis (relative to camera's orientation) the
   * mouse wheel's Y axis controls.
   * @returns The configured axis or null if none.
   */
  get wheelYRotateRelative() {
    if (this._wheelYAction !== _CameraProperty.RotateRelative) {
      return null;
    }
    return this._wheelYActionCoordinate;
  }
  /**
   * Set which rotation axis (relative to camera's orientation) the mouse
   * wheel's Z axis controls.
   * @param axis The axis to be moved. Set null to clear.
   */
  set wheelZRotateRelative(axis) {
    if (axis === null && this._wheelZAction !== _CameraProperty.RotateRelative) {
      return;
    }
    this._wheelZAction = _CameraProperty.RotateRelative;
    this._wheelZActionCoordinate = axis;
  }
  /**
   * Get the configured rotation axis (relative to camera's orientation) the
   * mouse wheel's Z axis controls.
   * @returns The configured axis or null if none.
   */
  get wheelZRotateRelative() {
    if (this._wheelZAction !== _CameraProperty.RotateRelative) {
      return null;
    }
    return this._wheelZActionCoordinate;
  }
  /**
   * Set which movement axis (relative to the scene) the mouse wheel's X axis
   * controls.
   * @param axis The axis to be moved. Set null to clear.
   */
  set wheelXMoveScene(axis) {
    if (axis === null && this._wheelXAction !== _CameraProperty.MoveScene) {
      return;
    }
    this._wheelXAction = _CameraProperty.MoveScene;
    this._wheelXActionCoordinate = axis;
  }
  /**
   * Get the configured movement axis (relative to the scene) the mouse wheel's
   * X axis controls.
   * @returns The configured axis or null if none.
   */
  get wheelXMoveScene() {
    if (this._wheelXAction !== _CameraProperty.MoveScene) {
      return null;
    }
    return this._wheelXActionCoordinate;
  }
  /**
   * Set which movement axis (relative to the scene) the mouse wheel's Y axis
   * controls.
   * @param axis The axis to be moved. Set null to clear.
   */
  set wheelYMoveScene(axis) {
    if (axis === null && this._wheelYAction !== _CameraProperty.MoveScene) {
      return;
    }
    this._wheelYAction = _CameraProperty.MoveScene;
    this._wheelYActionCoordinate = axis;
  }
  /**
   * Get the configured movement axis (relative to the scene) the mouse wheel's
   * Y axis controls.
   * @returns The configured axis or null if none.
   */
  get wheelYMoveScene() {
    if (this._wheelYAction !== _CameraProperty.MoveScene) {
      return null;
    }
    return this._wheelYActionCoordinate;
  }
  /**
   * Set which movement axis (relative to the scene) the mouse wheel's Z axis
   * controls.
   * @param axis The axis to be moved. Set null to clear.
   */
  set wheelZMoveScene(axis) {
    if (axis === null && this._wheelZAction !== _CameraProperty.MoveScene) {
      return;
    }
    this._wheelZAction = _CameraProperty.MoveScene;
    this._wheelZActionCoordinate = axis;
  }
  /**
   * Get the configured movement axis (relative to the scene) the mouse wheel's
   * Z axis controls.
   * @returns The configured axis or null if none.
   */
  get wheelZMoveScene() {
    if (this._wheelZAction !== _CameraProperty.MoveScene) {
      return null;
    }
    return this._wheelZActionCoordinate;
  }
  /**
   * Called for each rendered frame.
   */
  checkInputs() {
    if (this._wheelDeltaX === 0 && this._wheelDeltaY === 0 && this._wheelDeltaZ == 0) {
      return;
    }
    this._moveRelative.setAll(0);
    this._rotateRelative.setAll(0);
    this._moveScene.setAll(0);
    this._updateCamera();
    if (this.camera.getScene().useRightHandedSystem) {
      this._moveRelative.z *= -1;
    }
    const cameraTransformMatrix = Matrix.Zero();
    this.camera.getViewMatrix().invertToRef(cameraTransformMatrix);
    const transformedDirection = Vector3.Zero();
    Vector3.TransformNormalToRef(this._moveRelative, cameraTransformMatrix, transformedDirection);
    this.camera.cameraRotation.x += this._rotateRelative.x / 200;
    this.camera.cameraRotation.y += this._rotateRelative.y / 200;
    this.camera.cameraDirection.addInPlace(transformedDirection);
    this.camera.cameraDirection.addInPlace(this._moveScene);
    super.checkInputs();
  }
  /**
   * Update the camera according to any configured properties for the 3
   * mouse-wheel axis.
   */
  _updateCamera() {
    this._updateCameraProperty(this._wheelDeltaX, this._wheelXAction, this._wheelXActionCoordinate);
    this._updateCameraProperty(this._wheelDeltaY, this._wheelYAction, this._wheelYActionCoordinate);
    this._updateCameraProperty(this._wheelDeltaZ, this._wheelZAction, this._wheelZActionCoordinate);
  }
  /**
   * Update one property of the camera.
   * @param value
   * @param cameraProperty
   * @param coordinate
   */
  _updateCameraProperty(value, cameraProperty, coordinate) {
    if (value === 0) {
      return;
    }
    if (cameraProperty === null || coordinate === null) {
      return;
    }
    let action = null;
    switch (cameraProperty) {
      case _CameraProperty.MoveRelative:
        action = this._moveRelative;
        break;
      case _CameraProperty.RotateRelative:
        action = this._rotateRelative;
        break;
      case _CameraProperty.MoveScene:
        action = this._moveScene;
        break;
    }
    switch (coordinate) {
      case 0:
        action.set(value, 0, 0);
        break;
      case 1:
        action.set(0, value, 0);
        break;
      case 2:
        action.set(0, 0, value);
        break;
    }
  }
};
__decorate([
  serialize()
], FreeCameraMouseWheelInput.prototype, "wheelXMoveRelative", null);
__decorate([
  serialize()
], FreeCameraMouseWheelInput.prototype, "wheelYMoveRelative", null);
__decorate([
  serialize()
], FreeCameraMouseWheelInput.prototype, "wheelZMoveRelative", null);
__decorate([
  serialize()
], FreeCameraMouseWheelInput.prototype, "wheelXRotateRelative", null);
__decorate([
  serialize()
], FreeCameraMouseWheelInput.prototype, "wheelYRotateRelative", null);
__decorate([
  serialize()
], FreeCameraMouseWheelInput.prototype, "wheelZRotateRelative", null);
__decorate([
  serialize()
], FreeCameraMouseWheelInput.prototype, "wheelXMoveScene", null);
__decorate([
  serialize()
], FreeCameraMouseWheelInput.prototype, "wheelYMoveScene", null);
__decorate([
  serialize()
], FreeCameraMouseWheelInput.prototype, "wheelZMoveScene", null);
CameraInputTypes["FreeCameraMouseWheelInput"] = FreeCameraMouseWheelInput;

// node_modules/@babylonjs/core/Cameras/Inputs/freeCameraTouchInput.js
var FreeCameraTouchInput = class {
  /**
   * Manage the touch inputs to control the movement of a free camera.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
   * @param allowMouse Defines if mouse events can be treated as touch events
   */
  constructor(allowMouse = false) {
    this.allowMouse = allowMouse;
    this.touchAngularSensibility = 2e5;
    this.touchMoveSensibility = 250;
    this.singleFingerRotate = false;
    this._offsetX = null;
    this._offsetY = null;
    this._pointerPressed = new Array();
    this._isSafari = Tools.IsSafari();
  }
  /**
   * Attach the input controls to a specific dom element to get the input from.
   * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
   */
  attachControl(noPreventDefault) {
    noPreventDefault = Tools.BackCompatCameraNoPreventDefault(arguments);
    let previousPosition = null;
    if (this._pointerInput === void 0) {
      this._onLostFocus = () => {
        this._offsetX = null;
        this._offsetY = null;
      };
      this._pointerInput = (p) => {
        const evt = p.event;
        const isMouseEvent = evt.pointerType === "mouse" || this._isSafari && typeof evt.pointerType === "undefined";
        if (!this.allowMouse && isMouseEvent) {
          return;
        }
        if (p.type === PointerEventTypes.POINTERDOWN) {
          if (!noPreventDefault) {
            evt.preventDefault();
          }
          this._pointerPressed.push(evt.pointerId);
          if (this._pointerPressed.length !== 1) {
            return;
          }
          previousPosition = {
            x: evt.clientX,
            y: evt.clientY
          };
        } else if (p.type === PointerEventTypes.POINTERUP) {
          if (!noPreventDefault) {
            evt.preventDefault();
          }
          const index = this._pointerPressed.indexOf(evt.pointerId);
          if (index === -1) {
            return;
          }
          this._pointerPressed.splice(index, 1);
          if (index != 0) {
            return;
          }
          previousPosition = null;
          this._offsetX = null;
          this._offsetY = null;
        } else if (p.type === PointerEventTypes.POINTERMOVE) {
          if (!noPreventDefault) {
            evt.preventDefault();
          }
          if (!previousPosition) {
            return;
          }
          const index = this._pointerPressed.indexOf(evt.pointerId);
          if (index != 0) {
            return;
          }
          this._offsetX = evt.clientX - previousPosition.x;
          this._offsetY = -(evt.clientY - previousPosition.y);
        }
      };
    }
    this._observer = this.camera.getScene()._inputManager._addCameraPointerObserver(this._pointerInput, PointerEventTypes.POINTERDOWN | PointerEventTypes.POINTERUP | PointerEventTypes.POINTERMOVE);
    if (this._onLostFocus) {
      const engine = this.camera.getEngine();
      const element = engine.getInputElement();
      if (element) {
        element.addEventListener("blur", this._onLostFocus);
      }
    }
  }
  /**
   * Detach the current controls from the specified dom element.
   */
  detachControl() {
    if (this._pointerInput) {
      if (this._observer) {
        this.camera.getScene()._inputManager._removeCameraPointerObserver(this._observer);
        this._observer = null;
      }
      if (this._onLostFocus) {
        const engine = this.camera.getEngine();
        const element = engine.getInputElement();
        if (element) {
          element.removeEventListener("blur", this._onLostFocus);
        }
        this._onLostFocus = null;
      }
      this._pointerPressed.length = 0;
      this._offsetX = null;
      this._offsetY = null;
    }
  }
  /**
   * Update the current camera state depending on the inputs that have been used this frame.
   * This is a dynamically created lambda to avoid the performance penalty of looping for inputs in the render loop.
   */
  checkInputs() {
    if (this._offsetX === null || this._offsetY === null) {
      return;
    }
    if (this._offsetX === 0 && this._offsetY === 0) {
      return;
    }
    const camera = this.camera;
    const handednessMultiplier = camera._calculateHandednessMultiplier();
    camera.cameraRotation.y = this._offsetX * handednessMultiplier / this.touchAngularSensibility;
    const rotateCamera = this.singleFingerRotate && this._pointerPressed.length === 1 || !this.singleFingerRotate && this._pointerPressed.length > 1;
    if (rotateCamera) {
      camera.cameraRotation.x = -(this._offsetY * handednessMultiplier) / this.touchAngularSensibility;
    } else {
      const speed = camera._computeLocalCameraSpeed();
      const direction = new Vector3(0, 0, this.touchMoveSensibility !== 0 ? speed * this._offsetY / this.touchMoveSensibility : 0);
      Matrix.RotationYawPitchRollToRef(camera.rotation.y, camera.rotation.x, 0, camera._cameraRotationMatrix);
      camera.cameraDirection.addInPlace(Vector3.TransformCoordinates(direction, camera._cameraRotationMatrix));
    }
  }
  /**
   * Gets the class name of the current input.
   * @returns the class name
   */
  getClassName() {
    return "FreeCameraTouchInput";
  }
  /**
   * Get the friendly name associated with the input class.
   * @returns the input friendly name
   */
  getSimpleName() {
    return "touch";
  }
};
__decorate([
  serialize()
], FreeCameraTouchInput.prototype, "touchAngularSensibility", void 0);
__decorate([
  serialize()
], FreeCameraTouchInput.prototype, "touchMoveSensibility", void 0);
CameraInputTypes["FreeCameraTouchInput"] = FreeCameraTouchInput;

// node_modules/@babylonjs/core/Cameras/freeCameraInputsManager.js
var FreeCameraInputsManager = class extends CameraInputsManager {
  /**
   * Instantiates a new FreeCameraInputsManager.
   * @param camera Defines the camera the inputs belong to
   */
  constructor(camera) {
    super(camera);
    this._mouseInput = null;
    this._mouseWheelInput = null;
  }
  /**
   * Add keyboard input support to the input manager.
   * @returns the current input manager
   */
  addKeyboard() {
    this.add(new FreeCameraKeyboardMoveInput());
    return this;
  }
  /**
   * Add mouse input support to the input manager.
   * @param touchEnabled if the FreeCameraMouseInput should support touch (default: true)
   * @returns the current input manager
   */
  addMouse(touchEnabled = true) {
    if (!this._mouseInput) {
      this._mouseInput = new FreeCameraMouseInput(touchEnabled);
      this.add(this._mouseInput);
    }
    return this;
  }
  /**
   * Removes the mouse input support from the manager
   * @returns the current input manager
   */
  removeMouse() {
    if (this._mouseInput) {
      this.remove(this._mouseInput);
    }
    return this;
  }
  /**
   * Add mouse wheel input support to the input manager.
   * @returns the current input manager
   */
  addMouseWheel() {
    if (!this._mouseWheelInput) {
      this._mouseWheelInput = new FreeCameraMouseWheelInput();
      this.add(this._mouseWheelInput);
    }
    return this;
  }
  /**
   * Removes the mouse wheel input support from the manager
   * @returns the current input manager
   */
  removeMouseWheel() {
    if (this._mouseWheelInput) {
      this.remove(this._mouseWheelInput);
    }
    return this;
  }
  /**
   * Add touch input support to the input manager.
   * @returns the current input manager
   */
  addTouch() {
    this.add(new FreeCameraTouchInput());
    return this;
  }
  /**
   * Remove all attached input methods from a camera
   */
  clear() {
    super.clear();
    this._mouseInput = null;
  }
};

// node_modules/@babylonjs/core/Cameras/freeCamera.js
var FreeCamera = class extends TargetCamera {
  /**
   * Gets the input sensibility for a mouse input. (default is 2000.0)
   * Higher values reduce sensitivity.
   */
  get angularSensibility() {
    const mouse = this.inputs.attached["mouse"];
    if (mouse) {
      return mouse.angularSensibility;
    }
    return 0;
  }
  /**
   * Sets the input sensibility for a mouse input. (default is 2000.0)
   * Higher values reduce sensitivity.
   */
  set angularSensibility(value) {
    const mouse = this.inputs.attached["mouse"];
    if (mouse) {
      mouse.angularSensibility = value;
    }
  }
  /**
   * Gets or Set the list of keyboard keys used to control the forward move of the camera.
   */
  get keysUp() {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      return keyboard.keysUp;
    }
    return [];
  }
  set keysUp(value) {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      keyboard.keysUp = value;
    }
  }
  /**
   * Gets or Set the list of keyboard keys used to control the upward move of the camera.
   */
  get keysUpward() {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      return keyboard.keysUpward;
    }
    return [];
  }
  set keysUpward(value) {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      keyboard.keysUpward = value;
    }
  }
  /**
   * Gets or Set the list of keyboard keys used to control the backward move of the camera.
   */
  get keysDown() {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      return keyboard.keysDown;
    }
    return [];
  }
  set keysDown(value) {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      keyboard.keysDown = value;
    }
  }
  /**
   * Gets or Set the list of keyboard keys used to control the downward move of the camera.
   */
  get keysDownward() {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      return keyboard.keysDownward;
    }
    return [];
  }
  set keysDownward(value) {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      keyboard.keysDownward = value;
    }
  }
  /**
   * Gets or Set the list of keyboard keys used to control the left strafe move of the camera.
   */
  get keysLeft() {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      return keyboard.keysLeft;
    }
    return [];
  }
  set keysLeft(value) {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      keyboard.keysLeft = value;
    }
  }
  /**
   * Gets or Set the list of keyboard keys used to control the right strafe move of the camera.
   */
  get keysRight() {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      return keyboard.keysRight;
    }
    return [];
  }
  set keysRight(value) {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      keyboard.keysRight = value;
    }
  }
  /**
   * Gets or Set the list of keyboard keys used to control the left rotation move of the camera.
   */
  get keysRotateLeft() {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      return keyboard.keysRotateLeft;
    }
    return [];
  }
  set keysRotateLeft(value) {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      keyboard.keysRotateLeft = value;
    }
  }
  /**
   * Gets or Set the list of keyboard keys used to control the right rotation move of the camera.
   */
  get keysRotateRight() {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      return keyboard.keysRotateRight;
    }
    return [];
  }
  set keysRotateRight(value) {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      keyboard.keysRotateRight = value;
    }
  }
  /**
   * Gets or Set the list of keyboard keys used to control the up rotation move of the camera.
   */
  get keysRotateUp() {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      return keyboard.keysRotateUp;
    }
    return [];
  }
  set keysRotateUp(value) {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      keyboard.keysRotateUp = value;
    }
  }
  /**
   * Gets or Set the list of keyboard keys used to control the down rotation move of the camera.
   */
  get keysRotateDown() {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      return keyboard.keysRotateDown;
    }
    return [];
  }
  set keysRotateDown(value) {
    const keyboard = this.inputs.attached["keyboard"];
    if (keyboard) {
      keyboard.keysRotateDown = value;
    }
  }
  /**
   * Instantiates a Free Camera.
   * This represents a free type of camera. It can be useful in First Person Shooter game for instance.
   * Please consider using the new UniversalCamera instead as it adds more functionality like touch to this camera.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_introduction#universal-camera
   * @param name Define the name of the camera in the scene
   * @param position Define the start position of the camera in the scene
   * @param scene Define the scene the camera belongs to
   * @param setActiveOnSceneIfNoneActive Defines whether the camera should be marked as active if not other active cameras have been defined
   */
  constructor(name, position, scene, setActiveOnSceneIfNoneActive = true) {
    super(name, position, scene, setActiveOnSceneIfNoneActive);
    this.ellipsoid = new Vector3(0.5, 1, 0.5);
    this.ellipsoidOffset = new Vector3(0, 0, 0);
    this.checkCollisions = false;
    this.applyGravity = false;
    this._needMoveForGravity = false;
    this._oldPosition = Vector3.Zero();
    this._diffPosition = Vector3.Zero();
    this._newPosition = Vector3.Zero();
    this._collisionMask = -1;
    this._onCollisionPositionChange = (collisionId, newPosition, collidedMesh = null) => {
      this._newPosition.copyFrom(newPosition);
      this._newPosition.subtractToRef(this._oldPosition, this._diffPosition);
      if (this._diffPosition.length() > AbstractEngine.CollisionsEpsilon) {
        this.position.addToRef(this._diffPosition, this._deferredPositionUpdate);
        if (!this._deferOnly) {
          this.position.copyFrom(this._deferredPositionUpdate);
        } else {
          this._deferredUpdated = true;
        }
        if (this.onCollide && collidedMesh) {
          this.onCollide(collidedMesh);
        }
      }
    };
    this.inputs = new FreeCameraInputsManager(this);
    this.inputs.addKeyboard().addMouse();
  }
  /**
   * Attached controls to the current camera.
   * @param ignored defines an ignored parameter kept for backward compatibility.
   * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
   */
  attachControl(ignored, noPreventDefault) {
    noPreventDefault = Tools.BackCompatCameraNoPreventDefault(arguments);
    this.inputs.attachElement(noPreventDefault);
  }
  /**
   * Detach the current controls from the specified dom element.
   */
  detachControl() {
    this.inputs.detachElement();
    this.cameraDirection = new Vector3(0, 0, 0);
    this.cameraRotation = new Vector2(0, 0);
  }
  /**
   * Define a collision mask to limit the list of object the camera can collide with
   */
  get collisionMask() {
    return this._collisionMask;
  }
  set collisionMask(mask) {
    this._collisionMask = !isNaN(mask) ? mask : -1;
  }
  /**
   * @internal
   */
  _collideWithWorld(displacement) {
    let globalPosition;
    if (this.parent) {
      globalPosition = Vector3.TransformCoordinates(this.position, this.parent.getWorldMatrix());
    } else {
      globalPosition = this.position;
    }
    globalPosition.subtractFromFloatsToRef(0, this.ellipsoid.y, 0, this._oldPosition);
    this._oldPosition.addInPlace(this.ellipsoidOffset);
    const coordinator = this.getScene().collisionCoordinator;
    if (!this._collider) {
      this._collider = coordinator.createCollider();
    }
    this._collider._radius = this.ellipsoid;
    this._collider.collisionMask = this._collisionMask;
    let actualDisplacement = displacement;
    if (this.applyGravity) {
      actualDisplacement = displacement.add(this.getScene().gravity);
    }
    coordinator.getNewPosition(this._oldPosition, actualDisplacement, this._collider, 3, null, this._onCollisionPositionChange, this.uniqueId);
  }
  /** @internal */
  _checkInputs() {
    if (!this._localDirection) {
      this._localDirection = Vector3.Zero();
      this._transformedDirection = Vector3.Zero();
    }
    this.inputs.checkInputs();
    super._checkInputs();
  }
  /**
   * Enable movement without a user input. This allows gravity to always be applied.
   */
  set needMoveForGravity(value) {
    this._needMoveForGravity = value;
  }
  /**
   * When true, gravity is applied whether there is user input or not.
   */
  get needMoveForGravity() {
    return this._needMoveForGravity;
  }
  /** @internal */
  _decideIfNeedsToMove() {
    return this._needMoveForGravity || Math.abs(this.cameraDirection.x) > 0 || Math.abs(this.cameraDirection.y) > 0 || Math.abs(this.cameraDirection.z) > 0;
  }
  /** @internal */
  _updatePosition() {
    if (this.checkCollisions && this.getScene().collisionsEnabled) {
      this._collideWithWorld(this.cameraDirection);
    } else {
      super._updatePosition();
    }
  }
  /**
   * Destroy the camera and release the current resources hold by it.
   */
  dispose() {
    this.inputs.clear();
    super.dispose();
  }
  /**
   * Gets the current object class name.
   * @returns the class name
   */
  getClassName() {
    return "FreeCamera";
  }
};
__decorate([
  serializeAsVector3()
], FreeCamera.prototype, "ellipsoid", void 0);
__decorate([
  serializeAsVector3()
], FreeCamera.prototype, "ellipsoidOffset", void 0);
__decorate([
  serialize()
], FreeCamera.prototype, "checkCollisions", void 0);
__decorate([
  serialize()
], FreeCamera.prototype, "applyGravity", void 0);
RegisterClass("BABYLON.FreeCamera", FreeCamera);

// node_modules/@babylonjs/core/Lights/hemisphericLight.js
Node.AddNodeConstructor("Light_Type_3", (name, scene) => {
  return () => new HemisphericLight(name, Vector3.Zero(), scene);
});
var HemisphericLight = class extends Light {
  /**
   * Creates a HemisphericLight object in the scene according to the passed direction (Vector3).
   * The HemisphericLight simulates the ambient environment light, so the passed direction is the light reflection direction, not the incoming direction.
   * The HemisphericLight can't cast shadows.
   * Documentation : https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction
   * @param name The friendly name of the light
   * @param direction The direction of the light reflection
   * @param scene The scene the light belongs to
   */
  constructor(name, direction, scene) {
    super(name, scene);
    this.groundColor = new Color3(0, 0, 0);
    this.direction = direction || Vector3.Up();
  }
  _buildUniformLayout() {
    this._uniformBuffer.addUniform("vLightData", 4);
    this._uniformBuffer.addUniform("vLightDiffuse", 4);
    this._uniformBuffer.addUniform("vLightSpecular", 4);
    this._uniformBuffer.addUniform("vLightGround", 3);
    this._uniformBuffer.addUniform("shadowsInfo", 3);
    this._uniformBuffer.addUniform("depthValues", 2);
    this._uniformBuffer.create();
  }
  /**
   * Returns the string "HemisphericLight".
   * @returns The class name
   */
  getClassName() {
    return "HemisphericLight";
  }
  /**
   * Sets the HemisphericLight direction towards the passed target (Vector3).
   * Returns the updated direction.
   * @param target The target the direction should point to
   * @returns The computed direction
   */
  setDirectionToTarget(target) {
    this.direction = Vector3.Normalize(target.subtract(Vector3.Zero()));
    return this.direction;
  }
  /**
   * Returns the shadow generator associated to the light.
   * @returns Always null for hemispheric lights because it does not support shadows.
   */
  getShadowGenerator() {
    return null;
  }
  /**
   * Sets the passed Effect object with the HemisphericLight normalized direction and color and the passed name (string).
   * @param _effect The effect to update
   * @param lightIndex The index of the light in the effect to update
   * @returns The hemispheric light
   */
  transferToEffect(_effect, lightIndex) {
    const normalizeDirection = Vector3.Normalize(this.direction);
    this._uniformBuffer.updateFloat4("vLightData", normalizeDirection.x, normalizeDirection.y, normalizeDirection.z, 0, lightIndex);
    this._uniformBuffer.updateColor3("vLightGround", this.groundColor.scale(this.intensity), lightIndex);
    return this;
  }
  transferToNodeMaterialEffect(effect, lightDataUniformName) {
    const normalizeDirection = Vector3.Normalize(this.direction);
    effect.setFloat3(lightDataUniformName, normalizeDirection.x, normalizeDirection.y, normalizeDirection.z);
    return this;
  }
  /**
   * Computes the world matrix of the node
   * @returns the world matrix
   */
  computeWorldMatrix() {
    if (!this._worldMatrix) {
      this._worldMatrix = Matrix.Identity();
    }
    return this._worldMatrix;
  }
  /**
   * Returns the integer 3.
   * @returns The light Type id as a constant defines in Light.LIGHTTYPEID_x
   */
  // eslint-disable-next-line @typescript-eslint/naming-convention
  getTypeID() {
    return Light.LIGHTTYPEID_HEMISPHERICLIGHT;
  }
  /**
   * Prepares the list of defines specific to the light type.
   * @param defines the list of defines
   * @param lightIndex defines the index of the light for the effect
   */
  prepareLightSpecificDefines(defines, lightIndex) {
    defines["HEMILIGHT" + lightIndex] = true;
  }
};
__decorate([
  serializeAsColor3()
], HemisphericLight.prototype, "groundColor", void 0);
__decorate([
  serializeAsVector3()
], HemisphericLight.prototype, "direction", void 0);
RegisterClass("BABYLON.HemisphericLight", HemisphericLight);

// node_modules/@babylonjs/core/FlowGraph/Blocks/flowGraphBlockFactory.js
var CustomBlocks = {};
function addToBlockFactory(module, blockName, factory) {
  CustomBlocks[`${module}/${blockName}`] = factory;
}
function blockFactory(blockName) {
  switch (blockName) {
    case "FlowGraphPlayAnimationBlock":
      return async () => (await import("./flowGraphPlayAnimationBlock-RRIAVWZ4.js")).FlowGraphPlayAnimationBlock;
    case "FlowGraphStopAnimationBlock":
      return async () => (await import("./flowGraphStopAnimationBlock-JRK5E5W7.js")).FlowGraphStopAnimationBlock;
    case "FlowGraphPauseAnimationBlock":
      return async () => (await import("./flowGraphPauseAnimationBlock-3D2ZLILL.js")).FlowGraphPauseAnimationBlock;
    case "FlowGraphInterpolationBlock":
      return async () => (await import("./flowGraphInterpolationBlock-YDQIIO2U.js")).FlowGraphInterpolationBlock;
    case "FlowGraphSceneReadyEventBlock":
      return async () => (await import("./flowGraphSceneReadyEventBlock-DXLBZPTZ.js")).FlowGraphSceneReadyEventBlock;
    case "FlowGraphSceneTickEventBlock":
      return async () => (await import("./flowGraphSceneTickEventBlock-F3UIBYTO.js")).FlowGraphSceneTickEventBlock;
    case "FlowGraphSendCustomEventBlock":
      return async () => (await import("./flowGraphSendCustomEventBlock-LLKAN3BN.js")).FlowGraphSendCustomEventBlock;
    case "FlowGraphReceiveCustomEventBlock":
      return async () => (await import("./flowGraphReceiveCustomEventBlock-THDAD7VB.js")).FlowGraphReceiveCustomEventBlock;
    case "FlowGraphMeshPickEventBlock":
      return async () => (await import("./flowGraphMeshPickEventBlock-4ROW2OCN.js")).FlowGraphMeshPickEventBlock;
    case "FlowGraphEBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphEBlock;
    case "FlowGraphPIBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphPiBlock;
    case "FlowGraphInfBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphInfBlock;
    case "FlowGraphNaNBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphNaNBlock;
    case "FlowGraphRandomBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphRandomBlock;
    case "FlowGraphAddBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphAddBlock;
    case "FlowGraphSubtractBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphSubtractBlock;
    case "FlowGraphMultiplyBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphMultiplyBlock;
    case "FlowGraphDivideBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphDivideBlock;
    case "FlowGraphAbsBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphAbsBlock;
    case "FlowGraphSignBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphSignBlock;
    case "FlowGraphTruncBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphTruncBlock;
    case "FlowGraphFloorBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphFloorBlock;
    case "FlowGraphCeilBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphCeilBlock;
    case "FlowGraphRoundBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphRoundBlock;
    case "FlowGraphFractBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphFractionBlock;
    case "FlowGraphNegationBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphNegationBlock;
    case "FlowGraphModuloBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphModuloBlock;
    case "FlowGraphMinBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphMinBlock;
    case "FlowGraphMaxBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphMaxBlock;
    case "FlowGraphClampBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphClampBlock;
    case "FlowGraphSaturateBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphSaturateBlock;
    case "FlowGraphMathInterpolationBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphMathInterpolationBlock;
    case "FlowGraphEqualityBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphEqualityBlock;
    case "FlowGraphLessThanBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphLessThanBlock;
    case "FlowGraphLessThanOrEqualBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphLessThanOrEqualBlock;
    case "FlowGraphGreaterThanBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphGreaterThanBlock;
    case "FlowGraphGreaterThanOrEqualBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphGreaterThanOrEqualBlock;
    case "FlowGraphIsNaNBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphIsNanBlock;
    case "FlowGraphIsInfBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphIsInfinityBlock;
    case "FlowGraphDegToRadBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphDegToRadBlock;
    case "FlowGraphRadToDegBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphRadToDegBlock;
    case "FlowGraphSinBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphSinBlock;
    case "FlowGraphCosBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphCosBlock;
    case "FlowGraphTanBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphTanBlock;
    case "FlowGraphASinBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphAsinBlock;
    case "FlowGraphACosBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphAcosBlock;
    case "FlowGraphATanBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphAtanBlock;
    case "FlowGraphATan2Block":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphAtan2Block;
    case "FlowGraphSinhBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphSinhBlock;
    case "FlowGraphCoshBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphCoshBlock;
    case "FlowGraphTanhBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphTanhBlock;
    case "FlowGraphASinhBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphAsinhBlock;
    case "FlowGraphACoshBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphAcoshBlock;
    case "FlowGraphATanhBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphAtanhBlock;
    case "FlowGraphExponentialBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphExpBlock;
    case "FlowGraphLogBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphLogBlock;
    case "FlowGraphLog2Block":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphLog2Block;
    case "FlowGraphLog10Block":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphLog10Block;
    case "FlowGraphSquareRootBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphSquareRootBlock;
    case "FlowGraphPowerBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphPowerBlock;
    case "FlowGraphCubeRootBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphCubeRootBlock;
    case "FlowGraphBitwiseAndBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphBitwiseAndBlock;
    case "FlowGraphBitwiseOrBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphBitwiseOrBlock;
    case "FlowGraphBitwiseNotBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphBitwiseNotBlock;
    case "FlowGraphBitwiseXorBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphBitwiseXorBlock;
    case "FlowGraphBitwiseLeftShiftBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphBitwiseLeftShiftBlock;
    case "FlowGraphBitwiseRightShiftBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphBitwiseRightShiftBlock;
    case "FlowGraphLengthBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphLengthBlock;
    case "FlowGraphNormalizeBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphNormalizeBlock;
    case "FlowGraphDotBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphDotBlock;
    case "FlowGraphCrossBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphCrossBlock;
    case "FlowGraphRotate2DBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphRotate2DBlock;
    case "FlowGraphRotate3DBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphRotate3DBlock;
    case "FlowGraphTransposeBlock":
      return async () => (await import("./flowGraphMatrixMathBlocks-VGUFWP3C.js")).FlowGraphTransposeBlock;
    case "FlowGraphDeterminantBlock":
      return async () => (await import("./flowGraphMatrixMathBlocks-VGUFWP3C.js")).FlowGraphDeterminantBlock;
    case "FlowGraphInvertMatrixBlock":
      return async () => (await import("./flowGraphMatrixMathBlocks-VGUFWP3C.js")).FlowGraphInvertMatrixBlock;
    case "FlowGraphMatrixMultiplicationBlock":
      return async () => (await import("./flowGraphMatrixMathBlocks-VGUFWP3C.js")).FlowGraphMatrixMultiplicationBlock;
    case "FlowGraphBranchBlock":
      return async () => (await import("./flowGraphBranchBlock-ZTUSI7SN.js")).FlowGraphBranchBlock;
    case "FlowGraphSetDelayBlock":
      return async () => (await import("./flowGraphSetDelayBlock-WQJRQUDY.js")).FlowGraphSetDelayBlock;
    case "FlowGraphCancelDelayBlock":
      return async () => (await import("./flowGraphCancelDelayBlock-H6YS4M5V.js")).FlowGraphCancelDelayBlock;
    case "FlowGraphCallCounterBlock":
      return async () => (await import("./flowGraphCounterBlock-2IODMHKQ.js")).FlowGraphCallCounterBlock;
    case "FlowGraphDebounceBlock":
      return async () => (await import("./flowGraphDebounceBlock-HGBJU4XX.js")).FlowGraphDebounceBlock;
    case "FlowGraphThrottleBlock":
      return async () => (await import("./flowGraphThrottleBlock-X66OQTYE.js")).FlowGraphThrottleBlock;
    case "FlowGraphDoNBlock":
      return async () => (await import("./flowGraphDoNBlock-GFKG6VEB.js")).FlowGraphDoNBlock;
    case "FlowGraphFlipFlopBlock":
      return async () => (await import("./flowGraphFlipFlopBlock-A2OOAM25.js")).FlowGraphFlipFlopBlock;
    case "FlowGraphForLoopBlock":
      return async () => (await import("./flowGraphForLoopBlock-VXKG3VVK.js")).FlowGraphForLoopBlock;
    case "FlowGraphMultiGateBlock":
      return async () => (await import("./flowGraphMultiGateBlock-CQAVJN56.js")).FlowGraphMultiGateBlock;
    case "FlowGraphSequenceBlock":
      return async () => (await import("./flowGraphSequenceBlock-TARZ7D5X.js")).FlowGraphSequenceBlock;
    case "FlowGraphSwitchBlock":
      return async () => (await import("./flowGraphSwitchBlock-ETFWUIXT.js")).FlowGraphSwitchBlock;
    case "FlowGraphWaitAllBlock":
      return async () => (await import("./flowGraphWaitAllBlock-RQ45QFIJ.js")).FlowGraphWaitAllBlock;
    case "FlowGraphWhileLoopBlock":
      return async () => (await import("./flowGraphWhileLoopBlock-F3FLRH26.js")).FlowGraphWhileLoopBlock;
    case "FlowGraphConsoleLogBlock":
      return async () => (await import("./flowGraphConsoleLogBlock-4K2S7I43.js")).FlowGraphConsoleLogBlock;
    case "FlowGraphConditionalBlock":
      return async () => (await import("./flowGraphConditionalDataBlock-OOS4DDNG.js")).FlowGraphConditionalDataBlock;
    case "FlowGraphConstantBlock":
      return async () => (await import("./flowGraphConstantBlock-EMNIKO5J.js")).FlowGraphConstantBlock;
    case "FlowGraphTransformCoordinatesSystemBlock":
      return async () => (await import("./flowGraphTransformCoordinatesSystemBlock-DT2HGEVD.js")).FlowGraphTransformCoordinatesSystemBlock;
    case "FlowGraphGetAssetBlock":
      return async () => (await import("./flowGraphGetAssetBlock-OUPAKAZP.js")).FlowGraphGetAssetBlock;
    case "FlowGraphGetPropertyBlock":
      return async () => (await import("./flowGraphGetPropertyBlock-ODRYWJM5.js")).FlowGraphGetPropertyBlock;
    case "FlowGraphSetPropertyBlock":
      return async () => (await import("./flowGraphSetPropertyBlock-4UQI2NQH.js")).FlowGraphSetPropertyBlock;
    case "FlowGraphGetVariableBlock":
      return async () => (await import("./flowGraphGetVariableBlock-LEYVHP4Y.js")).FlowGraphGetVariableBlock;
    case "FlowGraphSetVariableBlock":
      return async () => (await import("./flowGraphSetVariableBlock-RCWP23TR.js")).FlowGraphSetVariableBlock;
    case "FlowGraphJsonPointerParserBlock":
      return async () => (await import("./flowGraphJsonPointerParserBlock-CXYVLAM4.js")).FlowGraphJsonPointerParserBlock;
    case "FlowGraphLeadingZerosBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphLeadingZerosBlock;
    case "FlowGraphTrailingZerosBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphTrailingZerosBlock;
    case "FlowGraphOneBitsCounterBlock":
      return async () => (await import("./flowGraphMathBlocks-HXDYO55I.js")).FlowGraphOneBitsCounterBlock;
    case "FlowGraphCombineVector2Block":
      return async () => (await import("./flowGraphMathCombineExtractBlocks-KAID6JRJ.js")).FlowGraphCombineVector2Block;
    case "FlowGraphCombineVector3Block":
      return async () => (await import("./flowGraphMathCombineExtractBlocks-KAID6JRJ.js")).FlowGraphCombineVector3Block;
    case "FlowGraphCombineVector4Block":
      return async () => (await import("./flowGraphMathCombineExtractBlocks-KAID6JRJ.js")).FlowGraphCombineVector4Block;
    case "FlowGraphCombineMatrixBlock":
      return async () => (await import("./flowGraphMathCombineExtractBlocks-KAID6JRJ.js")).FlowGraphCombineMatrixBlock;
    case "FlowGraphExtractVector2Block":
      return async () => (await import("./flowGraphMathCombineExtractBlocks-KAID6JRJ.js")).FlowGraphExtractVector2Block;
    case "FlowGraphExtractVector3Block":
      return async () => (await import("./flowGraphMathCombineExtractBlocks-KAID6JRJ.js")).FlowGraphExtractVector3Block;
    case "FlowGraphExtractVector4Block":
      return async () => (await import("./flowGraphMathCombineExtractBlocks-KAID6JRJ.js")).FlowGraphExtractVector4Block;
    case "FlowGraphExtractMatrixBlock":
      return async () => (await import("./flowGraphMathCombineExtractBlocks-KAID6JRJ.js")).FlowGraphExtractMatrixBlock;
    case "FlowGraphTransformVectorBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphTransformBlock;
    case "FlowGraphTransformCoordinatesBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphTransformCoordinatesBlock;
    case "FlowGraphConjugateBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphConjugateBlock;
    case "FlowGraphAngleBetweenBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphAngleBetweenBlock;
    case "FlowGraphQuaternionFromAxisAngleBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphQuaternionFromAxisAngleBlock;
    case "FlowGraphAxisAngleFromQuaternionBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphAxisAngleFromQuaternionBlock;
    case "FlowGraphQuaternionFromDirectionsBlock":
      return async () => (await import("./flowGraphVectorMathBlocks-CAU7Y7OJ.js")).FlowGraphQuaternionFromDirectionsBlock;
    case "FlowGraphMatrixDecompose":
      return async () => (await import("./flowGraphMatrixMathBlocks-VGUFWP3C.js")).FlowGraphMatrixDecomposeBlock;
    case "FlowGraphMatrixCompose":
      return async () => (await import("./flowGraphMatrixMathBlocks-VGUFWP3C.js")).FlowGraphMatrixComposeBlock;
    case "FlowGraphBooleanToFloat":
      return async () => (await import("./flowGraphTypeToTypeBlocks-RVHVCBRV.js")).FlowGraphBooleanToFloat;
    case "FlowGraphBooleanToInt":
      return async () => (await import("./flowGraphTypeToTypeBlocks-RVHVCBRV.js")).FlowGraphBooleanToInt;
    case "FlowGraphFloatToBoolean":
      return async () => (await import("./flowGraphTypeToTypeBlocks-RVHVCBRV.js")).FlowGraphFloatToBoolean;
    case "FlowGraphIntToBoolean":
      return async () => (await import("./flowGraphTypeToTypeBlocks-RVHVCBRV.js")).FlowGraphIntToBoolean;
    case "FlowGraphIntToFloat":
      return async () => (await import("./flowGraphTypeToTypeBlocks-RVHVCBRV.js")).FlowGraphIntToFloat;
    case "FlowGraphFloatToInt":
      return async () => (await import("./flowGraphTypeToTypeBlocks-RVHVCBRV.js")).FlowGraphFloatToInt;
    case "FlowGraphEasingBlock":
      return async () => (await import("./flowGraphEasingBlock-YAG5W5ID.js")).FlowGraphEasingBlock;
    case "FlowGraphBezierCurveEasing":
      return async () => (await import("./flowGraphBezierCurveEasingBlock-XBGWVDXG.js")).FlowGraphBezierCurveEasingBlock;
    case "FlowGraphPointerOverEventBlock":
      return async () => (await import("./flowGraphPointerOverEventBlock-CKO2FUY5.js")).FlowGraphPointerOverEventBlock;
    case "FlowGraphPointerOutEventBlock":
      return async () => (await import("./flowGraphPointerOutEventBlock-7GXEGCOF.js")).FlowGraphPointerOutEventBlock;
    case "FlowGraphContextBlock":
      return async () => (await import("./flowGraphContextBlock-OT32HG7D.js")).FlowGraphContextBlock;
    case "FlowGraphArrayIndexBlock":
      return async () => (await import("./flowGraphArrayIndexBlock-5ZKTRKV7.js")).FlowGraphArrayIndexBlock;
    case "FlowGraphCodeExecutionBlock":
      return async () => (await import("./flowGraphCodeExecutionBlock-4FTBSH4Z.js")).FlowGraphCodeExecutionBlock;
    case "FlowGraphIndexOfBlock":
      return async () => (await import("./flowGraphIndexOfBlock-HJRMZGBM.js")).FlowGraphIndexOfBlock;
    case "FlowGraphFunctionReference":
      return async () => (await import("./flowGraphFunctionReferenceBlock-WVBE4EQB.js")).FlowGraphFunctionReferenceBlock;
    case "FlowGraphDataSwitchBlock":
      return async () => (await import("./flowGraphDataSwitchBlock-23XYPDX2.js")).FlowGraphDataSwitchBlock;
    default:
      if (CustomBlocks[blockName]) {
        return CustomBlocks[blockName];
      }
      throw new Error(`Unknown block name ${blockName}`);
  }
}

// node_modules/@babylonjs/core/FlowGraph/flowGraphParser.js
function GetDataOutConnectionByUniqueId(blocks, uniqueId) {
  for (const block of blocks) {
    for (const dataOut of block.dataOutputs) {
      if (dataOut.uniqueId === uniqueId) {
        return dataOut;
      }
    }
  }
  throw new Error("Could not find data out connection with unique id " + uniqueId);
}
function GetSignalInConnectionByUniqueId(blocks, uniqueId) {
  for (const block of blocks) {
    if (block instanceof FlowGraphExecutionBlock) {
      for (const signalIn of block.signalInputs) {
        if (signalIn.uniqueId === uniqueId) {
          return signalIn;
        }
      }
    }
  }
  throw new Error("Could not find signal in connection with unique id " + uniqueId);
}
async function ParseCoordinatorAsync(serializedObject, options) {
  const valueParseFunction = options.valueParseFunction ?? defaultValueParseFunction;
  const coordinator = new FlowGraphCoordinator({ scene: options.scene });
  if (serializedObject.dispatchEventsSynchronously) {
    coordinator.dispatchEventsSynchronously = serializedObject.dispatchEventsSynchronously;
  }
  await options.scene.whenReadyAsync();
  if (serializedObject._defaultValues) {
    for (const key in serializedObject._defaultValues) {
      const value = serializedObject._defaultValues[key];
      getRichTypeByFlowGraphType(key).defaultValue = value;
    }
  }
  await Promise.all(serializedObject._flowGraphs?.map(async (serializedGraph) => await ParseFlowGraphAsync(serializedGraph, { coordinator, valueParseFunction, pathConverter: options.pathConverter })));
  return coordinator;
}
async function ParseFlowGraphAsync(serializationObject, options) {
  const resolvedClasses = await Promise.all(serializationObject.allBlocks.map(async (serializedBlock) => {
    const classFactory = blockFactory(serializedBlock.className);
    return await classFactory();
  }));
  return ParseFlowGraph(serializationObject, options, resolvedClasses);
}
function ParseFlowGraph(serializationObject, options, resolvedClasses) {
  const graph = options.coordinator.createGraph();
  const blocks = [];
  const valueParseFunction = options.valueParseFunction ?? defaultValueParseFunction;
  for (let i = 0; i < serializationObject.allBlocks.length; i++) {
    const serializedBlock = serializationObject.allBlocks[i];
    const block = ParseFlowGraphBlockWithClassType(serializedBlock, { scene: options.coordinator.config.scene, pathConverter: options.pathConverter, assetsContainer: options.coordinator.config.scene, valueParseFunction }, resolvedClasses[i]);
    blocks.push(block);
    if (block instanceof FlowGraphEventBlock) {
      graph.addEventBlock(block);
    }
  }
  for (const block of blocks) {
    for (const dataIn of block.dataInputs) {
      for (const serializedConnection of dataIn.connectedPointIds) {
        const connection = GetDataOutConnectionByUniqueId(blocks, serializedConnection);
        dataIn.connectTo(connection);
      }
    }
    if (block instanceof FlowGraphExecutionBlock) {
      for (const signalOut of block.signalOutputs) {
        for (const serializedConnection of signalOut.connectedPointIds) {
          const connection = GetSignalInConnectionByUniqueId(blocks, serializedConnection);
          signalOut.connectTo(connection);
        }
      }
    }
  }
  for (const serializedContext of serializationObject.executionContexts) {
    ParseFlowGraphContext(serializedContext, { graph, valueParseFunction }, serializationObject.rightHanded);
  }
  return graph;
}
function ParseFlowGraphContext(serializationObject, options, rightHanded) {
  const result = options.graph.createContext();
  if (serializationObject.enableLogging) {
    result.enableLogging = true;
  }
  result.treatDataAsRightHanded = rightHanded || false;
  const valueParseFunction = options.valueParseFunction ?? defaultValueParseFunction;
  result.uniqueId = serializationObject.uniqueId;
  const scene = result.getScene();
  if (serializationObject._assetsContext) {
    const ac = serializationObject._assetsContext;
    const assetsContext = {
      meshes: ac.meshes?.map((m) => scene.getMeshById(m)),
      lights: ac.lights?.map((l) => scene.getLightByName(l)),
      cameras: ac.cameras?.map((c) => scene.getCameraByName(c)),
      materials: ac.materials?.map((m) => scene.getMaterialById(m)),
      textures: ac.textures?.map((t) => scene.getTextureByName(t)),
      animations: ac.animations?.map((a) => scene.animations.find((anim) => anim.name === a)),
      skeletons: ac.skeletons?.map((s) => scene.getSkeletonByName(s)),
      particleSystems: ac.particleSystems?.map((ps) => scene.getParticleSystemById(ps)),
      animationGroups: ac.animationGroups?.map((ag) => scene.getAnimationGroupByName(ag)),
      transformNodes: ac.transformNodes?.map((tn) => scene.getTransformNodeById(tn)),
      rootNodes: [],
      multiMaterials: [],
      morphTargetManagers: [],
      geometries: [],
      actionManagers: [],
      environmentTexture: null,
      postProcesses: [],
      sounds: null,
      effectLayers: [],
      layers: [],
      reflectionProbes: [],
      lensFlareSystems: [],
      proceduralTextures: [],
      getNodes: function() {
        throw new Error("Function not implemented.");
      }
    };
    result.assetsContext = assetsContext;
  }
  for (const key in serializationObject._userVariables) {
    const value = valueParseFunction(key, serializationObject._userVariables, result.assetsContext, scene);
    result.userVariables[key] = value;
  }
  for (const key in serializationObject._connectionValues) {
    const value = valueParseFunction(key, serializationObject._connectionValues, result.assetsContext, scene);
    result._setConnectionValueByKey(key, value);
  }
  return result;
}
async function ParseBlockAsync(serializationObject, parseOptions) {
  const classFactory = blockFactory(serializationObject.className);
  const classType = await classFactory();
  return ParseFlowGraphBlockWithClassType(serializationObject, parseOptions, classType);
}
function ParseFlowGraphBlockWithClassType(serializationObject, parseOptions, classType) {
  const parsedConfig = {};
  const valueParseFunction = parseOptions.valueParseFunction ?? defaultValueParseFunction;
  if (serializationObject.config) {
    for (const key in serializationObject.config) {
      parsedConfig[key] = valueParseFunction(key, serializationObject.config, parseOptions.assetsContainer || parseOptions.scene, parseOptions.scene);
    }
  }
  if (needsPathConverter(serializationObject.className)) {
    if (!parseOptions.pathConverter) {
      throw new Error("Path converter is required for this block");
    }
    parsedConfig.pathConverter = parseOptions.pathConverter;
  }
  const obj = new classType(parsedConfig);
  obj.uniqueId = serializationObject.uniqueId;
  for (let i = 0; i < serializationObject.dataInputs.length; i++) {
    const dataInput = obj.getDataInput(serializationObject.dataInputs[i].name);
    if (dataInput) {
      dataInput.deserialize(serializationObject.dataInputs[i]);
    } else {
      throw new Error("Could not find data input with name " + serializationObject.dataInputs[i].name + " in block " + serializationObject.className);
    }
  }
  for (let i = 0; i < serializationObject.dataOutputs.length; i++) {
    const dataOutput = obj.getDataOutput(serializationObject.dataOutputs[i].name);
    if (dataOutput) {
      dataOutput.deserialize(serializationObject.dataOutputs[i]);
    } else {
      throw new Error("Could not find data output with name " + serializationObject.dataOutputs[i].name + " in block " + serializationObject.className);
    }
  }
  obj.metadata = serializationObject.metadata;
  obj.deserialize && obj.deserialize(serializationObject);
  return obj;
}
function ParseGraphConnectionWithClassType(serializationObject = {}, ownerBlock, classType) {
  const connection = new classType(serializationObject.name, serializationObject._connectionType, ownerBlock);
  connection.deserialize(serializationObject);
  return connection;
}
function ParseGraphDataConnection(serializationObject, ownerBlock, classType) {
  const richType = ParseRichType(serializationObject.richType);
  const defaultValue = serializationObject.defaultValue;
  const connection = new classType(serializationObject.name, serializationObject._connectionType, ownerBlock, richType, defaultValue, !!serializationObject._optional);
  connection.deserialize(serializationObject);
  return connection;
}
function ParseRichType(serializationObject) {
  return new RichType(serializationObject.typeName, serializationObject.defaultValue);
}

// node_modules/@babylonjs/core/Materials/Textures/cubeTexture.js
var DefaultLodScale = 0.8;
var CubeTexture = class _CubeTexture extends BaseTexture {
  /**
   * Gets or sets the size of the bounding box associated with the cube texture
   * When defined, the cubemap will switch to local mode
   * @see https://community.arm.com/graphics/b/blog/posts/reflections-based-on-local-cubemaps-in-unity
   * @example https://www.babylonjs-playground.com/#RNASML
   */
  set boundingBoxSize(value) {
    if (this._boundingBoxSize && this._boundingBoxSize.equals(value)) {
      return;
    }
    this._boundingBoxSize = value;
    const scene = this.getScene();
    if (scene) {
      scene.markAllMaterialsAsDirty(1);
    }
  }
  /**
   * Returns the bounding box size
   * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/reflectionTexture#using-local-cubemap-mode
   */
  get boundingBoxSize() {
    return this._boundingBoxSize;
  }
  /**
   * Sets texture matrix rotation angle around Y axis in radians.
   */
  set rotationY(value) {
    this._rotationY = value;
    this.setReflectionTextureMatrix(Matrix.RotationY(this._rotationY));
  }
  /**
   * Gets texture matrix rotation angle around Y axis radians.
   */
  get rotationY() {
    return this._rotationY;
  }
  /**
   * Are mip maps generated for this texture or not.
   */
  get noMipmap() {
    return this._noMipmap;
  }
  /**
   * Gets the forced extension (if any)
   */
  get forcedExtension() {
    return this._forcedExtension;
  }
  /**
   * Creates a cube texture from an array of image urls
   * @param files defines an array of image urls
   * @param scene defines the hosting scene
   * @param noMipmap specifies if mip maps are not used
   * @returns a cube texture
   */
  static CreateFromImages(files, scene, noMipmap) {
    let rootUrlKey = "";
    for (const url of files) {
      rootUrlKey += url;
    }
    return new _CubeTexture(rootUrlKey, scene, null, noMipmap, files);
  }
  /**
   * Creates and return a texture created from prefilterd data by tools like IBL Baker or Lys.
   * @param url defines the url of the prefiltered texture
   * @param scene defines the scene the texture is attached to
   * @param forcedExtension defines the extension of the file if different from the url
   * @param createPolynomials defines whether or not to create polynomial harmonics from the texture data if necessary
   * @returns the prefiltered texture
   */
  static CreateFromPrefilteredData(url, scene, forcedExtension = null, createPolynomials = true) {
    const oldValue = scene.useDelayedTextureLoading;
    scene.useDelayedTextureLoading = false;
    const result = new _CubeTexture(url, scene, null, false, null, null, null, void 0, true, forcedExtension, createPolynomials);
    scene.useDelayedTextureLoading = oldValue;
    return result;
  }
  /**
   * Creates a cube texture to use with reflection for instance. It can be based upon dds or six images as well
   * as prefiltered data.
   * @param rootUrl defines the url of the texture or the root name of the six images
   * @param sceneOrEngine defines the scene or engine the texture is attached to
   * @param extensionsOrOptions defines the suffixes add to the picture name in case six images are in use like _px.jpg or set of all options to create the cube texture
   * @param noMipmap defines if mipmaps should be created or not
   * @param files defines the six files to load for the different faces in that order: px, py, pz, nx, ny, nz
   * @param onLoad defines a callback triggered at the end of the file load if no errors occurred
   * @param onError defines a callback triggered in case of error during load
   * @param format defines the internal format to use for the texture once loaded
   * @param prefiltered defines whether or not the texture is created from prefiltered data
   * @param forcedExtension defines the extensions to use (force a special type of file to load) in case it is different from the file name
   * @param createPolynomials defines whether or not to create polynomial harmonics from the texture data if necessary
   * @param lodScale defines the scale applied to environment texture. This manages the range of LOD level used for IBL according to the roughness
   * @param lodOffset defines the offset applied to environment texture. This manages first LOD level used for IBL according to the roughness
   * @param loaderOptions options to be passed to the loader
   * @param useSRGBBuffer Defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU) (default: false)
   * @returns the cube texture
   */
  constructor(rootUrl, sceneOrEngine, extensionsOrOptions = null, noMipmap = false, files = null, onLoad = null, onError = null, format = 5, prefiltered = false, forcedExtension = null, createPolynomials = false, lodScale = DefaultLodScale, lodOffset = 0, loaderOptions, useSRGBBuffer) {
    super(sceneOrEngine);
    this.onLoadObservable = new Observable();
    this.boundingBoxPosition = Vector3.Zero();
    this._rotationY = 0;
    this._files = null;
    this._forcedExtension = null;
    this._extensions = null;
    this._textureMatrixRefraction = new Matrix();
    this._buffer = null;
    this.name = rootUrl;
    this.url = rootUrl;
    this._noMipmap = noMipmap;
    this.hasAlpha = false;
    this.isCube = true;
    this._textureMatrix = Matrix.Identity();
    this.coordinatesMode = Texture.CUBIC_MODE;
    let extensions = null;
    let buffer = null;
    if (extensionsOrOptions !== null && !Array.isArray(extensionsOrOptions)) {
      extensions = extensionsOrOptions.extensions ?? null;
      this._noMipmap = extensionsOrOptions.noMipmap ?? false;
      files = extensionsOrOptions.files ?? null;
      buffer = extensionsOrOptions.buffer ?? null;
      this._format = extensionsOrOptions.format ?? 5;
      prefiltered = extensionsOrOptions.prefiltered ?? false;
      forcedExtension = extensionsOrOptions.forcedExtension ?? null;
      this._createPolynomials = extensionsOrOptions.createPolynomials ?? false;
      this._lodScale = extensionsOrOptions.lodScale ?? DefaultLodScale;
      this._lodOffset = extensionsOrOptions.lodOffset ?? 0;
      this._loaderOptions = extensionsOrOptions.loaderOptions;
      this._useSRGBBuffer = extensionsOrOptions.useSRGBBuffer;
      onLoad = extensionsOrOptions.onLoad ?? null;
      onError = extensionsOrOptions.onError ?? null;
    } else {
      this._noMipmap = noMipmap;
      this._format = format;
      this._createPolynomials = createPolynomials;
      extensions = extensionsOrOptions;
      this._loaderOptions = loaderOptions;
      this._useSRGBBuffer = useSRGBBuffer;
      this._lodScale = lodScale;
      this._lodOffset = lodOffset;
    }
    if (!rootUrl && !files) {
      return;
    }
    this.updateURL(rootUrl, forcedExtension, onLoad, prefiltered, onError, extensions, this.getScene()?.useDelayedTextureLoading, files, buffer);
  }
  /**
   * Get the current class name of the texture useful for serialization or dynamic coding.
   * @returns "CubeTexture"
   */
  getClassName() {
    return "CubeTexture";
  }
  /**
   * Update the url (and optional buffer) of this texture if url was null during construction.
   * @param url the url of the texture
   * @param forcedExtension defines the extension to use
   * @param onLoad callback called when the texture is loaded  (defaults to null)
   * @param prefiltered Defines whether the updated texture is prefiltered or not
   * @param onError callback called if there was an error during the loading process (defaults to null)
   * @param extensions defines the suffixes add to the picture name in case six images are in use like _px.jpg...
   * @param delayLoad defines if the texture should be loaded now (false by default)
   * @param files defines the six files to load for the different faces in that order: px, py, pz, nx, ny, nz
   * @param buffer the buffer to use instead of loading from the url
   */
  updateURL(url, forcedExtension = null, onLoad = null, prefiltered = false, onError = null, extensions = null, delayLoad = false, files = null, buffer = null) {
    if (!this.name || this.name.startsWith("data:")) {
      this.name = url;
    }
    this.url = url;
    if (forcedExtension) {
      this._forcedExtension = forcedExtension;
    }
    const lastDot = url.lastIndexOf(".");
    const extension = forcedExtension ? forcedExtension : lastDot > -1 ? url.substring(lastDot).toLowerCase() : "";
    const isDDS = extension.indexOf(".dds") === 0;
    const isEnv = extension.indexOf(".env") === 0;
    const isBasis = extension.indexOf(".basis") === 0;
    if (isEnv) {
      this.gammaSpace = false;
      this._prefiltered = false;
      this.anisotropicFilteringLevel = 1;
    } else {
      this._prefiltered = prefiltered;
      if (prefiltered) {
        this.gammaSpace = false;
        this.anisotropicFilteringLevel = 1;
      }
    }
    if (files) {
      this._files = files;
    } else {
      if (!isBasis && !isEnv && !isDDS && !extensions) {
        extensions = ["_px.jpg", "_py.jpg", "_pz.jpg", "_nx.jpg", "_ny.jpg", "_nz.jpg"];
      }
      this._files = this._files || [];
      this._files.length = 0;
      if (extensions) {
        for (let index = 0; index < extensions.length; index++) {
          this._files.push(url + extensions[index]);
        }
        this._extensions = extensions;
      }
    }
    this._buffer = buffer;
    if (delayLoad) {
      this.delayLoadState = 4;
      this._delayedOnLoad = onLoad;
      this._delayedOnError = onError;
    } else {
      this._loadTexture(onLoad, onError);
    }
  }
  /**
   * Delays loading of the cube texture
   * @param forcedExtension defines the extension to use
   */
  delayLoad(forcedExtension) {
    if (this.delayLoadState !== 4) {
      return;
    }
    if (forcedExtension) {
      this._forcedExtension = forcedExtension;
    }
    this.delayLoadState = 1;
    this._loadTexture(this._delayedOnLoad, this._delayedOnError);
  }
  /**
   * Returns the reflection texture matrix
   * @returns the reflection texture matrix
   */
  getReflectionTextureMatrix() {
    return this._textureMatrix;
  }
  /**
   * Sets the reflection texture matrix
   * @param value Reflection texture matrix
   */
  setReflectionTextureMatrix(value) {
    if (value.updateFlag === this._textureMatrix.updateFlag) {
      return;
    }
    if (value.isIdentity() !== this._textureMatrix.isIdentity()) {
      this.getScene()?.markAllMaterialsAsDirty(1, (mat) => mat.getActiveTextures().indexOf(this) !== -1);
    }
    this._textureMatrix = value;
    if (!this.getScene()?.useRightHandedSystem) {
      return;
    }
    const scale = TmpVectors.Vector3[0];
    const quat = TmpVectors.Quaternion[0];
    const trans = TmpVectors.Vector3[1];
    this._textureMatrix.decompose(scale, quat, trans);
    quat.z *= -1;
    quat.w *= -1;
    Matrix.ComposeToRef(scale, quat, trans, this._textureMatrixRefraction);
  }
  /**
   * Gets a suitable rotate/transform matrix when the texture is used for refraction.
   * There's a separate function from getReflectionTextureMatrix because refraction requires a special configuration of the matrix in right-handed mode.
   * @returns The refraction matrix
   */
  getRefractionTextureMatrix() {
    return this.getScene()?.useRightHandedSystem ? this._textureMatrixRefraction : this._textureMatrix;
  }
  _loadTexture(onLoad = null, onError = null) {
    const scene = this.getScene();
    const oldTexture = this._texture;
    this._texture = this._getFromCache(this.url, this._noMipmap, void 0, void 0, this._useSRGBBuffer, this.isCube);
    const onLoadProcessing = () => {
      this.onLoadObservable.notifyObservers(this);
      if (oldTexture) {
        oldTexture.dispose();
        this.getScene()?.markAllMaterialsAsDirty(1);
      }
      if (onLoad) {
        onLoad();
      }
    };
    const errorHandler = (message, exception) => {
      this._loadingError = true;
      this._errorObject = { message, exception };
      if (onError) {
        onError(message, exception);
      }
      Texture.OnTextureLoadErrorObservable.notifyObservers(this);
    };
    if (!this._texture) {
      if (this._prefiltered) {
        this._texture = this._getEngine().createPrefilteredCubeTexture(this.url, scene, this._lodScale, this._lodOffset, onLoad, errorHandler, this._format, this._forcedExtension, this._createPolynomials);
      } else {
        this._texture = this._getEngine().createCubeTexture(this.url, scene, this._files, this._noMipmap, onLoad, errorHandler, this._format, this._forcedExtension, false, this._lodScale, this._lodOffset, null, this._loaderOptions, !!this._useSRGBBuffer, this._buffer);
      }
      this._texture?.onLoadedObservable.add(() => this.onLoadObservable.notifyObservers(this));
    } else {
      if (this._texture.isReady) {
        Tools.SetImmediate(() => onLoadProcessing());
      } else {
        this._texture.onLoadedObservable.add(() => onLoadProcessing());
      }
    }
  }
  /**
   * Parses text to create a cube texture
   * @param parsedTexture define the serialized text to read from
   * @param scene defines the hosting scene
   * @param rootUrl defines the root url of the cube texture
   * @returns a cube texture
   */
  static Parse(parsedTexture, scene, rootUrl) {
    const texture = SerializationHelper.Parse(() => {
      let prefiltered = false;
      if (parsedTexture.prefiltered) {
        prefiltered = parsedTexture.prefiltered;
      }
      return new _CubeTexture(rootUrl + (parsedTexture.url ?? parsedTexture.name), scene, parsedTexture.extensions, false, parsedTexture.files || null, null, null, void 0, prefiltered, parsedTexture.forcedExtension);
    }, parsedTexture, scene);
    if (parsedTexture.boundingBoxPosition) {
      texture.boundingBoxPosition = Vector3.FromArray(parsedTexture.boundingBoxPosition);
    }
    if (parsedTexture.boundingBoxSize) {
      texture.boundingBoxSize = Vector3.FromArray(parsedTexture.boundingBoxSize);
    }
    if (parsedTexture.animations) {
      for (let animationIndex = 0; animationIndex < parsedTexture.animations.length; animationIndex++) {
        const parsedAnimation = parsedTexture.animations[animationIndex];
        const internalClass = GetClass("BABYLON.Animation");
        if (internalClass) {
          texture.animations.push(internalClass.Parse(parsedAnimation));
        }
      }
    }
    return texture;
  }
  /**
   * Makes a clone, or deep copy, of the cube texture
   * @returns a new cube texture
   */
  clone() {
    let uniqueId = 0;
    const newCubeTexture = SerializationHelper.Clone(() => {
      const cubeTexture = new _CubeTexture(this.url, this.getScene() || this._getEngine(), this._extensions, this._noMipmap, this._files);
      uniqueId = cubeTexture.uniqueId;
      return cubeTexture;
    }, this);
    newCubeTexture.uniqueId = uniqueId;
    return newCubeTexture;
  }
};
__decorate([
  serialize()
], CubeTexture.prototype, "url", void 0);
__decorate([
  serializeAsVector3()
], CubeTexture.prototype, "boundingBoxPosition", void 0);
__decorate([
  serializeAsVector3()
], CubeTexture.prototype, "boundingBoxSize", null);
__decorate([
  serialize("rotationY")
], CubeTexture.prototype, "rotationY", null);
__decorate([
  serialize("files")
], CubeTexture.prototype, "_files", void 0);
__decorate([
  serialize("forcedExtension")
], CubeTexture.prototype, "_forcedExtension", void 0);
__decorate([
  serialize("extensions")
], CubeTexture.prototype, "_extensions", void 0);
__decorate([
  serializeAsMatrix("textureMatrix")
], CubeTexture.prototype, "_textureMatrix", void 0);
__decorate([
  serializeAsMatrix("textureMatrixRefraction")
], CubeTexture.prototype, "_textureMatrixRefraction", void 0);
Texture._CubeTextureParser = CubeTexture.Parse;
RegisterClass("BABYLON.CubeTexture", CubeTexture);

// node_modules/@babylonjs/core/Lights/pointLight.js
Node.AddNodeConstructor("Light_Type_0", (name, scene) => {
  return () => new PointLight(name, Vector3.Zero(), scene);
});
var PointLight = class extends ShadowLight {
  /**
   * Getter: In case of direction provided, the shadow will not use a cube texture but simulate a spot shadow as a fallback
   * This specifies what angle the shadow will use to be created.
   *
   * It default to 90 degrees to work nicely with the cube texture generation for point lights shadow maps.
   */
  get shadowAngle() {
    return this._shadowAngle;
  }
  /**
   * Setter: In case of direction provided, the shadow will not use a cube texture but simulate a spot shadow as a fallback
   * This specifies what angle the shadow will use to be created.
   *
   * It default to 90 degrees to work nicely with the cube texture generation for point lights shadow maps.
   */
  set shadowAngle(value) {
    this._shadowAngle = value;
    this.forceProjectionMatrixCompute();
  }
  /**
   * Gets the direction if it has been set.
   * In case of direction provided, the shadow will not use a cube texture but simulate a spot shadow as a fallback
   */
  get direction() {
    return this._direction;
  }
  /**
   * In case of direction provided, the shadow will not use a cube texture but simulate a spot shadow as a fallback
   */
  set direction(value) {
    const previousNeedCube = this.needCube();
    this._direction = value;
    if (this.needCube() !== previousNeedCube && this._shadowGenerators) {
      const iterator = this._shadowGenerators.values();
      for (let key = iterator.next(); key.done !== true; key = iterator.next()) {
        const shadowGenerator = key.value;
        shadowGenerator.recreateShadowMap();
      }
    }
  }
  /**
   * Creates a PointLight object from the passed name and position (Vector3) and adds it in the scene.
   * A PointLight emits the light in every direction.
   * It can cast shadows.
   * If the scene camera is already defined and you want to set your PointLight at the camera position, just set it :
   * ```javascript
   * var pointLight = new PointLight("pl", camera.position, scene);
   * ```
   * Documentation : https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction
   * @param name The light friendly name
   * @param position The position of the point light in the scene
   * @param scene The scene the lights belongs to
   */
  constructor(name, position, scene) {
    super(name, scene);
    this._shadowAngle = Math.PI / 2;
    this.position = position;
  }
  /**
   * Returns the string "PointLight"
   * @returns the class name
   */
  getClassName() {
    return "PointLight";
  }
  /**
   * Returns the integer 0.
   * @returns The light Type id as a constant defines in Light.LIGHTTYPEID_x
   */
  // eslint-disable-next-line @typescript-eslint/naming-convention
  getTypeID() {
    return Light.LIGHTTYPEID_POINTLIGHT;
  }
  /**
   * Specifies whether or not the shadowmap should be a cube texture.
   * @returns true if the shadowmap needs to be a cube texture.
   */
  needCube() {
    return !this.direction;
  }
  /**
   * Returns a new Vector3 aligned with the PointLight cube system according to the passed cube face index (integer).
   * @param faceIndex The index of the face we are computed the direction to generate shadow
   * @returns The set direction in 2d mode otherwise the direction to the cubemap face if needCube() is true
   */
  getShadowDirection(faceIndex) {
    if (this.direction) {
      return super.getShadowDirection(faceIndex);
    } else {
      switch (faceIndex) {
        case 0:
          return new Vector3(1, 0, 0);
        case 1:
          return new Vector3(-1, 0, 0);
        case 2:
          return new Vector3(0, -1, 0);
        case 3:
          return new Vector3(0, 1, 0);
        case 4:
          return new Vector3(0, 0, 1);
        case 5:
          return new Vector3(0, 0, -1);
      }
    }
    return Vector3.Zero();
  }
  /**
   * Sets the passed matrix "matrix" as a left-handed perspective projection matrix with the following settings :
   * - fov = PI / 2
   * - aspect ratio : 1.0
   * - z-near and far equal to the active camera minZ and maxZ.
   * Returns the PointLight.
   * @param matrix
   * @param viewMatrix
   * @param renderList
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  _setDefaultShadowProjectionMatrix(matrix, viewMatrix, renderList) {
    const activeCamera = this.getScene().activeCamera;
    if (!activeCamera) {
      return;
    }
    const minZ = this.shadowMinZ !== void 0 ? this.shadowMinZ : activeCamera.minZ;
    const maxZ = this.shadowMaxZ !== void 0 ? this.shadowMaxZ : activeCamera.maxZ;
    const useReverseDepthBuffer = this.getScene().getEngine().useReverseDepthBuffer;
    Matrix.PerspectiveFovLHToRef(this.shadowAngle, 1, useReverseDepthBuffer ? maxZ : minZ, useReverseDepthBuffer ? minZ : maxZ, matrix, true, this._scene.getEngine().isNDCHalfZRange, void 0, useReverseDepthBuffer);
  }
  _buildUniformLayout() {
    this._uniformBuffer.addUniform("vLightData", 4);
    this._uniformBuffer.addUniform("vLightDiffuse", 4);
    this._uniformBuffer.addUniform("vLightSpecular", 4);
    this._uniformBuffer.addUniform("vLightFalloff", 4);
    this._uniformBuffer.addUniform("shadowsInfo", 3);
    this._uniformBuffer.addUniform("depthValues", 2);
    this._uniformBuffer.create();
  }
  /**
   * Sets the passed Effect "effect" with the PointLight transformed position (or position, if none) and passed name (string).
   * @param effect The effect to update
   * @param lightIndex The index of the light in the effect to update
   * @returns The point light
   */
  transferToEffect(effect, lightIndex) {
    if (this.computeTransformedInformation()) {
      this._uniformBuffer.updateFloat4("vLightData", this.transformedPosition.x - this._scene.floatingOriginOffset.x, this.transformedPosition.y - this._scene.floatingOriginOffset.y, this.transformedPosition.z - this._scene.floatingOriginOffset.z, 0, lightIndex);
    } else {
      this._uniformBuffer.updateFloat4("vLightData", this.position.x - this._scene.floatingOriginOffset.x, this.position.y - this._scene.floatingOriginOffset.y, this.position.z - this._scene.floatingOriginOffset.z, 0, lightIndex);
    }
    this._uniformBuffer.updateFloat4("vLightFalloff", this.range, this._inverseSquaredRange, 0, 0, lightIndex);
    return this;
  }
  transferToNodeMaterialEffect(effect, lightDataUniformName) {
    if (this.computeTransformedInformation()) {
      effect.setFloat3(lightDataUniformName, this.transformedPosition.x - this._scene.floatingOriginOffset.x, this.transformedPosition.y - this._scene.floatingOriginOffset.y, this.transformedPosition.z - this._scene.floatingOriginOffset.z);
    } else {
      effect.setFloat3(lightDataUniformName, this.position.x - this._scene.floatingOriginOffset.x, this.position.y - this._scene.floatingOriginOffset.y, this.position.z - this._scene.floatingOriginOffset.z);
    }
    return this;
  }
  /**
   * Prepares the list of defines specific to the light type.
   * @param defines the list of defines
   * @param lightIndex defines the index of the light for the effect
   */
  prepareLightSpecificDefines(defines, lightIndex) {
    defines["POINTLIGHT" + lightIndex] = true;
  }
};
__decorate([
  serialize()
], PointLight.prototype, "shadowAngle", null);
RegisterClass("BABYLON.PointLight", PointLight);

// node_modules/@babylonjs/core/Lights/LTC/ltcTextureTool.js
async function DecodeLTCTextureDataAsync() {
  const ltc1 = new Uint16Array(64 * 64 * 4);
  const ltc2 = new Uint16Array(64 * 64 * 4);
  const file = await Tools.LoadFileAsync(Tools.GetAssetUrl("https://assets.babylonjs.com/core/areaLights/areaLightsLTC.bin"));
  const ltcEncoded = new Uint16Array(file);
  const pixelCount = ltcEncoded.length / 8;
  for (let pixelIndex = 0; pixelIndex < pixelCount; pixelIndex++) {
    ltc1[pixelIndex * 4] = ltcEncoded[pixelIndex * 8];
    ltc1[pixelIndex * 4 + 1] = ltcEncoded[pixelIndex * 8 + 1];
    ltc1[pixelIndex * 4 + 2] = ltcEncoded[pixelIndex * 8 + 2];
    ltc1[pixelIndex * 4 + 3] = ltcEncoded[pixelIndex * 8 + 3];
    ltc2[pixelIndex * 4] = ltcEncoded[pixelIndex * 8 + 4];
    ltc2[pixelIndex * 4 + 1] = ltcEncoded[pixelIndex * 8 + 5];
    ltc2[pixelIndex * 4 + 2] = ltcEncoded[pixelIndex * 8 + 6];
    ltc2[pixelIndex * 4 + 3] = ltcEncoded[pixelIndex * 8 + 7];
  }
  return [ltc1, ltc2];
}

// node_modules/@babylonjs/core/Lights/areaLight.js
function CreateSceneLTCTextures(scene) {
  const useDelayedTextureLoading = scene.useDelayedTextureLoading;
  scene.useDelayedTextureLoading = false;
  const previousState = scene._blockEntityCollection;
  scene._blockEntityCollection = false;
  scene._ltcTextures = {
    LTC1: RawTexture.CreateRGBATexture(null, 64, 64, scene.getEngine(), false, false, 2, 2, 0, false, true),
    LTC2: RawTexture.CreateRGBATexture(null, 64, 64, scene.getEngine(), false, false, 2, 2, 0, false, true)
  };
  scene._blockEntityCollection = previousState;
  scene._ltcTextures.LTC1.wrapU = Texture.CLAMP_ADDRESSMODE;
  scene._ltcTextures.LTC1.wrapV = Texture.CLAMP_ADDRESSMODE;
  scene._ltcTextures.LTC2.wrapU = Texture.CLAMP_ADDRESSMODE;
  scene._ltcTextures.LTC2.wrapV = Texture.CLAMP_ADDRESSMODE;
  scene.useDelayedTextureLoading = useDelayedTextureLoading;
  DecodeLTCTextureDataAsync().then((textureData) => {
    if (scene._ltcTextures) {
      const ltc1 = scene._ltcTextures?.LTC1;
      ltc1.update(textureData[0]);
      const ltc2 = scene._ltcTextures?.LTC2;
      ltc2.update(textureData[1]);
      scene.onDisposeObservable.addOnce(() => {
        scene._ltcTextures?.LTC1.dispose();
        scene._ltcTextures?.LTC2.dispose();
      });
    }
  }).catch((error) => {
    Logger.Error(`Area Light fail to get LTC textures data. Error: ${error}`);
  });
}
var AreaLight = class extends Light {
  /**
   * Creates a area light object.
   * Documentation : https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction
   * @param name The friendly name of the light
   * @param position The position of the area light.
   * @param scene The scene the light belongs to
   */
  constructor(name, position, scene) {
    super(name, scene);
    this.position = position;
    if (!this._scene._ltcTextures) {
      CreateSceneLTCTextures(this._scene);
    }
  }
  transferTexturesToEffect(effect) {
    if (this._scene._ltcTextures) {
      effect.setTexture("areaLightsLTC1Sampler", this._scene._ltcTextures.LTC1);
      effect.setTexture("areaLightsLTC2Sampler", this._scene._ltcTextures.LTC2);
    }
    return this;
  }
  /**
   * Prepares the list of defines specific to the light type.
   * @param defines the list of defines
   * @param lightIndex defines the index of the light for the effect
   */
  prepareLightSpecificDefines(defines, lightIndex) {
    defines["AREALIGHT" + lightIndex] = true;
    defines["AREALIGHTUSED"] = true;
  }
  _isReady() {
    if (this._scene._ltcTextures) {
      return this._scene._ltcTextures.LTC1.isReady() && this._scene._ltcTextures.LTC2.isReady();
    }
    return false;
  }
};

// node_modules/@babylonjs/core/Lights/rectAreaLight.js
Node.AddNodeConstructor("Light_Type_4", (name, scene) => {
  return () => new RectAreaLight(name, Vector3.Zero(), 1, 1, scene);
});
var RectAreaLight = class extends AreaLight {
  /**
   * Rect Area Light width.
   */
  get width() {
    return this._width.x;
  }
  /**
   * Rect Area Light width.
   */
  set width(value) {
    this._width.x = value;
  }
  /**
   * Rect Area Light height.
   */
  get height() {
    return this._height.y;
  }
  /**
   * Rect Area Light height.
   */
  set height(value) {
    this._height.y = value;
  }
  /**
   * Creates a rectangular area light object.
   * Documentation : https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction
   * @param name The friendly name of the light
   * @param position The position of the area light.
   * @param width The width of the area light.
   * @param height The height of the area light.
   * @param scene The scene the light belongs to
   */
  constructor(name, position, width, height, scene) {
    super(name, position, scene);
    this._width = new Vector3(width, 0, 0);
    this._height = new Vector3(0, height, 0);
    this._pointTransformedPosition = Vector3.Zero();
    this._pointTransformedWidth = Vector3.Zero();
    this._pointTransformedHeight = Vector3.Zero();
  }
  /**
   * Returns the string "RectAreaLight"
   * @returns the class name
   */
  getClassName() {
    return "RectAreaLight";
  }
  /**
   * Returns the integer 4.
   * @returns The light Type id as a constant defines in Light.LIGHTTYPEID_x
   */
  // eslint-disable-next-line @typescript-eslint/naming-convention
  getTypeID() {
    return Light.LIGHTTYPEID_RECT_AREALIGHT;
  }
  _buildUniformLayout() {
    this._uniformBuffer.addUniform("vLightData", 4);
    this._uniformBuffer.addUniform("vLightDiffuse", 4);
    this._uniformBuffer.addUniform("vLightSpecular", 4);
    this._uniformBuffer.addUniform("vLightWidth", 4);
    this._uniformBuffer.addUniform("vLightHeight", 4);
    this._uniformBuffer.addUniform("shadowsInfo", 3);
    this._uniformBuffer.addUniform("depthValues", 2);
    this._uniformBuffer.create();
  }
  _computeTransformedInformation() {
    if (this.parent && this.parent.getWorldMatrix) {
      Vector3.TransformCoordinatesToRef(this.position, this.parent.getWorldMatrix(), this._pointTransformedPosition);
      Vector3.TransformNormalToRef(this._width, this.parent.getWorldMatrix(), this._pointTransformedWidth);
      Vector3.TransformNormalToRef(this._height, this.parent.getWorldMatrix(), this._pointTransformedHeight);
      return true;
    }
    return false;
  }
  /**
   * Sets the passed Effect "effect" with the PointLight transformed position (or position, if none) and passed name (string).
   * @param effect The effect to update
   * @param lightIndex The index of the light in the effect to update
   * @returns The point light
   */
  transferToEffect(effect, lightIndex) {
    if (this._computeTransformedInformation()) {
      this._uniformBuffer.updateFloat4("vLightData", this._pointTransformedPosition.x - this._scene.floatingOriginOffset.x, this._pointTransformedPosition.y - this._scene.floatingOriginOffset.y, this._pointTransformedPosition.z - this._scene.floatingOriginOffset.z, 0, lightIndex);
      this._uniformBuffer.updateFloat4("vLightWidth", this._pointTransformedWidth.x / 2, this._pointTransformedWidth.y / 2, this._pointTransformedWidth.z / 2, 0, lightIndex);
      this._uniformBuffer.updateFloat4("vLightHeight", this._pointTransformedHeight.x / 2, this._pointTransformedHeight.y / 2, this._pointTransformedHeight.z / 2, 0, lightIndex);
    } else {
      this._uniformBuffer.updateFloat4("vLightData", this.position.x - this._scene.floatingOriginOffset.x, this.position.y - this._scene.floatingOriginOffset.y, this.position.z - this._scene.floatingOriginOffset.z, 0, lightIndex);
      this._uniformBuffer.updateFloat4("vLightWidth", this._width.x / 2, this._width.y / 2, this._width.z / 2, 0, lightIndex);
      this._uniformBuffer.updateFloat4("vLightHeight", this._height.x / 2, this._height.y / 2, this._height.z / 2, 0, lightIndex);
    }
    return this;
  }
  transferToNodeMaterialEffect(effect, lightDataUniformName) {
    if (this._computeTransformedInformation()) {
      effect.setFloat3(lightDataUniformName, this._pointTransformedPosition.x - this._scene.floatingOriginOffset.x, this._pointTransformedPosition.y - this._scene.floatingOriginOffset.y, this._pointTransformedPosition.z - this._scene.floatingOriginOffset.z);
    } else {
      effect.setFloat3(lightDataUniformName, this.position.x - this._scene.floatingOriginOffset.x, this.position.y - this._scene.floatingOriginOffset.y, this.position.z - this._scene.floatingOriginOffset.z);
    }
    return this;
  }
};
__decorate([
  serialize()
], RectAreaLight.prototype, "width", null);
__decorate([
  serialize()
], RectAreaLight.prototype, "height", null);
RegisterClass("BABYLON.RectAreaLight", RectAreaLight);

// node_modules/@babylonjs/core/Materials/Textures/rawTexture2DArray.js
var RawTexture2DArray = class _RawTexture2DArray extends Texture {
  /**
   * Gets the number of layers of the texture
   */
  get depth() {
    return this._depth;
  }
  /**
   * Create a new RawTexture2DArray
   * @param data defines the data of the texture
   * @param width defines the width of the texture
   * @param height defines the height of the texture
   * @param depth defines the number of layers of the texture
   * @param format defines the texture format to use
   * @param scene defines the hosting scene
   * @param generateMipMaps defines a boolean indicating if mip levels should be generated (true by default)
   * @param invertY defines if texture must be stored with Y axis inverted
   * @param samplingMode defines the sampling mode to use (Texture.TRILINEAR_SAMPLINGMODE by default)
   * @param textureType defines the texture Type (Engine.TEXTURETYPE_UNSIGNED_BYTE, Engine.TEXTURETYPE_FLOAT...)
   * @param creationFlags specific flags to use when creating the texture (1 for storage textures, for eg)
   */
  constructor(data, width, height, depth, format, scene, generateMipMaps = true, invertY = false, samplingMode = Texture.TRILINEAR_SAMPLINGMODE, textureType = 0, creationFlags) {
    super(null, scene, !generateMipMaps, invertY);
    this.format = format;
    this._texture = scene.getEngine().createRawTexture2DArray(data, width, height, depth, format, generateMipMaps, invertY, samplingMode, null, textureType, creationFlags);
    this._depth = depth;
    this.is2DArray = true;
  }
  /**
   * Update the texture with new data
   * @param data defines the data to store in the texture
   */
  update(data) {
    if (!this._texture) {
      return;
    }
    this._getEngine().updateRawTexture2DArray(this._texture, data, this._texture.format, this._texture.invertY, null, this._texture.type);
  }
  /**
   * Creates a RGBA texture from some data.
   * @param data Define the texture data
   * @param width Define the width of the texture
   * @param height Define the height of the texture
   * @param depth defines the number of layers of the texture
   * @param scene defines the scene the texture will belong to
   * @param generateMipMaps Define whether or not to create mip maps for the texture
   * @param invertY define if the data should be flipped on Y when uploaded to the GPU
   * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
   * @param type define the format of the data (int, float... Engine.TEXTURETYPE_xxx)
   * @returns the RGBA texture
   */
  static CreateRGBATexture(data, width, height, depth, scene, generateMipMaps = true, invertY = false, samplingMode = 3, type = 0) {
    return new _RawTexture2DArray(data, width, height, depth, 5, scene, generateMipMaps, invertY, samplingMode, type);
  }
};

// node_modules/@babylonjs/core/Morph/morphTargetManager.js
var MorphTargetManager = class _MorphTargetManager {
  /**
   * Sets a boolean indicating that adding new target or updating an existing target will not update the underlying data buffers
   */
  set areUpdatesFrozen(block) {
    if (block) {
      this._blockCounter++;
    } else {
      this._blockCounter--;
      if (this._blockCounter <= 0) {
        this._blockCounter = 0;
        this._syncActiveTargets(this._forceUpdateWhenUnfrozen);
        this._forceUpdateWhenUnfrozen = false;
      }
    }
  }
  get areUpdatesFrozen() {
    return this._blockCounter > 0;
  }
  /**
   * Creates a new MorphTargetManager
   * @param scene defines the current scene
   */
  constructor(scene = null) {
    this._targets = new Array();
    this._targetInfluenceChangedObservers = new Array();
    this._targetDataLayoutChangedObservers = new Array();
    this._activeTargets = new SmartArray(16);
    this._supportsPositions = false;
    this._supportsNormals = false;
    this._supportsTangents = false;
    this._supportsUVs = false;
    this._supportsUV2s = false;
    this._supportsColors = false;
    this._vertexCount = 0;
    this._uniqueId = 0;
    this._tempInfluences = new Array();
    this._canUseTextureForTargets = false;
    this._blockCounter = 0;
    this._mustSynchronize = true;
    this._forceUpdateWhenUnfrozen = false;
    this._textureVertexStride = 0;
    this._textureWidth = 0;
    this._textureHeight = 1;
    this._parentContainer = null;
    this.optimizeInfluencers = true;
    this.enablePositionMorphing = true;
    this.enableNormalMorphing = true;
    this.enableTangentMorphing = true;
    this.enableUVMorphing = true;
    this.enableUV2Morphing = true;
    this.enableColorMorphing = true;
    this._numMaxInfluencers = 0;
    this._useTextureToStoreTargets = true;
    this.metadata = null;
    if (!scene) {
      scene = EngineStore.LastCreatedScene;
    }
    this._scene = scene;
    if (this._scene) {
      this._scene.addMorphTargetManager(this);
      this._uniqueId = this._scene.getUniqueId();
      const engineCaps = this._scene.getEngine().getCaps();
      this._canUseTextureForTargets = engineCaps.canUseGLVertexID && engineCaps.textureFloat && engineCaps.maxVertexTextureImageUnits > 0 && engineCaps.texture2DArrayMaxLayerCount > 1;
    }
  }
  /**
   * Gets or sets the maximum number of influencers (targets) (default value: 0).
   * Setting a value for this property can lead to a smoother experience, as only one shader will be compiled, which will use this value as the maximum number of influencers.
   * If you leave the value at 0 (default), a new shader will be compiled every time the number of active influencers changes. This can cause problems, as compiling a shader takes time.
   * If you assign a non-zero value to this property, you need to ensure that this value is greater than the maximum number of (active) influencers you'll need for this morph manager.
   * Otherwise, the number of active influencers will be truncated at the value you set for this property, which can lead to unexpected results.
   * Note that this property has no effect if "useTextureToStoreTargets" is false.
   * Note as well that if MorphTargetManager.ConstantTargetCountForTextureMode is greater than 0, this property will be ignored and the constant value will be used instead.
   */
  get numMaxInfluencers() {
    if (_MorphTargetManager.ConstantTargetCountForTextureMode > 0 && this.isUsingTextureForTargets) {
      return _MorphTargetManager.ConstantTargetCountForTextureMode;
    }
    return this._numMaxInfluencers;
  }
  set numMaxInfluencers(value) {
    if (this._numMaxInfluencers === value) {
      return;
    }
    this._numMaxInfluencers = value;
    this._mustSynchronize = true;
    this._syncActiveTargets();
  }
  /**
   * Gets the unique ID of this manager
   */
  get uniqueId() {
    return this._uniqueId;
  }
  /**
   * Gets the number of vertices handled by this manager
   */
  get vertexCount() {
    return this._vertexCount;
  }
  /**
   * Gets a boolean indicating if this manager supports morphing of positions
   */
  get supportsPositions() {
    return this._supportsPositions && this.enablePositionMorphing;
  }
  /**
   * Gets a boolean indicating if this manager supports morphing of normals
   */
  get supportsNormals() {
    return this._supportsNormals && this.enableNormalMorphing;
  }
  /**
   * Gets a boolean indicating if this manager supports morphing of tangents
   */
  get supportsTangents() {
    return this._supportsTangents && this.enableTangentMorphing;
  }
  /**
   * Gets a boolean indicating if this manager supports morphing of texture coordinates
   */
  get supportsUVs() {
    return this._supportsUVs && this.enableUVMorphing;
  }
  /**
   * Gets a boolean indicating if this manager supports morphing of texture coordinates 2
   */
  get supportsUV2s() {
    return this._supportsUV2s && this.enableUV2Morphing;
  }
  /**
   * Gets a boolean indicating if this manager supports morphing of colors
   */
  get supportsColors() {
    return this._supportsColors && this.enableColorMorphing;
  }
  /**
   * Gets a boolean indicating if this manager has data for morphing positions
   */
  get hasPositions() {
    return this._supportsPositions;
  }
  /**
   * Gets a boolean indicating if this manager has data for morphing normals
   */
  get hasNormals() {
    return this._supportsNormals;
  }
  /**
   * Gets a boolean indicating if this manager has data for morphing tangents
   */
  get hasTangents() {
    return this._supportsTangents;
  }
  /**
   * Gets a boolean indicating if this manager has data for morphing texture coordinates
   */
  get hasUVs() {
    return this._supportsUVs;
  }
  /**
   * Gets a boolean indicating if this manager has data for morphing texture coordinates 2
   */
  get hasUV2s() {
    return this._supportsUV2s;
  }
  /**
   * Gets a boolean indicating if this manager has data for morphing colors
   */
  get hasColors() {
    return this._supportsColors;
  }
  /**
   * Gets the number of targets stored in this manager
   */
  get numTargets() {
    return this._targets.length;
  }
  /**
   * Gets the number of influencers (ie. the number of targets with influences > 0)
   */
  get numInfluencers() {
    return this._activeTargets.length;
  }
  /**
   * Gets the list of influences (one per target)
   */
  get influences() {
    return this._influences;
  }
  /**
   * Gets or sets a boolean indicating that targets should be stored as a texture instead of using vertex attributes (default is true).
   * Please note that this option is not available if the hardware does not support it
   */
  get useTextureToStoreTargets() {
    return this._useTextureToStoreTargets;
  }
  set useTextureToStoreTargets(value) {
    if (this._useTextureToStoreTargets === value) {
      return;
    }
    this._useTextureToStoreTargets = value;
    this._mustSynchronize = true;
    this._syncActiveTargets();
  }
  /**
   * Gets a boolean indicating that the targets are stored into a texture (instead of as attributes)
   */
  get isUsingTextureForTargets() {
    return _MorphTargetManager.EnableTextureStorage && this.useTextureToStoreTargets && this._canUseTextureForTargets && !this._scene?.getEngine().getCaps().disableMorphTargetTexture;
  }
  /**
   * Gets the active target at specified index. An active target is a target with an influence > 0
   * @param index defines the index to check
   * @returns the requested target
   */
  getActiveTarget(index) {
    return this._activeTargets.data[index];
  }
  /**
   * Gets the target at specified index
   * @param index defines the index to check
   * @returns the requested target
   */
  getTarget(index) {
    return this._targets[index];
  }
  /**
   * Gets the first target with the specified name
   * @param name defines the name to check
   * @returns the requested target
   */
  getTargetByName(name) {
    for (const target of this._targets) {
      if (target.name === name) {
        return target;
      }
    }
    return null;
  }
  /**
   * Add a new target to this manager
   * @param target defines the target to add
   */
  addTarget(target) {
    this._targets.push(target);
    this._targetInfluenceChangedObservers.push(target.onInfluenceChanged.add((needUpdate) => {
      if (this.areUpdatesFrozen && needUpdate) {
        this._forceUpdateWhenUnfrozen = true;
      }
      this._syncActiveTargets(needUpdate);
    }));
    this._targetDataLayoutChangedObservers.push(target._onDataLayoutChanged.add(() => {
      this._mustSynchronize = true;
      this._syncActiveTargets();
    }));
    this._mustSynchronize = true;
    this._syncActiveTargets();
  }
  /**
   * Removes a target from the manager
   * @param target defines the target to remove
   */
  removeTarget(target) {
    const index = this._targets.indexOf(target);
    if (index >= 0) {
      this._targets.splice(index, 1);
      target.onInfluenceChanged.remove(this._targetInfluenceChangedObservers.splice(index, 1)[0]);
      target._onDataLayoutChanged.remove(this._targetDataLayoutChangedObservers.splice(index, 1)[0]);
      this._mustSynchronize = true;
      this._syncActiveTargets();
    }
    if (this._scene) {
      this._scene.stopAnimation(target);
    }
  }
  /**
   * @internal
   */
  _bind(effect) {
    effect.setFloat3("morphTargetTextureInfo", this._textureVertexStride, this._textureWidth, this._textureHeight);
    effect.setFloatArray("morphTargetTextureIndices", this._morphTargetTextureIndices);
    effect.setTexture("morphTargets", this._targetStoreTexture);
    effect.setFloat("morphTargetCount", this.numInfluencers);
  }
  /**
   * Clone the current manager
   * @returns a new MorphTargetManager
   */
  clone() {
    const copy = new _MorphTargetManager(this._scene);
    copy.areUpdatesFrozen = true;
    for (const target of this._targets) {
      copy.addTarget(target.clone());
    }
    copy.areUpdatesFrozen = false;
    copy.enablePositionMorphing = this.enablePositionMorphing;
    copy.enableNormalMorphing = this.enableNormalMorphing;
    copy.enableTangentMorphing = this.enableTangentMorphing;
    copy.enableUVMorphing = this.enableUVMorphing;
    copy.enableUV2Morphing = this.enableUV2Morphing;
    copy.enableColorMorphing = this.enableColorMorphing;
    copy.metadata = this.metadata;
    return copy;
  }
  /**
   * Serializes the current manager into a Serialization object
   * @returns the serialized object
   */
  serialize() {
    const serializationObject = {};
    serializationObject.id = this.uniqueId;
    serializationObject.targets = [];
    for (const target of this._targets) {
      serializationObject.targets.push(target.serialize());
    }
    if (this.metadata) {
      serializationObject.metadata = this.metadata;
    }
    return serializationObject;
  }
  _syncActiveTargets(needUpdate = false) {
    if (this.areUpdatesFrozen) {
      return;
    }
    const wasUsingTextureForTargets = !!this._targetStoreTexture;
    const isUsingTextureForTargets = this.isUsingTextureForTargets;
    if (this._mustSynchronize || wasUsingTextureForTargets !== isUsingTextureForTargets) {
      this._mustSynchronize = false;
      this.synchronize();
    }
    let influenceCount = 0;
    this._activeTargets.reset();
    if (!this._morphTargetTextureIndices || this._morphTargetTextureIndices.length !== this._targets.length) {
      this._morphTargetTextureIndices = new Float32Array(this._targets.length);
    }
    let targetIndex = -1;
    for (const target of this._targets) {
      targetIndex++;
      if (target.influence === 0 && this.optimizeInfluencers) {
        continue;
      }
      if (this._activeTargets.length >= _MorphTargetManager.MaxActiveMorphTargetsInVertexAttributeMode && !this.isUsingTextureForTargets) {
        break;
      }
      this._activeTargets.push(target);
      this._morphTargetTextureIndices[influenceCount] = targetIndex;
      this._tempInfluences[influenceCount++] = target.influence;
    }
    if (this._morphTargetTextureIndices.length !== influenceCount) {
      this._morphTargetTextureIndices = this._morphTargetTextureIndices.slice(0, influenceCount);
    }
    if (!this._influences || this._influences.length !== influenceCount) {
      this._influences = new Float32Array(influenceCount);
    }
    for (let index = 0; index < influenceCount; index++) {
      this._influences[index] = this._tempInfluences[index];
    }
    if (needUpdate && this._scene) {
      for (const mesh of this._scene.meshes) {
        if (mesh.morphTargetManager === this) {
          if (isUsingTextureForTargets) {
            mesh._markSubMeshesAsAttributesDirty();
          } else {
            mesh._syncGeometryWithMorphTargetManager();
          }
        }
      }
    }
  }
  /**
   * Synchronize the targets with all the meshes using this morph target manager
   */
  synchronize() {
    if (!this._scene || this.areUpdatesFrozen) {
      return;
    }
    const engine = this._scene.getEngine();
    this._supportsPositions = true;
    this._supportsNormals = true;
    this._supportsTangents = true;
    this._supportsUVs = true;
    this._supportsUV2s = true;
    this._supportsColors = true;
    this._vertexCount = 0;
    this._targetStoreTexture?.dispose();
    this._targetStoreTexture = null;
    if (this.isUsingTextureForTargets && this._targets.length > engine.getCaps().texture2DArrayMaxLayerCount) {
      this.useTextureToStoreTargets = false;
    }
    for (const target of this._targets) {
      this._supportsPositions = this._supportsPositions && target.hasPositions;
      this._supportsNormals = this._supportsNormals && target.hasNormals;
      this._supportsTangents = this._supportsTangents && target.hasTangents;
      this._supportsUVs = this._supportsUVs && target.hasUVs;
      this._supportsUV2s = this._supportsUV2s && target.hasUV2s;
      this._supportsColors = this._supportsColors && target.hasColors;
      const vertexCount = target.vertexCount;
      if (this._vertexCount === 0) {
        this._vertexCount = vertexCount;
      } else if (this._vertexCount !== vertexCount) {
        Logger.Error(`Incompatible target. Targets must all have the same vertices count. Current vertex count: ${this._vertexCount}, vertex count for target "${target.name}": ${vertexCount}`);
        return;
      }
    }
    if (this.isUsingTextureForTargets) {
      this._textureVertexStride = 0;
      this._supportsPositions && this._textureVertexStride++;
      this._supportsNormals && this._textureVertexStride++;
      this._supportsTangents && this._textureVertexStride++;
      this._supportsUVs && this._textureVertexStride++;
      this._supportsUV2s && this._textureVertexStride++;
      this._supportsColors && this._textureVertexStride++;
      this._textureWidth = this._vertexCount * this._textureVertexStride || 1;
      this._textureHeight = 1;
      const maxTextureSize = engine.getCaps().maxTextureSize;
      if (this._textureWidth > maxTextureSize) {
        this._textureHeight = Math.ceil(this._textureWidth / maxTextureSize);
        this._textureWidth = maxTextureSize;
      }
      const targetCount = this._targets.length;
      const data = new Float32Array(targetCount * this._textureWidth * this._textureHeight * 4);
      let offset = 0;
      for (let index = 0; index < targetCount; index++) {
        const target = this._targets[index];
        const positions = target.getPositions();
        const normals = target.getNormals();
        const uvs = target.getUVs();
        const tangents = target.getTangents();
        const uv2s = target.getUV2s();
        const colors = target.getColors();
        offset = index * this._textureWidth * this._textureHeight * 4;
        for (let vertex = 0; vertex < this._vertexCount; vertex++) {
          if (this._supportsPositions && positions) {
            data[offset] = positions[vertex * 3];
            data[offset + 1] = positions[vertex * 3 + 1];
            data[offset + 2] = positions[vertex * 3 + 2];
            offset += 4;
          }
          if (this._supportsNormals && normals) {
            data[offset] = normals[vertex * 3];
            data[offset + 1] = normals[vertex * 3 + 1];
            data[offset + 2] = normals[vertex * 3 + 2];
            offset += 4;
          }
          if (this._supportsUVs && uvs) {
            data[offset] = uvs[vertex * 2];
            data[offset + 1] = uvs[vertex * 2 + 1];
            offset += 4;
          }
          if (this._supportsTangents && tangents) {
            data[offset] = tangents[vertex * 3];
            data[offset + 1] = tangents[vertex * 3 + 1];
            data[offset + 2] = tangents[vertex * 3 + 2];
            offset += 4;
          }
          if (this._supportsUV2s && uv2s) {
            data[offset] = uv2s[vertex * 2];
            data[offset + 1] = uv2s[vertex * 2 + 1];
            offset += 4;
          }
          if (this._supportsColors && colors) {
            data[offset] = colors[vertex * 4];
            data[offset + 1] = colors[vertex * 4 + 1];
            data[offset + 2] = colors[vertex * 4 + 2];
            data[offset + 3] = colors[vertex * 4 + 3];
            offset += 4;
          }
        }
      }
      this._targetStoreTexture = RawTexture2DArray.CreateRGBATexture(data, this._textureWidth, this._textureHeight, targetCount, this._scene, false, false, 1, 1);
      this._targetStoreTexture.name = `Morph texture_${this.uniqueId}`;
    }
    for (const mesh of this._scene.meshes) {
      if (mesh.morphTargetManager === this) {
        mesh._syncGeometryWithMorphTargetManager();
      }
    }
  }
  /**
   * Release all resources
   */
  dispose() {
    if (this._targetStoreTexture) {
      this._targetStoreTexture.dispose();
    }
    this._targetStoreTexture = null;
    this.metadata = null;
    if (this._scene) {
      this._scene.removeMorphTargetManager(this);
      if (this._parentContainer) {
        const index = this._parentContainer.morphTargetManagers.indexOf(this);
        if (index > -1) {
          this._parentContainer.morphTargetManagers.splice(index, 1);
        }
        this._parentContainer = null;
      }
      for (const morph of this._targets) {
        this._scene.stopAnimation(morph);
      }
    }
  }
  // Statics
  /**
   * Creates a new MorphTargetManager from serialized data
   * @param serializationObject defines the serialized data
   * @param scene defines the hosting scene
   * @returns the new MorphTargetManager
   */
  static Parse(serializationObject, scene) {
    const result = new _MorphTargetManager(scene);
    for (const targetData of serializationObject.targets) {
      result.addTarget(MorphTarget.Parse(targetData, scene));
    }
    if (serializationObject.metadata) {
      result.metadata = serializationObject.metadata;
    }
    return result;
  }
};
MorphTargetManager.EnableTextureStorage = true;
MorphTargetManager.MaxActiveMorphTargetsInVertexAttributeMode = 8;
MorphTargetManager.ConstantTargetCountForTextureMode = 0;

// node_modules/@babylonjs/core/Materials/Textures/rawCubeTexture.js
var RawCubeTexture = class _RawCubeTexture extends CubeTexture {
  /**
   * Creates a cube texture where the raw buffers are passed in.
   * @param scene defines the scene the texture is attached to
   * @param data defines the array of data to use to create each face
   * @param size defines the size of the textures
   * @param format defines the format of the data
   * @param type defines the type of the data (like Engine.TEXTURETYPE_UNSIGNED_BYTE)
   * @param generateMipMaps  defines if the engine should generate the mip levels
   * @param invertY defines if data must be stored with Y axis inverted
   * @param samplingMode defines the required sampling mode (like Texture.NEAREST_SAMPLINGMODE)
   * @param compression defines the compression used (null by default)
   */
  constructor(scene, data, size, format = 5, type = 0, generateMipMaps = false, invertY = false, samplingMode = 3, compression = null) {
    super("", scene);
    this._texture = scene.getEngine().createRawCubeTexture(data, size, format, type, generateMipMaps, invertY, samplingMode, compression);
  }
  /**
   * Updates the raw cube texture.
   * @param data defines the data to store
   * @param format defines the data format
   * @param type defines the type fo the data (Engine.TEXTURETYPE_UNSIGNED_BYTE by default)
   * @param invertY defines if data must be stored with Y axis inverted
   * @param compression defines the compression used (null by default)
   */
  update(data, format, type, invertY, compression = null) {
    this._texture.getEngine().updateRawCubeTexture(this._texture, data, format, type, invertY, compression);
  }
  /**
   * Updates a raw cube texture with RGBD encoded data.
   * @param data defines the array of data [mipmap][face] to use to create each face
   * @param sphericalPolynomial defines the spherical polynomial for irradiance
   * @param lodScale defines the scale applied to environment texture. This manages the range of LOD level used for IBL according to the roughness
   * @param lodOffset defines the offset applied to environment texture. This manages first LOD level used for IBL according to the roughness
   * @returns a promise that resolves when the operation is complete
   */
  // eslint-disable-next-line @typescript-eslint/promise-function-async, no-restricted-syntax
  updateRGBDAsync(data, sphericalPolynomial = null, lodScale = 0.8, lodOffset = 0) {
    return _UpdateRGBDAsync(this._texture, data, sphericalPolynomial, lodScale, lodOffset).then(() => {
    });
  }
  /**
   * Clones the raw cube texture.
   * @returns a new cube texture
   */
  clone() {
    return SerializationHelper.Clone(() => {
      const scene = this.getScene();
      const internalTexture = this._texture;
      const texture = new _RawCubeTexture(scene, internalTexture._bufferViewArray, internalTexture.width, internalTexture.format, internalTexture.type, internalTexture.generateMipMaps, internalTexture.invertY, internalTexture.samplingMode, internalTexture._compression);
      if (internalTexture.source === 13) {
        texture.updateRGBDAsync(internalTexture._bufferViewArrayArray, internalTexture._sphericalPolynomial, internalTexture._lodGenerationScale, internalTexture._lodGenerationOffset);
      }
      return texture;
    }, this);
  }
};

// node_modules/@babylonjs/core/Materials/GaussianSplatting/gaussianSplattingMaterial.js
var GaussianSplattingMaterialDefines = class extends MaterialDefines {
  /**
   * Constructor of the defines.
   */
  constructor() {
    super();
    this.FOG = false;
    this.THIN_INSTANCES = true;
    this.LOGARITHMICDEPTH = false;
    this.CLIPPLANE = false;
    this.CLIPPLANE2 = false;
    this.CLIPPLANE3 = false;
    this.CLIPPLANE4 = false;
    this.CLIPPLANE5 = false;
    this.CLIPPLANE6 = false;
    this.SH_DEGREE = 0;
    this.COMPENSATION = false;
    this.rebuild();
  }
};
var GaussianSplattingMaterial = class _GaussianSplattingMaterial extends PushMaterial {
  /**
   * Instantiates a Gaussian Splatting Material in the given scene
   * @param name The friendly name of the material
   * @param scene The scene to add the material to
   */
  constructor(name, scene) {
    super(name, scene);
    this.kernelSize = _GaussianSplattingMaterial.KernelSize;
    this._compensation = _GaussianSplattingMaterial.Compensation;
    this._isDirty = false;
    this.backFaceCulling = false;
  }
  /**
   * Set compensation default value is `GaussianSplattingMaterial.Compensation`
   */
  set compensation(value) {
    this._isDirty = this._isDirty != value;
    this._compensation = value;
  }
  /**
   * Get compensation
   */
  get compensation() {
    return this._compensation;
  }
  /**
   * Gets a boolean indicating that current material needs to register RTT
   */
  get hasRenderTargetTextures() {
    return false;
  }
  /**
   * Specifies whether or not this material should be rendered in alpha test mode.
   * @returns false
   */
  needAlphaTesting() {
    return false;
  }
  /**
   * Specifies whether or not this material should be rendered in alpha blend mode.
   * @returns true
   */
  needAlphaBlending() {
    return true;
  }
  /**
   * Checks whether the material is ready to be rendered for a given mesh.
   * @param mesh The mesh to render
   * @param subMesh The submesh to check against
   * @returns true if all the dependencies are ready (Textures, Effects...)
   */
  isReadyForSubMesh(mesh, subMesh) {
    const useInstances = true;
    const drawWrapper = subMesh._drawWrapper;
    let defines = subMesh.materialDefines;
    if (defines && this._isDirty) {
      defines.markAsUnprocessed();
    }
    if (drawWrapper.effect && this.isFrozen) {
      if (drawWrapper._wasPreviouslyReady && drawWrapper._wasPreviouslyUsingInstances === useInstances) {
        return true;
      }
    }
    if (!subMesh.materialDefines) {
      defines = subMesh.materialDefines = new GaussianSplattingMaterialDefines();
    }
    const scene = this.getScene();
    if (this._isReadyForSubMesh(subMesh)) {
      return true;
    }
    const engine = scene.getEngine();
    const gsMesh = mesh;
    PrepareDefinesForMisc(mesh, scene, this._useLogarithmicDepth, this.pointsCloud, this.fogEnabled, false, defines, void 0, void 0, void 0, this._setVertexOutputInvariant);
    PrepareDefinesForFrameBoundValues(scene, engine, this, defines, useInstances, null, true);
    PrepareDefinesForAttributes(mesh, defines, false, false);
    if (engine.version > 1 || engine.isWebGPU) {
      defines["SH_DEGREE"] = gsMesh.shDegree;
    }
    const splatMaterial = gsMesh.material;
    defines["COMPENSATION"] = splatMaterial && splatMaterial.compensation ? splatMaterial.compensation : _GaussianSplattingMaterial.Compensation;
    if (defines.isDirty) {
      defines.markAsProcessed();
      scene.resetCachedMaterial();
      const attribs = [VertexBuffer.PositionKind, "splatIndex"];
      PrepareAttributesForInstances(attribs, defines);
      const uniforms = [
        "world",
        "view",
        "projection",
        "vFogInfos",
        "vFogColor",
        "logarithmicDepthConstant",
        "invViewport",
        "dataTextureSize",
        "focal",
        "eyePosition",
        "kernelSize",
        "viewDirectionFactor"
      ];
      const samplers = ["covariancesATexture", "covariancesBTexture", "centersTexture", "colorsTexture", "shTexture0", "shTexture1", "shTexture2"];
      const uniformBuffers = ["Scene", "Mesh"];
      PrepareUniformsAndSamplersList({
        uniformsNames: uniforms,
        uniformBuffersNames: uniformBuffers,
        samplers,
        defines
      });
      AddClipPlaneUniforms(uniforms);
      const join = defines.toString();
      const effect = scene.getEngine().createEffect("gaussianSplatting", {
        attributes: attribs,
        uniformsNames: uniforms,
        uniformBuffersNames: uniformBuffers,
        samplers,
        defines: join,
        onCompiled: this.onCompiled,
        onError: this.onError,
        indexParameters: {},
        shaderLanguage: this._shaderLanguage,
        extraInitializationsAsync: async () => {
          if (this._shaderLanguage === 1) {
            await Promise.all([import("./gaussianSplatting.fragment-WESN2GFT.js"), import("./gaussianSplatting.vertex-BZ33SHG2.js")]);
          } else {
            await Promise.all([import("./gaussianSplatting.fragment-KWGZCY5Q.js"), import("./gaussianSplatting.vertex-NYU6RSY3.js")]);
          }
        }
      }, engine);
      subMesh.setEffect(effect, defines, this._materialContext);
    }
    if (!subMesh.effect || !subMesh.effect.isReady()) {
      return false;
    }
    defines._renderId = scene.getRenderId();
    drawWrapper._wasPreviouslyReady = true;
    drawWrapper._wasPreviouslyUsingInstances = useInstances;
    this._isDirty = false;
    return true;
  }
  /**
   * Bind material effect for a specific Gaussian Splatting mesh
   * @param mesh Gaussian splatting mesh
   * @param effect Splatting material or node material
   * @param scene scene that contains mesh and camera used for rendering
   */
  static BindEffect(mesh, effect, scene) {
    const engine = scene.getEngine();
    const camera = scene.activeCamera;
    const renderWidth = engine.getRenderWidth();
    const renderHeight = engine.getRenderHeight();
    const gsMesh = mesh;
    const gsMaterial = gsMesh.material;
    const numberOfRigs = camera?.rigParent?.rigCameras.length || 1;
    effect.setFloat2("invViewport", 1 / (renderWidth / numberOfRigs), 1 / renderHeight);
    let focal = 1e3;
    if (camera) {
      const t = camera.getProjectionMatrix().m[5];
      if (camera.fovMode == Camera.FOVMODE_VERTICAL_FIXED) {
        focal = renderHeight * t / 2;
      } else {
        focal = renderWidth * t / 2;
      }
    }
    effect.setFloat2("focal", focal, focal);
    effect.setVector3("viewDirectionFactor", gsMesh.viewDirectionFactor);
    effect.setFloat("kernelSize", gsMaterial && gsMaterial.kernelSize ? gsMaterial.kernelSize : _GaussianSplattingMaterial.KernelSize);
    scene.bindEyePosition(effect, "eyePosition", true);
    if (gsMesh.covariancesATexture) {
      const textureSize = gsMesh.covariancesATexture.getSize();
      effect.setFloat2("dataTextureSize", textureSize.width, textureSize.height);
      effect.setTexture("covariancesATexture", gsMesh.covariancesATexture);
      effect.setTexture("covariancesBTexture", gsMesh.covariancesBTexture);
      effect.setTexture("centersTexture", gsMesh.centersTexture);
      effect.setTexture("colorsTexture", gsMesh.colorsTexture);
      if (gsMesh.shTextures) {
        for (let i = 0; i < gsMesh.shTextures?.length; i++) {
          effect.setTexture(`shTexture${i}`, gsMesh.shTextures[i]);
        }
      }
    }
  }
  /**
   * Binds the submesh to this material by preparing the effect and shader to draw
   * @param world defines the world transformation matrix
   * @param mesh defines the mesh containing the submesh
   * @param subMesh defines the submesh to bind the material to
   */
  bindForSubMesh(world, mesh, subMesh) {
    const scene = this.getScene();
    const defines = subMesh.materialDefines;
    if (!defines) {
      return;
    }
    const effect = subMesh.effect;
    if (!effect) {
      return;
    }
    this._activeEffect = effect;
    mesh.getMeshUniformBuffer().bindToEffect(effect, "Mesh");
    mesh.transferToEffect(world);
    const mustRebind = this._mustRebind(scene, effect, subMesh, mesh.visibility);
    if (mustRebind) {
      this.bindView(effect);
      this.bindViewProjection(effect);
      _GaussianSplattingMaterial.BindEffect(mesh, this._activeEffect, scene);
      BindClipPlane(effect, this, scene);
    } else if (scene.getEngine()._features.needToAlwaysBindUniformBuffers) {
      this._needToBindSceneUbo = true;
    }
    BindFogParameters(scene, mesh, effect);
    if (this.useLogarithmicDepth) {
      BindLogDepth(defines, effect, scene);
    }
    this._afterBind(mesh, this._activeEffect, subMesh);
  }
  /**
   * Clones the material.
   * @param name The cloned name.
   * @returns The cloned material.
   */
  clone(name) {
    return SerializationHelper.Clone(() => new _GaussianSplattingMaterial(name, this.getScene()), this);
  }
  /**
   * Serializes the current material to its JSON representation.
   * @returns The JSON representation.
   */
  serialize() {
    const serializationObject = super.serialize();
    serializationObject.customType = "BABYLON.GaussianSplattingMaterial";
    return serializationObject;
  }
  /**
   * Gets the class name of the material
   * @returns "GaussianSplattingMaterial"
   */
  getClassName() {
    return "GaussianSplattingMaterial";
  }
  /**
   * Parse a JSON input to create back a Gaussian Splatting material.
   * @param source The JSON data to parse
   * @param scene The scene to create the parsed material in
   * @param rootUrl The root url of the assets the material depends upon
   * @returns the instantiated GaussianSplattingMaterial.
   */
  static Parse(source, scene, rootUrl) {
    return SerializationHelper.Parse(() => new _GaussianSplattingMaterial(source.name, scene), source, scene, rootUrl);
  }
};
GaussianSplattingMaterial.KernelSize = 0.3;
GaussianSplattingMaterial.Compensation = false;
RegisterClass("BABYLON.GaussianSplattingMaterial", GaussianSplattingMaterial);

// node_modules/@babylonjs/core/Meshes/Compression/dracoDecoder.js
var DracoDecoder = class _DracoDecoder extends DracoCodec {
  /**
   * Returns true if the decoder's `DefaultConfiguration` is available.
   */
  static get DefaultAvailable() {
    return _IsConfigurationAvailable(_DracoDecoder.DefaultConfiguration);
  }
  /**
   * Default instance for the DracoDecoder.
   */
  static get Default() {
    _DracoDecoder._Default ?? (_DracoDecoder._Default = new _DracoDecoder());
    return _DracoDecoder._Default;
  }
  /**
   * Reset the default DracoDecoder object to null and disposing the removed default instance.
   * Note that if the workerPool is a member of the static DefaultConfiguration object it is recommended not to run dispose,
   * unless the static worker pool is no longer needed.
   * @param skipDispose set to true to not dispose the removed default instance
   */
  static ResetDefault(skipDispose) {
    if (_DracoDecoder._Default) {
      if (!skipDispose) {
        _DracoDecoder._Default.dispose();
      }
      _DracoDecoder._Default = null;
    }
  }
  _isModuleAvailable() {
    return typeof DracoDecoderModule !== "undefined";
  }
  async _createModuleAsync(wasmBinary, jsModule) {
    const module = await (jsModule || DracoDecoderModule)({ wasmBinary });
    return { module };
  }
  _getWorkerContent() {
    return `${DecodeMesh}(${DecoderWorkerFunction})()`;
  }
  /**
   * Creates a new Draco decoder.
   * @param configuration Optional override of the configuration for the DracoDecoder. If not provided, defaults to {@link DracoDecoder.DefaultConfiguration}.
   */
  constructor(configuration = _DracoDecoder.DefaultConfiguration) {
    super(configuration);
  }
  /**
   * Decode Draco compressed mesh data to mesh data.
   * @param data The ArrayBuffer or ArrayBufferView of the compressed Draco data
   * @param attributes A map of attributes from vertex buffer kinds to Draco unique ids
   * @param gltfNormalizedOverride A map of attributes from vertex buffer kinds to normalized flags to override the Draco normalization
   * @returns A promise that resolves with the decoded mesh data
   */
  // eslint-disable-next-line @typescript-eslint/promise-function-async, no-restricted-syntax
  decodeMeshToMeshDataAsync(data, attributes, gltfNormalizedOverride) {
    const dataView = data instanceof ArrayBuffer ? new Int8Array(data) : new Int8Array(data.buffer, data.byteOffset, data.byteLength);
    const applyGltfNormalizedOverride = (kind, normalized) => {
      if (gltfNormalizedOverride && gltfNormalizedOverride[kind] !== void 0) {
        if (normalized !== gltfNormalizedOverride[kind]) {
          Logger.Warn(`Normalized flag from Draco data (${normalized}) does not match normalized flag from glTF accessor (${gltfNormalizedOverride[kind]}). Using flag from glTF accessor.`);
        }
        return gltfNormalizedOverride[kind];
      } else {
        return normalized;
      }
    };
    if (this._workerPoolPromise) {
      return this._workerPoolPromise.then(async (workerPool) => {
        return await new Promise((resolve, reject) => {
          workerPool.push((worker, onComplete) => {
            let resultIndices = null;
            const resultAttributes = [];
            const onError = (error) => {
              worker.removeEventListener("error", onError);
              worker.removeEventListener("message", onMessage);
              reject(error);
              onComplete();
            };
            const onMessage = (event) => {
              const message = event.data;
              switch (message.id) {
                case "indices": {
                  resultIndices = message.data;
                  break;
                }
                case "attribute": {
                  resultAttributes.push({
                    kind: message.kind,
                    data: message.data,
                    size: message.size,
                    byteOffset: message.byteOffset,
                    byteStride: message.byteStride,
                    normalized: applyGltfNormalizedOverride(message.kind, message.normalized)
                  });
                  break;
                }
                case "decodeMeshDone": {
                  worker.removeEventListener("error", onError);
                  worker.removeEventListener("message", onMessage);
                  resolve({ indices: resultIndices, attributes: resultAttributes, totalVertices: message.totalVertices });
                  onComplete();
                  break;
                }
              }
            };
            worker.addEventListener("error", onError);
            worker.addEventListener("message", onMessage);
            const dataViewCopy = dataView.slice();
            worker.postMessage({ id: "decodeMesh", dataView: dataViewCopy, attributes }, [dataViewCopy.buffer]);
          });
        });
      });
    }
    if (this._modulePromise) {
      return this._modulePromise.then((decoder) => {
        let resultIndices = null;
        const resultAttributes = [];
        const numPoints = DecodeMesh(decoder.module, dataView, attributes, (indices) => {
          resultIndices = indices;
        }, (kind, data2, size, byteOffset, byteStride, normalized) => {
          resultAttributes.push({
            kind,
            data: data2,
            size,
            byteOffset,
            byteStride,
            normalized
          });
        });
        return { indices: resultIndices, attributes: resultAttributes, totalVertices: numPoints };
      });
    }
    throw new Error("Draco decoder module is not available");
  }
  /**
   * Decode Draco compressed mesh data to Babylon geometry.
   * @param name The name to use when creating the geometry
   * @param scene The scene to use when creating the geometry
   * @param data The ArrayBuffer or ArrayBufferView of the Draco compressed data
   * @param attributes A map of attributes from vertex buffer kinds to Draco unique ids
   * @returns A promise that resolves with the decoded geometry
   */
  async decodeMeshToGeometryAsync(name, scene, data, attributes) {
    const meshData = await this.decodeMeshToMeshDataAsync(data, attributes);
    const geometry = new Geometry(name, scene);
    if (meshData.indices) {
      geometry.setIndices(meshData.indices);
    }
    for (const attribute of meshData.attributes) {
      geometry.setVerticesBuffer(new VertexBuffer(scene.getEngine(), attribute.data, attribute.kind, false, void 0, attribute.byteStride, void 0, attribute.byteOffset, attribute.size, void 0, attribute.normalized, true), meshData.totalVertices);
    }
    return geometry;
  }
  /** @internal */
  async _decodeMeshToGeometryForGltfAsync(name, scene, data, attributes, gltfNormalizedOverride, boundingInfo) {
    const meshData = await this.decodeMeshToMeshDataAsync(data, attributes, gltfNormalizedOverride);
    const geometry = new Geometry(name, scene);
    if (boundingInfo) {
      geometry._boundingInfo = boundingInfo;
      geometry.useBoundingInfoFromGeometry = true;
    }
    if (meshData.indices) {
      geometry.setIndices(meshData.indices);
    }
    for (const attribute of meshData.attributes) {
      geometry.setVerticesBuffer(new VertexBuffer(scene.getEngine(), attribute.data, attribute.kind, false, void 0, attribute.byteStride, void 0, attribute.byteOffset, attribute.size, void 0, attribute.normalized, true), meshData.totalVertices);
    }
    return geometry;
  }
};
DracoDecoder.DefaultConfiguration = {
  wasmUrl: `${Tools._DefaultCdnUrl}/draco_wasm_wrapper_gltf.js`,
  wasmBinaryUrl: `${Tools._DefaultCdnUrl}/draco_decoder_gltf.wasm`,
  fallbackUrl: `${Tools._DefaultCdnUrl}/draco_decoder_gltf.js`
};
DracoDecoder._Default = null;

// node_modules/@babylonjs/core/Meshes/Compression/meshoptCompression.js
var NumberOfWorkers = 0;
var WorkerTimeout = null;
var MeshoptCompression = class _MeshoptCompression {
  /**
   * Default instance for the meshoptimizer object.
   */
  static get Default() {
    if (!_MeshoptCompression._Default) {
      _MeshoptCompression._Default = new _MeshoptCompression();
    }
    return _MeshoptCompression._Default;
  }
  /**
   * Constructor
   */
  constructor() {
    const decoder = _MeshoptCompression.Configuration.decoder;
    this._decoderModulePromise = Tools.LoadBabylonScriptAsync(decoder.url).then(() => {
      return MeshoptDecoder.ready;
    });
  }
  /**
   * Stop all async operations and release resources.
   */
  dispose() {
    delete this._decoderModulePromise;
  }
  /**
   * Decode meshopt data.
   * @see https://github.com/zeux/meshoptimizer/tree/master/js#decoder
   * @param source The input data.
   * @param count The number of elements.
   * @param stride The stride in bytes.
   * @param mode The compression mode.
   * @param filter The compression filter.
   * @returns a Promise<Uint8Array> that resolves to the decoded data
   */
  async decodeGltfBufferAsync(source, count, stride, mode, filter) {
    await this._decoderModulePromise;
    if (NumberOfWorkers === 0) {
      MeshoptDecoder.useWorkers(1);
      NumberOfWorkers = 1;
    }
    const result = await MeshoptDecoder.decodeGltfBufferAsync(count, stride, source, mode, filter);
    if (WorkerTimeout !== null) {
      clearTimeout(WorkerTimeout);
    }
    WorkerTimeout = setTimeout(() => {
      MeshoptDecoder.useWorkers(0);
      NumberOfWorkers = 0;
      WorkerTimeout = null;
    }, 1e3);
    return result;
  }
};
MeshoptCompression.Configuration = {
  decoder: {
    url: `${Tools._DefaultCdnUrl}/meshopt_decoder.js`
  }
};
MeshoptCompression._Default = null;

// node_modules/@babylonjs/core/Meshes/GaussianSplatting/gaussianSplattingMesh.js
var UnpackUnorm = (value, bits) => {
  const t = (1 << bits) - 1;
  return (value & t) / t;
};
var Unpack111011 = (value, result) => {
  result.x = UnpackUnorm(value >>> 21, 11);
  result.y = UnpackUnorm(value >>> 11, 10);
  result.z = UnpackUnorm(value, 11);
};
var Unpack8888 = (value, result) => {
  result[0] = UnpackUnorm(value >>> 24, 8) * 255;
  result[1] = UnpackUnorm(value >>> 16, 8) * 255;
  result[2] = UnpackUnorm(value >>> 8, 8) * 255;
  result[3] = UnpackUnorm(value, 8) * 255;
};
var UnpackRot = (value, result) => {
  const norm = 1 / (Math.sqrt(2) * 0.5);
  const a = (UnpackUnorm(value >>> 20, 10) - 0.5) * norm;
  const b = (UnpackUnorm(value >>> 10, 10) - 0.5) * norm;
  const c = (UnpackUnorm(value, 10) - 0.5) * norm;
  const m = Math.sqrt(1 - (a * a + b * b + c * c));
  switch (value >>> 30) {
    case 0:
      result.set(m, a, b, c);
      break;
    case 1:
      result.set(a, m, b, c);
      break;
    case 2:
      result.set(a, b, m, c);
      break;
    case 3:
      result.set(a, b, c, m);
      break;
  }
};
var PLYType;
(function(PLYType2) {
  PLYType2[PLYType2["FLOAT"] = 0] = "FLOAT";
  PLYType2[PLYType2["INT"] = 1] = "INT";
  PLYType2[PLYType2["UINT"] = 2] = "UINT";
  PLYType2[PLYType2["DOUBLE"] = 3] = "DOUBLE";
  PLYType2[PLYType2["UCHAR"] = 4] = "UCHAR";
  PLYType2[PLYType2["UNDEFINED"] = 5] = "UNDEFINED";
})(PLYType || (PLYType = {}));
var PLYValue;
(function(PLYValue2) {
  PLYValue2[PLYValue2["MIN_X"] = 0] = "MIN_X";
  PLYValue2[PLYValue2["MIN_Y"] = 1] = "MIN_Y";
  PLYValue2[PLYValue2["MIN_Z"] = 2] = "MIN_Z";
  PLYValue2[PLYValue2["MAX_X"] = 3] = "MAX_X";
  PLYValue2[PLYValue2["MAX_Y"] = 4] = "MAX_Y";
  PLYValue2[PLYValue2["MAX_Z"] = 5] = "MAX_Z";
  PLYValue2[PLYValue2["MIN_SCALE_X"] = 6] = "MIN_SCALE_X";
  PLYValue2[PLYValue2["MIN_SCALE_Y"] = 7] = "MIN_SCALE_Y";
  PLYValue2[PLYValue2["MIN_SCALE_Z"] = 8] = "MIN_SCALE_Z";
  PLYValue2[PLYValue2["MAX_SCALE_X"] = 9] = "MAX_SCALE_X";
  PLYValue2[PLYValue2["MAX_SCALE_Y"] = 10] = "MAX_SCALE_Y";
  PLYValue2[PLYValue2["MAX_SCALE_Z"] = 11] = "MAX_SCALE_Z";
  PLYValue2[PLYValue2["PACKED_POSITION"] = 12] = "PACKED_POSITION";
  PLYValue2[PLYValue2["PACKED_ROTATION"] = 13] = "PACKED_ROTATION";
  PLYValue2[PLYValue2["PACKED_SCALE"] = 14] = "PACKED_SCALE";
  PLYValue2[PLYValue2["PACKED_COLOR"] = 15] = "PACKED_COLOR";
  PLYValue2[PLYValue2["X"] = 16] = "X";
  PLYValue2[PLYValue2["Y"] = 17] = "Y";
  PLYValue2[PLYValue2["Z"] = 18] = "Z";
  PLYValue2[PLYValue2["SCALE_0"] = 19] = "SCALE_0";
  PLYValue2[PLYValue2["SCALE_1"] = 20] = "SCALE_1";
  PLYValue2[PLYValue2["SCALE_2"] = 21] = "SCALE_2";
  PLYValue2[PLYValue2["DIFFUSE_RED"] = 22] = "DIFFUSE_RED";
  PLYValue2[PLYValue2["DIFFUSE_GREEN"] = 23] = "DIFFUSE_GREEN";
  PLYValue2[PLYValue2["DIFFUSE_BLUE"] = 24] = "DIFFUSE_BLUE";
  PLYValue2[PLYValue2["OPACITY"] = 25] = "OPACITY";
  PLYValue2[PLYValue2["F_DC_0"] = 26] = "F_DC_0";
  PLYValue2[PLYValue2["F_DC_1"] = 27] = "F_DC_1";
  PLYValue2[PLYValue2["F_DC_2"] = 28] = "F_DC_2";
  PLYValue2[PLYValue2["F_DC_3"] = 29] = "F_DC_3";
  PLYValue2[PLYValue2["ROT_0"] = 30] = "ROT_0";
  PLYValue2[PLYValue2["ROT_1"] = 31] = "ROT_1";
  PLYValue2[PLYValue2["ROT_2"] = 32] = "ROT_2";
  PLYValue2[PLYValue2["ROT_3"] = 33] = "ROT_3";
  PLYValue2[PLYValue2["MIN_COLOR_R"] = 34] = "MIN_COLOR_R";
  PLYValue2[PLYValue2["MIN_COLOR_G"] = 35] = "MIN_COLOR_G";
  PLYValue2[PLYValue2["MIN_COLOR_B"] = 36] = "MIN_COLOR_B";
  PLYValue2[PLYValue2["MAX_COLOR_R"] = 37] = "MAX_COLOR_R";
  PLYValue2[PLYValue2["MAX_COLOR_G"] = 38] = "MAX_COLOR_G";
  PLYValue2[PLYValue2["MAX_COLOR_B"] = 39] = "MAX_COLOR_B";
  PLYValue2[PLYValue2["SH_0"] = 40] = "SH_0";
  PLYValue2[PLYValue2["SH_1"] = 41] = "SH_1";
  PLYValue2[PLYValue2["SH_2"] = 42] = "SH_2";
  PLYValue2[PLYValue2["SH_3"] = 43] = "SH_3";
  PLYValue2[PLYValue2["SH_4"] = 44] = "SH_4";
  PLYValue2[PLYValue2["SH_5"] = 45] = "SH_5";
  PLYValue2[PLYValue2["SH_6"] = 46] = "SH_6";
  PLYValue2[PLYValue2["SH_7"] = 47] = "SH_7";
  PLYValue2[PLYValue2["SH_8"] = 48] = "SH_8";
  PLYValue2[PLYValue2["SH_9"] = 49] = "SH_9";
  PLYValue2[PLYValue2["SH_10"] = 50] = "SH_10";
  PLYValue2[PLYValue2["SH_11"] = 51] = "SH_11";
  PLYValue2[PLYValue2["SH_12"] = 52] = "SH_12";
  PLYValue2[PLYValue2["SH_13"] = 53] = "SH_13";
  PLYValue2[PLYValue2["SH_14"] = 54] = "SH_14";
  PLYValue2[PLYValue2["SH_15"] = 55] = "SH_15";
  PLYValue2[PLYValue2["SH_16"] = 56] = "SH_16";
  PLYValue2[PLYValue2["SH_17"] = 57] = "SH_17";
  PLYValue2[PLYValue2["SH_18"] = 58] = "SH_18";
  PLYValue2[PLYValue2["SH_19"] = 59] = "SH_19";
  PLYValue2[PLYValue2["SH_20"] = 60] = "SH_20";
  PLYValue2[PLYValue2["SH_21"] = 61] = "SH_21";
  PLYValue2[PLYValue2["SH_22"] = 62] = "SH_22";
  PLYValue2[PLYValue2["SH_23"] = 63] = "SH_23";
  PLYValue2[PLYValue2["SH_24"] = 64] = "SH_24";
  PLYValue2[PLYValue2["SH_25"] = 65] = "SH_25";
  PLYValue2[PLYValue2["SH_26"] = 66] = "SH_26";
  PLYValue2[PLYValue2["SH_27"] = 67] = "SH_27";
  PLYValue2[PLYValue2["SH_28"] = 68] = "SH_28";
  PLYValue2[PLYValue2["SH_29"] = 69] = "SH_29";
  PLYValue2[PLYValue2["SH_30"] = 70] = "SH_30";
  PLYValue2[PLYValue2["SH_31"] = 71] = "SH_31";
  PLYValue2[PLYValue2["SH_32"] = 72] = "SH_32";
  PLYValue2[PLYValue2["SH_33"] = 73] = "SH_33";
  PLYValue2[PLYValue2["SH_34"] = 74] = "SH_34";
  PLYValue2[PLYValue2["SH_35"] = 75] = "SH_35";
  PLYValue2[PLYValue2["SH_36"] = 76] = "SH_36";
  PLYValue2[PLYValue2["SH_37"] = 77] = "SH_37";
  PLYValue2[PLYValue2["SH_38"] = 78] = "SH_38";
  PLYValue2[PLYValue2["SH_39"] = 79] = "SH_39";
  PLYValue2[PLYValue2["SH_40"] = 80] = "SH_40";
  PLYValue2[PLYValue2["SH_41"] = 81] = "SH_41";
  PLYValue2[PLYValue2["SH_42"] = 82] = "SH_42";
  PLYValue2[PLYValue2["SH_43"] = 83] = "SH_43";
  PLYValue2[PLYValue2["SH_44"] = 84] = "SH_44";
  PLYValue2[PLYValue2["UNDEFINED"] = 85] = "UNDEFINED";
})(PLYValue || (PLYValue = {}));
var GaussianSplattingMesh = class _GaussianSplattingMesh extends Mesh {
  /**
   * View direction factor used to compute the SH view direction in the shader.
   */
  get viewDirectionFactor() {
    return this._viewDirectionFactor;
  }
  /**
   * SH degree. 0 = no sh (default). 1 = 3 parameters. 2 = 8 parameters. 3 = 15 parameters.
   */
  get shDegree() {
    return this._shDegree;
  }
  /**
   * Number of splats in the mesh
   */
  get splatCount() {
    return this._splatIndex?.length;
  }
  /**
   * returns the splats data array buffer that contains in order : postions (3 floats), size (3 floats), color (4 bytes), orientation quaternion (4 bytes)
   */
  get splatsData() {
    return this._splatsData;
  }
  /**
   * Gets the covariancesA texture
   */
  get covariancesATexture() {
    return this._covariancesATexture;
  }
  /**
   * Gets the covariancesB texture
   */
  get covariancesBTexture() {
    return this._covariancesBTexture;
  }
  /**
   * Gets the centers texture
   */
  get centersTexture() {
    return this._centersTexture;
  }
  /**
   * Gets the colors texture
   */
  get colorsTexture() {
    return this._colorsTexture;
  }
  /**
   * Gets the SH textures
   */
  get shTextures() {
    return this._shTextures;
  }
  /**
   * Gets the kernel size
   * Documentation and mathematical explanations here:
   * https://github.com/graphdeco-inria/gaussian-splatting/issues/294#issuecomment-1772688093
   * https://github.com/autonomousvision/mip-splatting/issues/18#issuecomment-1929388931
   */
  get kernelSize() {
    return this._material instanceof GaussianSplattingMaterial ? this._material.kernelSize : 0;
  }
  /**
   * Get the compensation state
   */
  get compensation() {
    return this._material instanceof GaussianSplattingMaterial ? this._material.compensation : false;
  }
  /**
   * set rendering material
   */
  set material(value) {
    this._material = value;
    this._material.backFaceCulling = true;
    this._material.cullBackFaces = false;
    value.resetDrawCache();
  }
  /**
   * get rendering material
   */
  get material() {
    return this._material;
  }
  /**
   * Creates a new gaussian splatting mesh
   * @param name defines the name of the mesh
   * @param url defines the url to load from (optional)
   * @param scene defines the hosting scene (optional)
   * @param keepInRam keep datas in ram for editing purpose
   */
  constructor(name, url = null, scene = null, keepInRam = false) {
    super(name, scene);
    this._vertexCount = 0;
    this._worker = null;
    this._frameIdLastUpdate = -1;
    this._modelViewMatrix = Matrix.Identity();
    this._canPostToWorker = true;
    this._readyToDisplay = false;
    this._covariancesATexture = null;
    this._covariancesBTexture = null;
    this._centersTexture = null;
    this._colorsTexture = null;
    this._splatPositions = null;
    this._splatIndex = null;
    this._shTextures = null;
    this._splatsData = null;
    this._sh = null;
    this._keepInRam = false;
    this._delayedTextureUpdate = null;
    this._oldDirection = new Vector3();
    this._useRGBACovariants = false;
    this._material = null;
    this._tmpCovariances = [0, 0, 0, 0, 0, 0];
    this._sortIsDirty = false;
    this._shDegree = 0;
    this._viewDirectionFactor = new Vector3(1, 1, -1);
    const vertexData = new VertexData();
    vertexData.positions = [-2, -2, 0, 2, -2, 0, 2, 2, 0, -2, 2, 0];
    vertexData.indices = [0, 1, 2, 0, 2, 3];
    vertexData.applyToMesh(this);
    this.subMeshes = [];
    new SubMesh(0, 0, 4, 0, 6, this);
    this.setEnabled(false);
    this._useRGBACovariants = !this.getEngine().isWebGPU && this.getEngine().version === 1;
    this._keepInRam = keepInRam;
    if (url) {
      this.loadFileAsync(url);
    }
    this._material = new GaussianSplattingMaterial(this.name + "_material", this._scene);
  }
  /**
   * Returns the class name
   * @returns "GaussianSplattingMesh"
   */
  getClassName() {
    return "GaussianSplattingMesh";
  }
  /**
   * Returns the total number of vertices (splats) within the mesh
   * @returns the total number of vertices
   */
  getTotalVertices() {
    return this._vertexCount;
  }
  /**
   * Is this node ready to be used/rendered
   * @param completeCheck defines if a complete check (including materials and lights) has to be done (false by default)
   * @returns true when ready
   */
  isReady(completeCheck = false) {
    if (!super.isReady(completeCheck, true)) {
      return false;
    }
    if (!this._readyToDisplay) {
      this._postToWorker(true);
      return false;
    }
    return true;
  }
  /** @internal */
  _postToWorker(forced = false) {
    const frameId = this.getScene().getFrameId();
    if ((forced || frameId !== this._frameIdLastUpdate) && this._worker && this._scene.activeCamera && this._canPostToWorker) {
      const cameraMatrix = this._scene.activeCamera.getViewMatrix();
      this.getWorldMatrix().multiplyToRef(cameraMatrix, this._modelViewMatrix);
      cameraMatrix.invertToRef(TmpVectors.Matrix[0]);
      this.getWorldMatrix().multiplyToRef(TmpVectors.Matrix[0], TmpVectors.Matrix[1]);
      Vector3.TransformNormalToRef(Vector3.Forward(this._scene.useRightHandedSystem), TmpVectors.Matrix[1], TmpVectors.Vector3[2]);
      TmpVectors.Vector3[2].normalize();
      const dot = Vector3.Dot(TmpVectors.Vector3[2], this._oldDirection);
      if (forced || Math.abs(dot - 1) >= 0.01) {
        this._oldDirection.copyFrom(TmpVectors.Vector3[2]);
        this._frameIdLastUpdate = frameId;
        this._canPostToWorker = false;
        this._worker.postMessage({ view: this._modelViewMatrix.m, depthMix: this._depthMix, useRightHandedSystem: this._scene.useRightHandedSystem }, [
          this._depthMix.buffer
        ]);
      }
    }
  }
  /**
   * Triggers the draw call for the mesh. Usually, you don't need to call this method by your own because the mesh rendering is handled by the scene rendering manager
   * @param subMesh defines the subMesh to render
   * @param enableAlphaMode defines if alpha mode can be changed
   * @param effectiveMeshReplacement defines an optional mesh used to provide info for the rendering
   * @returns the current mesh
   */
  render(subMesh, enableAlphaMode, effectiveMeshReplacement) {
    this._postToWorker();
    return super.render(subMesh, enableAlphaMode, effectiveMeshReplacement);
  }
  static _TypeNameToEnum(name) {
    switch (name) {
      case "float":
        return 0;
      case "int":
        return 1;
        break;
      case "uint":
        return 2;
      case "double":
        return 3;
      case "uchar":
        return 4;
    }
    return 5;
  }
  static _ValueNameToEnum(name) {
    switch (name) {
      case "min_x":
        return 0;
      case "min_y":
        return 1;
      case "min_z":
        return 2;
      case "max_x":
        return 3;
      case "max_y":
        return 4;
      case "max_z":
        return 5;
      case "min_scale_x":
        return 6;
      case "min_scale_y":
        return 7;
      case "min_scale_z":
        return 8;
      case "max_scale_x":
        return 9;
      case "max_scale_y":
        return 10;
      case "max_scale_z":
        return 11;
      case "packed_position":
        return 12;
      case "packed_rotation":
        return 13;
      case "packed_scale":
        return 14;
      case "packed_color":
        return 15;
      case "x":
        return 16;
      case "y":
        return 17;
      case "z":
        return 18;
      case "scale_0":
        return 19;
      case "scale_1":
        return 20;
      case "scale_2":
        return 21;
      case "diffuse_red":
      case "red":
        return 22;
      case "diffuse_green":
      case "green":
        return 23;
      case "diffuse_blue":
      case "blue":
        return 24;
      case "f_dc_0":
        return 26;
      case "f_dc_1":
        return 27;
      case "f_dc_2":
        return 28;
      case "f_dc_3":
        return 29;
      case "opacity":
        return 25;
      case "rot_0":
        return 30;
      case "rot_1":
        return 31;
      case "rot_2":
        return 32;
      case "rot_3":
        return 33;
      case "min_r":
        return 34;
      case "min_g":
        return 35;
      case "min_b":
        return 36;
      case "max_r":
        return 37;
      case "max_g":
        return 38;
      case "max_b":
        return 39;
      case "f_rest_0":
        return 40;
      case "f_rest_1":
        return 41;
      case "f_rest_2":
        return 42;
      case "f_rest_3":
        return 43;
      case "f_rest_4":
        return 44;
      case "f_rest_5":
        return 45;
      case "f_rest_6":
        return 46;
      case "f_rest_7":
        return 47;
      case "f_rest_8":
        return 48;
      case "f_rest_9":
        return 49;
      case "f_rest_10":
        return 50;
      case "f_rest_11":
        return 51;
      case "f_rest_12":
        return 52;
      case "f_rest_13":
        return 53;
      case "f_rest_14":
        return 54;
      case "f_rest_15":
        return 55;
      case "f_rest_16":
        return 56;
      case "f_rest_17":
        return 57;
      case "f_rest_18":
        return 58;
      case "f_rest_19":
        return 59;
      case "f_rest_20":
        return 60;
      case "f_rest_21":
        return 61;
      case "f_rest_22":
        return 62;
      case "f_rest_23":
        return 63;
      case "f_rest_24":
        return 64;
      case "f_rest_25":
        return 65;
      case "f_rest_26":
        return 66;
      case "f_rest_27":
        return 67;
      case "f_rest_28":
        return 68;
      case "f_rest_29":
        return 69;
      case "f_rest_30":
        return 70;
      case "f_rest_31":
        return 71;
      case "f_rest_32":
        return 72;
      case "f_rest_33":
        return 73;
      case "f_rest_34":
        return 74;
      case "f_rest_35":
        return 75;
      case "f_rest_36":
        return 76;
      case "f_rest_37":
        return 77;
      case "f_rest_38":
        return 78;
      case "f_rest_39":
        return 79;
      case "f_rest_40":
        return 80;
      case "f_rest_41":
        return 81;
      case "f_rest_42":
        return 82;
      case "f_rest_43":
        return 83;
      case "f_rest_44":
        return 84;
    }
    return 85;
  }
  /**
   * Parse a PLY file header and returns metas infos on splats and chunks
   * @param data the loaded buffer
   * @returns a PLYHeader
   */
  static ParseHeader(data) {
    const ubuf = new Uint8Array(data);
    const header = new TextDecoder().decode(ubuf.slice(0, 1024 * 10));
    const headerEnd = "end_header\n";
    const headerEndIndex = header.indexOf(headerEnd);
    if (headerEndIndex < 0 || !header) {
      return null;
    }
    const vertexCount = parseInt(/element vertex (\d+)\n/.exec(header)[1]);
    const chunkElement = /element chunk (\d+)\n/.exec(header);
    let chunkCount = 0;
    if (chunkElement) {
      chunkCount = parseInt(chunkElement[1]);
    }
    let rowVertexOffset = 0;
    let rowChunkOffset = 0;
    const offsets = {
      double: 8,
      int: 4,
      uint: 4,
      float: 4,
      short: 2,
      ushort: 2,
      uchar: 1,
      list: 0
    };
    let ElementMode;
    (function(ElementMode2) {
      ElementMode2[ElementMode2["Vertex"] = 0] = "Vertex";
      ElementMode2[ElementMode2["Chunk"] = 1] = "Chunk";
      ElementMode2[ElementMode2["SH"] = 2] = "SH";
    })(ElementMode || (ElementMode = {}));
    let chunkMode = 1;
    const vertexProperties = [];
    const chunkProperties = [];
    const filtered = header.slice(0, headerEndIndex).split("\n");
    let shDegree = 0;
    for (const prop of filtered) {
      if (prop.startsWith("property ")) {
        const [, typeName, name] = prop.split(" ");
        const value = _GaussianSplattingMesh._ValueNameToEnum(name);
        if (value != 85) {
          if (value >= 84) {
            shDegree = 3;
          } else if (value >= 64) {
            shDegree = 2;
          } else if (value >= 48) {
            shDegree = 1;
          }
        }
        const type = _GaussianSplattingMesh._TypeNameToEnum(typeName);
        if (chunkMode == 1) {
          chunkProperties.push({ value, type, offset: rowChunkOffset });
          rowChunkOffset += offsets[typeName];
        } else if (chunkMode == 0) {
          vertexProperties.push({ value, type, offset: rowVertexOffset });
          rowVertexOffset += offsets[typeName];
        } else if (chunkMode == 2) {
          vertexProperties.push({ value, type, offset: rowVertexOffset });
        }
        if (!offsets[typeName]) {
          Logger.Warn(`Unsupported property type: ${typeName}.`);
        }
      } else if (prop.startsWith("element ")) {
        const [, type] = prop.split(" ");
        if (type == "chunk") {
          chunkMode = 1;
        } else if (type == "vertex") {
          chunkMode = 0;
        } else if (type == "sh") {
          chunkMode = 2;
        }
      }
    }
    const dataView = new DataView(data, headerEndIndex + headerEnd.length);
    const buffer = new ArrayBuffer(_GaussianSplattingMesh._RowOutputLength * vertexCount);
    let shBuffer = null;
    let shCoefficientCount = 0;
    if (shDegree) {
      const shVectorCount = (shDegree + 1) * (shDegree + 1) - 1;
      shCoefficientCount = shVectorCount * 3;
      shBuffer = new ArrayBuffer(shCoefficientCount * vertexCount);
    }
    return {
      vertexCount,
      chunkCount,
      rowVertexLength: rowVertexOffset,
      rowChunkLength: rowChunkOffset,
      vertexProperties,
      chunkProperties,
      dataView,
      buffer,
      shDegree,
      shCoefficientCount,
      shBuffer
    };
  }
  static _GetCompressedChunks(header, offset) {
    if (!header.chunkCount) {
      return null;
    }
    const dataView = header.dataView;
    const compressedChunks = new Array(header.chunkCount);
    for (let i = 0; i < header.chunkCount; i++) {
      const currentChunk = {
        min: new Vector3(),
        max: new Vector3(),
        minScale: new Vector3(),
        maxScale: new Vector3(),
        minColor: new Vector3(0, 0, 0),
        maxColor: new Vector3(1, 1, 1)
      };
      compressedChunks[i] = currentChunk;
      for (let propertyIndex = 0; propertyIndex < header.chunkProperties.length; propertyIndex++) {
        const property = header.chunkProperties[propertyIndex];
        let value;
        switch (property.type) {
          case 0:
            value = dataView.getFloat32(property.offset + offset.value, true);
            break;
          default:
            continue;
        }
        switch (property.value) {
          case 0:
            currentChunk.min.x = value;
            break;
          case 1:
            currentChunk.min.y = value;
            break;
          case 2:
            currentChunk.min.z = value;
            break;
          case 3:
            currentChunk.max.x = value;
            break;
          case 4:
            currentChunk.max.y = value;
            break;
          case 5:
            currentChunk.max.z = value;
            break;
          case 6:
            currentChunk.minScale.x = value;
            break;
          case 7:
            currentChunk.minScale.y = value;
            break;
          case 8:
            currentChunk.minScale.z = value;
            break;
          case 9:
            currentChunk.maxScale.x = value;
            break;
          case 10:
            currentChunk.maxScale.y = value;
            break;
          case 11:
            currentChunk.maxScale.z = value;
            break;
          case 34:
            currentChunk.minColor.x = value;
            break;
          case 35:
            currentChunk.minColor.y = value;
            break;
          case 36:
            currentChunk.minColor.z = value;
            break;
          case 37:
            currentChunk.maxColor.x = value;
            break;
          case 38:
            currentChunk.maxColor.y = value;
            break;
          case 39:
            currentChunk.maxColor.z = value;
            break;
        }
      }
      offset.value += header.rowChunkLength;
    }
    return compressedChunks;
  }
  static _GetSplat(header, index, compressedChunks, offset) {
    const q = TmpVectors.Quaternion[0];
    const temp3 = TmpVectors.Vector3[0];
    const rowOutputLength = _GaussianSplattingMesh._RowOutputLength;
    const buffer = header.buffer;
    const dataView = header.dataView;
    const position = new Float32Array(buffer, index * rowOutputLength, 3);
    const scale = new Float32Array(buffer, index * rowOutputLength + 12, 3);
    const rgba = new Uint8ClampedArray(buffer, index * rowOutputLength + 24, 4);
    const rot = new Uint8ClampedArray(buffer, index * rowOutputLength + 28, 4);
    let sh = null;
    if (header.shBuffer) {
      sh = new Uint8ClampedArray(header.shBuffer, index * header.shCoefficientCount, header.shCoefficientCount);
    }
    const chunkIndex = index >> 8;
    let r0 = 255;
    let r1 = 0;
    let r2 = 0;
    let r3 = 0;
    const plySH = [];
    for (let propertyIndex = 0; propertyIndex < header.vertexProperties.length; propertyIndex++) {
      const property = header.vertexProperties[propertyIndex];
      let value;
      switch (property.type) {
        case 0:
          value = dataView.getFloat32(offset.value + property.offset, true);
          break;
        case 1:
          value = dataView.getInt32(offset.value + property.offset, true);
          break;
        case 2:
          value = dataView.getUint32(offset.value + property.offset, true);
          break;
        case 3:
          value = dataView.getFloat64(offset.value + property.offset, true);
          break;
        case 4:
          value = dataView.getUint8(offset.value + property.offset);
          break;
        default:
          continue;
      }
      switch (property.value) {
        case 12:
          {
            const compressedChunk = compressedChunks[chunkIndex];
            Unpack111011(value, temp3);
            position[0] = Scalar.Lerp(compressedChunk.min.x, compressedChunk.max.x, temp3.x);
            position[1] = Scalar.Lerp(compressedChunk.min.y, compressedChunk.max.y, temp3.y);
            position[2] = Scalar.Lerp(compressedChunk.min.z, compressedChunk.max.z, temp3.z);
          }
          break;
        case 13:
          {
            UnpackRot(value, q);
            r0 = q.x;
            r1 = q.y;
            r2 = q.z;
            r3 = q.w;
          }
          break;
        case 14:
          {
            const compressedChunk = compressedChunks[chunkIndex];
            Unpack111011(value, temp3);
            scale[0] = Math.exp(Scalar.Lerp(compressedChunk.minScale.x, compressedChunk.maxScale.x, temp3.x));
            scale[1] = Math.exp(Scalar.Lerp(compressedChunk.minScale.y, compressedChunk.maxScale.y, temp3.y));
            scale[2] = Math.exp(Scalar.Lerp(compressedChunk.minScale.z, compressedChunk.maxScale.z, temp3.z));
          }
          break;
        case 15:
          {
            const compressedChunk = compressedChunks[chunkIndex];
            Unpack8888(value, rgba);
            rgba[0] = Scalar.Lerp(compressedChunk.minColor.x, compressedChunk.maxColor.x, rgba[0] / 255) * 255;
            rgba[1] = Scalar.Lerp(compressedChunk.minColor.y, compressedChunk.maxColor.y, rgba[1] / 255) * 255;
            rgba[2] = Scalar.Lerp(compressedChunk.minColor.z, compressedChunk.maxColor.z, rgba[2] / 255) * 255;
          }
          break;
        case 16:
          position[0] = value;
          break;
        case 17:
          position[1] = value;
          break;
        case 18:
          position[2] = value;
          break;
        case 19:
          scale[0] = Math.exp(value);
          break;
        case 20:
          scale[1] = Math.exp(value);
          break;
        case 21:
          scale[2] = Math.exp(value);
          break;
        case 22:
          rgba[0] = value;
          break;
        case 23:
          rgba[1] = value;
          break;
        case 24:
          rgba[2] = value;
          break;
        case 26:
          rgba[0] = (0.5 + _GaussianSplattingMesh._SH_C0 * value) * 255;
          break;
        case 27:
          rgba[1] = (0.5 + _GaussianSplattingMesh._SH_C0 * value) * 255;
          break;
        case 28:
          rgba[2] = (0.5 + _GaussianSplattingMesh._SH_C0 * value) * 255;
          break;
        case 29:
          rgba[3] = (0.5 + _GaussianSplattingMesh._SH_C0 * value) * 255;
          break;
        case 25:
          rgba[3] = 1 / (1 + Math.exp(-value)) * 255;
          break;
        case 30:
          r0 = value;
          break;
        case 31:
          r1 = value;
          break;
        case 32:
          r2 = value;
          break;
        case 33:
          r3 = value;
          break;
      }
      if (sh && property.value >= 40 && property.value <= 84) {
        const shIndex = property.value - 40;
        if (property.type == 4 && header.chunkCount) {
          const compressedValue = dataView.getUint8(header.rowChunkLength * header.chunkCount + header.vertexCount * header.rowVertexLength + index * header.shCoefficientCount + shIndex);
          plySH[shIndex] = (compressedValue * (8 / 255) - 4) * 127.5 + 127.5;
        } else {
          const clampedValue = Scalar.Clamp(value * 127.5 + 127.5, 0, 255);
          plySH[shIndex] = clampedValue;
        }
      }
    }
    if (sh) {
      const shDim = header.shDegree == 1 ? 3 : header.shDegree == 2 ? 8 : 15;
      for (let j = 0; j < shDim; j++) {
        sh[j * 3 + 0] = plySH[j];
        sh[j * 3 + 1] = plySH[j + shDim];
        sh[j * 3 + 2] = plySH[j + shDim * 2];
      }
    }
    q.set(r1, r2, r3, r0);
    q.normalize();
    rot[0] = q.w * 127.5 + 127.5;
    rot[1] = q.x * 127.5 + 127.5;
    rot[2] = q.y * 127.5 + 127.5;
    rot[3] = q.z * 127.5 + 127.5;
    offset.value += header.rowVertexLength;
  }
  /**
   * Converts a .ply data with SH coefficients splat
   * if data array buffer is not ply, returns the original buffer
   * @param data the .ply data to load
   * @param useCoroutine use coroutine and yield
   * @returns the loaded splat buffer and optional array of sh coefficients
   */
  static *ConvertPLYWithSHToSplat(data, useCoroutine = false) {
    const header = _GaussianSplattingMesh.ParseHeader(data);
    if (!header) {
      return { buffer: data };
    }
    const offset = { value: 0 };
    const compressedChunks = _GaussianSplattingMesh._GetCompressedChunks(header, offset);
    for (let i = 0; i < header.vertexCount; i++) {
      _GaussianSplattingMesh._GetSplat(header, i, compressedChunks, offset);
      if (i % _GaussianSplattingMesh._PlyConversionBatchSize === 0 && useCoroutine) {
        yield;
      }
    }
    let sh = null;
    if (header.shDegree && header.shBuffer) {
      const textureCount = Math.ceil(header.shCoefficientCount / 16);
      let shIndexRead = 0;
      const ubuf = new Uint8Array(header.shBuffer);
      sh = [];
      const splatCount = header.vertexCount;
      const engine = EngineStore.LastCreatedEngine;
      if (engine) {
        const width = engine.getCaps().maxTextureSize;
        const height = Math.ceil(splatCount / width);
        for (let textureIndex = 0; textureIndex < textureCount; textureIndex++) {
          const texture = new Uint8Array(height * width * 4 * 4);
          sh.push(texture);
        }
        for (let i = 0; i < splatCount; i++) {
          for (let shIndexWrite = 0; shIndexWrite < header.shCoefficientCount; shIndexWrite++) {
            const shValue = ubuf[shIndexRead++];
            const textureIndex = Math.floor(shIndexWrite / 16);
            const shArray = sh[textureIndex];
            const byteIndexInTexture = shIndexWrite % 16;
            const offsetPerSplat = i * 16;
            shArray[byteIndexInTexture + offsetPerSplat] = shValue;
          }
        }
      }
    }
    return { buffer: header.buffer, sh };
  }
  /**
   * Converts a .ply data array buffer to splat
   * if data array buffer is not ply, returns the original buffer
   * @param data the .ply data to load
   * @param useCoroutine use coroutine and yield
   * @returns the loaded splat buffer without SH coefficient, whether ply contains or not SH.
   */
  static *ConvertPLYToSplat(data, useCoroutine = false) {
    const header = _GaussianSplattingMesh.ParseHeader(data);
    if (!header) {
      return data;
    }
    const offset = { value: 0 };
    const compressedChunks = _GaussianSplattingMesh._GetCompressedChunks(header, offset);
    for (let i = 0; i < header.vertexCount; i++) {
      _GaussianSplattingMesh._GetSplat(header, i, compressedChunks, offset);
      if (i % _GaussianSplattingMesh._PlyConversionBatchSize === 0 && useCoroutine) {
        yield;
      }
    }
    return header.buffer;
  }
  /**
   * Converts a .ply data array buffer to splat
   * if data array buffer is not ply, returns the original buffer
   * @param data the .ply data to load
   * @returns the loaded splat buffer
   */
  static async ConvertPLYToSplatAsync(data) {
    return await runCoroutineAsync(_GaussianSplattingMesh.ConvertPLYToSplat(data, true), createYieldingScheduler());
  }
  /**
   * Converts a .ply with SH data array buffer to splat
   * if data array buffer is not ply, returns the original buffer
   * @param data the .ply data to load
   * @returns the loaded splat buffer with SH
   */
  static async ConvertPLYWithSHToSplatAsync(data) {
    return await runCoroutineAsync(_GaussianSplattingMesh.ConvertPLYWithSHToSplat(data, true), createYieldingScheduler());
  }
  /**
   * Loads a .splat Gaussian Splatting array buffer asynchronously
   * @param data arraybuffer containing splat file
   * @returns a promise that resolves when the operation is complete
   */
  async loadDataAsync(data) {
    return await this.updateDataAsync(data);
  }
  /**
   * Loads a .splat Gaussian or .ply Splatting file asynchronously
   * @param url path to the splat file to load
   * @returns a promise that resolves when the operation is complete
   * @deprecated Please use SceneLoader.ImportMeshAsync instead
   */
  async loadFileAsync(url) {
    const plyBuffer = await Tools.LoadFileAsync(url, true);
    const splatsData = await _GaussianSplattingMesh.ConvertPLYWithSHToSplatAsync(plyBuffer);
    await this.updateDataAsync(splatsData.buffer, splatsData.sh);
  }
  /**
   * Releases resources associated with this mesh.
   * @param doNotRecurse Set to true to not recurse into each children (recurse into each children by default)
   */
  dispose(doNotRecurse) {
    this._covariancesATexture?.dispose();
    this._covariancesBTexture?.dispose();
    this._centersTexture?.dispose();
    this._colorsTexture?.dispose();
    if (this._shTextures) {
      for (const shTexture of this._shTextures) {
        shTexture.dispose();
      }
    }
    this._covariancesATexture = null;
    this._covariancesBTexture = null;
    this._centersTexture = null;
    this._colorsTexture = null;
    this._shTextures = null;
    this._worker?.terminate();
    this._worker = null;
    super.dispose(doNotRecurse, true);
  }
  _copyTextures(source) {
    this._covariancesATexture = source.covariancesATexture?.clone();
    this._covariancesBTexture = source.covariancesBTexture?.clone();
    this._centersTexture = source.centersTexture?.clone();
    this._colorsTexture = source.colorsTexture?.clone();
    if (source._shTextures) {
      this._shTextures = [];
      for (const shTexture of this._shTextures) {
        this._shTextures?.push(shTexture.clone());
      }
    }
  }
  /**
   * Returns a new Mesh object generated from the current mesh properties.
   * @param name is a string, the name given to the new mesh
   * @returns a new Gaussian Splatting Mesh
   */
  clone(name = "") {
    const newGS = new _GaussianSplattingMesh(name, void 0, this.getScene());
    newGS._copySource(this);
    newGS.makeGeometryUnique();
    newGS._vertexCount = this._vertexCount;
    newGS._copyTextures(this);
    newGS._modelViewMatrix = Matrix.Identity();
    newGS._splatPositions = this._splatPositions;
    newGS._readyToDisplay = false;
    newGS._instanciateWorker();
    const binfo = this.getBoundingInfo();
    newGS.getBoundingInfo().reConstruct(binfo.minimum, binfo.maximum, this.getWorldMatrix());
    newGS.forcedInstanceCount = newGS._vertexCount;
    newGS.setEnabled(true);
    return newGS;
  }
  _makeSplat(index, fBuffer, uBuffer, covA, covB, colorArray, minimum, maximum) {
    const matrixRotation = TmpVectors.Matrix[0];
    const matrixScale = TmpVectors.Matrix[1];
    const quaternion = TmpVectors.Quaternion[0];
    const covBSItemSize = this._useRGBACovariants ? 4 : 2;
    const x = fBuffer[8 * index + 0];
    const y = -fBuffer[8 * index + 1];
    const z = fBuffer[8 * index + 2];
    this._splatPositions[4 * index + 0] = x;
    this._splatPositions[4 * index + 1] = y;
    this._splatPositions[4 * index + 2] = z;
    minimum.minimizeInPlaceFromFloats(x, y, z);
    maximum.maximizeInPlaceFromFloats(x, y, z);
    quaternion.set((uBuffer[32 * index + 28 + 1] - 127.5) / 127.5, (uBuffer[32 * index + 28 + 2] - 127.5) / 127.5, (uBuffer[32 * index + 28 + 3] - 127.5) / 127.5, -(uBuffer[32 * index + 28 + 0] - 127.5) / 127.5);
    quaternion.normalize();
    quaternion.toRotationMatrix(matrixRotation);
    Matrix.ScalingToRef(fBuffer[8 * index + 3 + 0] * 2, fBuffer[8 * index + 3 + 1] * 2, fBuffer[8 * index + 3 + 2] * 2, matrixScale);
    const m = matrixRotation.multiplyToRef(matrixScale, TmpVectors.Matrix[0]).m;
    const covariances = this._tmpCovariances;
    covariances[0] = m[0] * m[0] + m[1] * m[1] + m[2] * m[2];
    covariances[1] = m[0] * m[4] + m[1] * m[5] + m[2] * m[6];
    covariances[2] = m[0] * m[8] + m[1] * m[9] + m[2] * m[10];
    covariances[3] = m[4] * m[4] + m[5] * m[5] + m[6] * m[6];
    covariances[4] = m[4] * m[8] + m[5] * m[9] + m[6] * m[10];
    covariances[5] = m[8] * m[8] + m[9] * m[9] + m[10] * m[10];
    let factor = -1e4;
    for (let covIndex = 0; covIndex < 6; covIndex++) {
      factor = Math.max(factor, Math.abs(covariances[covIndex]));
    }
    this._splatPositions[4 * index + 3] = factor;
    const transform = factor;
    covA[index * 4 + 0] = ToHalfFloat(covariances[0] / transform);
    covA[index * 4 + 1] = ToHalfFloat(covariances[1] / transform);
    covA[index * 4 + 2] = ToHalfFloat(covariances[2] / transform);
    covA[index * 4 + 3] = ToHalfFloat(covariances[3] / transform);
    covB[index * covBSItemSize + 0] = ToHalfFloat(covariances[4] / transform);
    covB[index * covBSItemSize + 1] = ToHalfFloat(covariances[5] / transform);
    colorArray[index * 4 + 0] = uBuffer[32 * index + 24 + 0];
    colorArray[index * 4 + 1] = uBuffer[32 * index + 24 + 1];
    colorArray[index * 4 + 2] = uBuffer[32 * index + 24 + 2];
    colorArray[index * 4 + 3] = uBuffer[32 * index + 24 + 3];
  }
  _updateTextures(covA, covB, colorArray, sh) {
    const textureSize = this._getTextureSize(this._vertexCount);
    const createTextureFromData = (data, width, height, format) => {
      return new RawTexture(data, width, height, format, this._scene, false, false, 2, 1);
    };
    const createTextureFromDataU8 = (data, width, height, format) => {
      return new RawTexture(data, width, height, format, this._scene, false, false, 2, 0);
    };
    const createTextureFromDataU32 = (data, width, height, format) => {
      return new RawTexture(data, width, height, format, this._scene, false, false, 1, 7);
    };
    const createTextureFromDataF16 = (data, width, height, format) => {
      return new RawTexture(data, width, height, format, this._scene, false, false, 2, 2);
    };
    if (this._covariancesATexture) {
      this._delayedTextureUpdate = { covA, covB, colors: colorArray, centers: this._splatPositions, sh };
      const positions = Float32Array.from(this._splatPositions);
      const vertexCount = this._vertexCount;
      this._worker.postMessage({ positions, vertexCount }, [positions.buffer]);
      this._postToWorker(true);
    } else {
      this._covariancesATexture = createTextureFromDataF16(covA, textureSize.x, textureSize.y, 5);
      this._covariancesBTexture = createTextureFromDataF16(covB, textureSize.x, textureSize.y, this._useRGBACovariants ? 5 : 7);
      this._centersTexture = createTextureFromData(this._splatPositions, textureSize.x, textureSize.y, 5);
      this._colorsTexture = createTextureFromDataU8(colorArray, textureSize.x, textureSize.y, 5);
      if (sh) {
        this._shTextures = [];
        for (const shData of sh) {
          const buffer = new Uint32Array(shData.buffer);
          const shTexture = createTextureFromDataU32(buffer, textureSize.x, textureSize.y, 11);
          shTexture.wrapU = 0;
          shTexture.wrapV = 0;
          this._shTextures.push(shTexture);
        }
      }
      this._instanciateWorker();
    }
  }
  *_updateData(data, isAsync, sh) {
    if (!this._covariancesATexture) {
      this._readyToDisplay = false;
    }
    const uBuffer = new Uint8Array(data);
    const fBuffer = new Float32Array(uBuffer.buffer);
    if (this._keepInRam) {
      this._splatsData = data;
      if (sh) {
        this._sh = sh;
      }
    }
    const vertexCount = uBuffer.length / _GaussianSplattingMesh._RowOutputLength;
    if (vertexCount != this._vertexCount) {
      this._updateSplatIndexBuffer(vertexCount);
    }
    this._vertexCount = vertexCount;
    this._shDegree = sh ? sh.length : 0;
    const textureSize = this._getTextureSize(vertexCount);
    const textureLength = textureSize.x * textureSize.y;
    const lineCountUpdate = _GaussianSplattingMesh.ProgressiveUpdateAmount ?? textureSize.y;
    const textureLengthPerUpdate = textureSize.x * lineCountUpdate;
    this._splatPositions = new Float32Array(4 * textureLength);
    const covA = new Uint16Array(textureLength * 4);
    const covB = new Uint16Array((this._useRGBACovariants ? 4 : 2) * textureLength);
    const colorArray = new Uint8Array(textureLength * 4);
    const minimum = new Vector3(Number.MAX_VALUE, Number.MAX_VALUE, Number.MAX_VALUE);
    const maximum = new Vector3(-Number.MAX_VALUE, -Number.MAX_VALUE, -Number.MAX_VALUE);
    if (_GaussianSplattingMesh.ProgressiveUpdateAmount) {
      this._updateTextures(covA, covB, colorArray, sh);
      this.setEnabled(true);
      const partCount = Math.ceil(textureSize.y / lineCountUpdate);
      for (let partIndex = 0; partIndex < partCount; partIndex++) {
        const updateLine = partIndex * lineCountUpdate;
        const splatIndexBase = updateLine * textureSize.x;
        for (let i = 0; i < textureLengthPerUpdate; i++) {
          this._makeSplat(splatIndexBase + i, fBuffer, uBuffer, covA, covB, colorArray, minimum, maximum);
        }
        this._updateSubTextures(this._splatPositions, covA, covB, colorArray, updateLine, Math.min(lineCountUpdate, textureSize.y - updateLine));
        this.getBoundingInfo().reConstruct(minimum, maximum, this.getWorldMatrix());
        if (isAsync) {
          yield;
        }
      }
      const positions = Float32Array.from(this._splatPositions);
      const vertexCount2 = this._vertexCount;
      this._worker.postMessage({ positions, vertexCount: vertexCount2 }, [positions.buffer]);
      this._sortIsDirty = true;
    } else {
      for (let i = 0; i < vertexCount; i++) {
        this._makeSplat(i, fBuffer, uBuffer, covA, covB, colorArray, minimum, maximum);
        if (isAsync && i % _GaussianSplattingMesh._SplatBatchSize === 0) {
          yield;
        }
      }
      this._updateTextures(covA, covB, colorArray, sh);
      this.getBoundingInfo().reConstruct(minimum, maximum, this.getWorldMatrix());
      this.setEnabled(true);
    }
    this._postToWorker(true);
  }
  /**
   * Update asynchronously the buffer
   * @param data array buffer containing center, color, orientation and scale of splats
   * @param sh optional array of uint8 array for SH data
   * @returns a promise
   */
  async updateDataAsync(data, sh) {
    return await runCoroutineAsync(this._updateData(data, true, sh), createYieldingScheduler());
  }
  /**
   * @experimental
   * Update data from GS (position, orientation, color, scaling)
   * @param data array that contain all the datas
   * @param sh optional array of uint8 array for SH data
   */
  updateData(data, sh) {
    runCoroutineSync(this._updateData(data, false, sh));
  }
  /**
   * Refreshes the bounding info, taking into account all the thin instances defined
   * @returns the current Gaussian Splatting
   */
  refreshBoundingInfo() {
    this.thinInstanceRefreshBoundingInfo(false);
    return this;
  }
  // in case size is different
  _updateSplatIndexBuffer(vertexCount) {
    if (!this._splatIndex || vertexCount > this._splatIndex.length) {
      this._splatIndex = new Float32Array(vertexCount);
      this.thinInstanceSetBuffer("splatIndex", this._splatIndex, 1, false);
    }
    this.forcedInstanceCount = vertexCount;
  }
  _updateSubTextures(centers, covA, covB, colors, lineStart, lineCount, sh) {
    const updateTextureFromData = (texture, data, width, lineStart2, lineCount2) => {
      this.getEngine().updateTextureData(texture.getInternalTexture(), data, 0, lineStart2, width, lineCount2, 0, 0, false);
    };
    const textureSize = this._getTextureSize(this._vertexCount);
    const covBSItemSize = this._useRGBACovariants ? 4 : 2;
    const texelStart = lineStart * textureSize.x;
    const texelCount = lineCount * textureSize.x;
    const covAView = new Uint16Array(covA.buffer, texelStart * 4 * Uint16Array.BYTES_PER_ELEMENT, texelCount * 4);
    const covBView = new Uint16Array(covB.buffer, texelStart * covBSItemSize * Uint16Array.BYTES_PER_ELEMENT, texelCount * covBSItemSize);
    const colorsView = new Uint8Array(colors.buffer, texelStart * 4, texelCount * 4);
    const centersView = new Float32Array(centers.buffer, texelStart * 4 * Float32Array.BYTES_PER_ELEMENT, texelCount * 4);
    updateTextureFromData(this._covariancesATexture, covAView, textureSize.x, lineStart, lineCount);
    updateTextureFromData(this._covariancesBTexture, covBView, textureSize.x, lineStart, lineCount);
    updateTextureFromData(this._centersTexture, centersView, textureSize.x, lineStart, lineCount);
    updateTextureFromData(this._colorsTexture, colorsView, textureSize.x, lineStart, lineCount);
    if (sh) {
      for (let i = 0; i < sh.length; i++) {
        const componentCount = 4;
        const shView = new Uint8Array(this._sh[i].buffer, texelStart * componentCount, texelCount * componentCount);
        updateTextureFromData(this._shTextures[i], shView, textureSize.x, lineStart, lineCount);
      }
    }
  }
  _instanciateWorker() {
    if (!this._vertexCount) {
      return;
    }
    this._updateSplatIndexBuffer(this._vertexCount);
    this._worker?.terminate();
    this._worker = new Worker(URL.createObjectURL(new Blob(["(", _GaussianSplattingMesh._CreateWorker.toString(), ")(self)"], {
      type: "application/javascript"
    })));
    this._depthMix = new BigInt64Array(this._vertexCount);
    const positions = Float32Array.from(this._splatPositions);
    const vertexCount = this._vertexCount;
    this._worker.postMessage({ positions, vertexCount }, [positions.buffer]);
    this._worker.onmessage = (e) => {
      this._depthMix = e.data.depthMix;
      const indexMix = new Uint32Array(e.data.depthMix.buffer);
      if (this._splatIndex) {
        for (let j = 0; j < this._vertexCount; j++) {
          this._splatIndex[j] = indexMix[2 * j];
        }
      }
      if (this._delayedTextureUpdate) {
        const textureSize = this._getTextureSize(vertexCount);
        this._updateSubTextures(this._delayedTextureUpdate.centers, this._delayedTextureUpdate.covA, this._delayedTextureUpdate.covB, this._delayedTextureUpdate.colors, 0, textureSize.y, this._delayedTextureUpdate.sh);
        this._delayedTextureUpdate = null;
      }
      this.thinInstanceBufferUpdated("splatIndex");
      this._canPostToWorker = true;
      this._readyToDisplay = true;
      if (this._sortIsDirty) {
        this._postToWorker(true);
        this._sortIsDirty = false;
      }
    };
  }
  _getTextureSize(length) {
    const engine = this._scene.getEngine();
    const width = engine.getCaps().maxTextureSize;
    let height = 1;
    if (engine.version === 1 && !engine.isWebGPU) {
      while (width * height < length) {
        height *= 2;
      }
    } else {
      height = Math.ceil(length / width);
    }
    if (height > width) {
      Logger.Error("GaussianSplatting texture size: (" + width + ", " + height + "), maxTextureSize: " + width);
      height = width;
    }
    return new Vector2(width, height);
  }
};
GaussianSplattingMesh._RowOutputLength = 3 * 4 + 3 * 4 + 4 + 4;
GaussianSplattingMesh._SH_C0 = 0.28209479177387814;
GaussianSplattingMesh._SplatBatchSize = 327680;
GaussianSplattingMesh._PlyConversionBatchSize = 32768;
GaussianSplattingMesh.ProgressiveUpdateAmount = 0;
GaussianSplattingMesh._CreateWorker = function(self) {
  let vertexCount = 0;
  let positions;
  let depthMix;
  let indices;
  let floatMix;
  self.onmessage = (e) => {
    if (e.data.positions) {
      positions = e.data.positions;
      vertexCount = e.data.vertexCount;
    } else {
      const viewProj = e.data.view;
      if (!positions || !viewProj) {
        throw new Error("positions or view is not defined!");
      }
      depthMix = e.data.depthMix;
      indices = new Uint32Array(depthMix.buffer);
      floatMix = new Float32Array(depthMix.buffer);
      for (let j = 0; j < vertexCount; j++) {
        indices[2 * j] = j;
      }
      let depthFactor = -1;
      if (e.data.useRightHandedSystem) {
        depthFactor = 1;
      }
      for (let j = 0; j < vertexCount; j++) {
        floatMix[2 * j + 1] = 1e4 + (viewProj[2] * positions[4 * j + 0] + viewProj[6] * positions[4 * j + 1] + viewProj[10] * positions[4 * j + 2]) * depthFactor;
      }
      depthMix.sort();
      self.postMessage({ depthMix }, [depthMix.buffer]);
    }
  };
};

// node_modules/@babylonjs/core/Misc/deferred.js
var Deferred = class {
  /**
   * The resolve method of the promise associated with this deferred object.
   */
  get resolve() {
    return this._resolve;
  }
  /**
   * The reject method of the promise associated with this deferred object.
   */
  get reject() {
    return this._reject;
  }
  /**
   * Constructor for this deferred object.
   */
  constructor() {
    this.promise = new Promise((resolve, reject) => {
      this._resolve = resolve;
      this._reject = reject;
    });
  }
};

// node_modules/@babylonjs/core/Misc/dataReader.js
var DataReader = class {
  /**
   * Constructor
   * @param buffer The buffer to read
   */
  constructor(buffer) {
    this.byteOffset = 0;
    this.buffer = buffer;
  }
  /**
   * Loads the given byte length.
   * @param byteLength The byte length to load
   * @returns A promise that resolves when the load is complete
   */
  async loadAsync(byteLength) {
    const data = await this.buffer.readAsync(this.byteOffset, byteLength);
    this._dataView = new DataView(data.buffer, data.byteOffset, data.byteLength);
    this._dataByteOffset = 0;
  }
  /**
   * Read a unsigned 32-bit integer from the currently loaded data range.
   * @returns The 32-bit integer read
   */
  readUint32() {
    const value = this._dataView.getUint32(this._dataByteOffset, true);
    this._dataByteOffset += 4;
    this.byteOffset += 4;
    return value;
  }
  /**
   * Read a byte array from the currently loaded data range.
   * @param byteLength The byte length to read
   * @returns The byte array read
   */
  readUint8Array(byteLength) {
    const value = new Uint8Array(this._dataView.buffer, this._dataView.byteOffset + this._dataByteOffset, byteLength);
    this._dataByteOffset += byteLength;
    this.byteOffset += byteLength;
    return value;
  }
  /**
   * Read a string from the currently loaded data range.
   * @param byteLength The byte length to read
   * @returns The string read
   */
  readString(byteLength) {
    return Decode(this.readUint8Array(byteLength));
  }
  /**
   * Skips the given byte length the currently loaded data range.
   * @param byteLength The byte length to skip
   */
  skipBytes(byteLength) {
    this._dataByteOffset += byteLength;
    this.byteOffset += byteLength;
  }
};

// node_modules/@babylonjs/core/Misc/lazy.js
var Lazy = class {
  /**
   * Creates a new instance of the Lazy class.
   * @param factory A function that creates the value.
   */
  constructor(factory) {
    this._factory = factory;
  }
  /**
   * Gets the lazily initialized value.
   */
  get value() {
    if (this._factory) {
      this._value = this._factory();
      this._factory = void 0;
    }
    return this._value;
  }
};

// node_modules/@babylonjs/core/Particles/cloudPoint.js
var CloudPoint = class {
  /**
   * Creates a Point Cloud object.
   * Don't create particles manually, use instead the PCS internal tools like _addParticle()
   * @param particleIndex (integer) is the particle index in the PCS pool. It's also the particle identifier.
   * @param group (PointsGroup) is the group the particle belongs to
   * @param groupId (integer) is the group identifier in the PCS.
   * @param idxInGroup (integer) is the index of the particle in the current point group (ex: the 10th point of addPoints(30))
   * @param pcs defines the PCS it is associated to
   */
  constructor(particleIndex, group, groupId, idxInGroup, pcs) {
    this.idx = 0;
    this.color = new Color4(1, 1, 1, 1);
    this.position = Vector3.Zero();
    this.rotation = Vector3.Zero();
    this.uv = new Vector2(0, 0);
    this.velocity = Vector3.Zero();
    this.pivot = Vector3.Zero();
    this.translateFromPivot = false;
    this._pos = 0;
    this._ind = 0;
    this.groupId = 0;
    this.idxInGroup = 0;
    this._stillInvisible = false;
    this._rotationMatrix = [1, 0, 0, 0, 1, 0, 0, 0, 1];
    this.parentId = null;
    this._globalPosition = Vector3.Zero();
    this.idx = particleIndex;
    this._group = group;
    this.groupId = groupId;
    this.idxInGroup = idxInGroup;
    this._pcs = pcs;
  }
  /**
   * get point size
   */
  get size() {
    return this.size;
  }
  /**
   * Set point size
   */
  set size(scale) {
    this.size = scale;
  }
  /**
   * Legacy support, changed quaternion to rotationQuaternion
   */
  get quaternion() {
    return this.rotationQuaternion;
  }
  /**
   * Legacy support, changed quaternion to rotationQuaternion
   */
  set quaternion(q) {
    this.rotationQuaternion = q;
  }
  /**
   * Returns a boolean. True if the particle intersects a mesh, else false
   * The intersection is computed on the particle position and Axis Aligned Bounding Box (AABB) or Sphere
   * @param target is the object (point or mesh) what the intersection is computed against
   * @param isSphere is boolean flag when false (default) bounding box of mesh is used, when true the bounding sphere is used
   * @returns true if it intersects
   */
  intersectsMesh(target, isSphere) {
    if (!target.hasBoundingInfo) {
      return false;
    }
    if (!this._pcs.mesh) {
      throw new Error("Point Cloud System doesnt contain the Mesh");
    }
    if (isSphere) {
      return target.getBoundingInfo().boundingSphere.intersectsPoint(this.position.add(this._pcs.mesh.position));
    }
    const bbox = target.getBoundingInfo().boundingBox;
    const maxX = bbox.maximumWorld.x;
    const minX = bbox.minimumWorld.x;
    const maxY = bbox.maximumWorld.y;
    const minY = bbox.minimumWorld.y;
    const maxZ = bbox.maximumWorld.z;
    const minZ = bbox.minimumWorld.z;
    const x = this.position.x + this._pcs.mesh.position.x;
    const y = this.position.y + this._pcs.mesh.position.y;
    const z = this.position.z + this._pcs.mesh.position.z;
    return minX <= x && x <= maxX && minY <= y && y <= maxY && minZ <= z && z <= maxZ;
  }
  /**
   * get the rotation matrix of the particle
   * @internal
   */
  getRotationMatrix(m) {
    let quaternion;
    if (this.rotationQuaternion) {
      quaternion = this.rotationQuaternion;
    } else {
      quaternion = TmpVectors.Quaternion[0];
      const rotation = this.rotation;
      Quaternion.RotationYawPitchRollToRef(rotation.y, rotation.x, rotation.z, quaternion);
    }
    quaternion.toRotationMatrix(m);
  }
};
var PointsGroup = class {
  /**
   * Get or set the groupId
   * @deprecated Please use groupId instead
   */
  // eslint-disable-next-line @typescript-eslint/naming-convention
  get groupID() {
    return this.groupId;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set groupID(groupID) {
    this.groupId = groupID;
  }
  /**
   * Creates a points group object. This is an internal reference to produce particles for the PCS.
   * PCS internal tool, don't use it manually.
   * @internal
   */
  constructor(id, posFunction) {
    this.groupId = id;
    this._positionFunction = posFunction;
  }
};

// node_modules/@babylonjs/core/Culling/ray.js
AddRayExtensions(Scene, Camera);
Scene.prototype.createPickingRayToRef = function(x, y, world, result, camera, cameraViewSpace = false, enableDistantPicking = false) {
  return CreatePickingRayToRef(this, x, y, world, result, camera, cameraViewSpace, enableDistantPicking);
};
Scene.prototype.createPickingRayInCameraSpace = function(x, y, camera) {
  return CreatePickingRayInCameraSpace(this, x, y, camera);
};
Scene.prototype.createPickingRayInCameraSpaceToRef = function(x, y, result, camera) {
  return CreatePickingRayInCameraSpaceToRef(this, x, y, result, camera);
};
Scene.prototype.pickWithBoundingInfo = function(x, y, predicate, fastCheck, camera) {
  return PickWithBoundingInfo(this, x, y, predicate, fastCheck, camera);
};
Scene.prototype.pick = function(x, y, predicate, fastCheck, camera, trianglePredicate, _enableDistantPicking = false) {
  return Pick(this, x, y, predicate, fastCheck, camera, trianglePredicate, _enableDistantPicking);
};
Scene.prototype.pickWithRay = function(ray, predicate, fastCheck, trianglePredicate) {
  return PickWithRay(this, ray, predicate, fastCheck, trianglePredicate);
};
Scene.prototype.multiPick = function(x, y, predicate, camera, trianglePredicate) {
  return MultiPick(this, x, y, predicate, camera, trianglePredicate);
};
Scene.prototype.multiPickWithRay = function(ray, predicate, trianglePredicate) {
  return MultiPickWithRay(this, ray, predicate, trianglePredicate);
};

// node_modules/@babylonjs/core/Particles/pointsCloudSystem.js
var PointColor;
(function(PointColor2) {
  PointColor2[PointColor2["Color"] = 2] = "Color";
  PointColor2[PointColor2["UV"] = 1] = "UV";
  PointColor2[PointColor2["Random"] = 0] = "Random";
  PointColor2[PointColor2["Stated"] = 3] = "Stated";
})(PointColor || (PointColor = {}));
var PointsCloudSystem = class {
  /**
   * Gets the particle positions computed by the Point Cloud System
   */
  get positions() {
    return this._positions32;
  }
  /**
   * Gets the particle colors computed by the Point Cloud System
   */
  get colors() {
    return this._colors32;
  }
  /**
   * Gets the particle uvs computed by the Point Cloud System
   */
  get uvs() {
    return this._uvs32;
  }
  /**
   * Creates a PCS (Points Cloud System) object
   * @param name (String) is the PCS name, this will be the underlying mesh name
   * @param pointSize (number) is the size for each point. Has no effect on a WebGPU engine.
   * @param scene (Scene) is the scene in which the PCS is added
   * @param options defines the options of the PCS e.g.
   * * updatable (optional boolean, default true) : if the PCS must be updatable or immutable
   */
  constructor(name, pointSize, scene, options) {
    this.particles = new Array();
    this.nbParticles = 0;
    this.counter = 0;
    this.vars = {};
    this._promises = [];
    this._positions = new Array();
    this._indices = new Array();
    this._normals = new Array();
    this._colors = new Array();
    this._uvs = new Array();
    this._updatable = true;
    this._isVisibilityBoxLocked = false;
    this._alwaysVisible = false;
    this._groups = new Array();
    this._groupCounter = 0;
    this._computeParticleColor = true;
    this._computeParticleTexture = true;
    this._computeParticleRotation = true;
    this._computeBoundingBox = false;
    this._isReady = false;
    this.name = name;
    this._size = pointSize;
    this._scene = scene || EngineStore.LastCreatedScene;
    if (options && options.updatable !== void 0) {
      this._updatable = options.updatable;
    } else {
      this._updatable = true;
    }
  }
  /**
   * Builds the PCS underlying mesh. Returns a standard Mesh.
   * If no points were added to the PCS, the returned mesh is just a single point.
   * @param material The material to use to render the mesh. If not provided, will create a default one
   * @returns a promise for the created mesh
   */
  async buildMeshAsync(material) {
    await Promise.all(this._promises);
    this._isReady = true;
    return await this._buildMeshAsync(material);
  }
  async _buildMeshAsync(material) {
    if (this.nbParticles === 0) {
      this.addPoints(1);
    }
    this._positions32 = new Float32Array(this._positions);
    this._uvs32 = new Float32Array(this._uvs);
    this._colors32 = new Float32Array(this._colors);
    const vertexData = new VertexData();
    vertexData.set(this._positions32, VertexBuffer.PositionKind);
    if (this._uvs32.length > 0) {
      vertexData.set(this._uvs32, VertexBuffer.UVKind);
    }
    let ec = 0;
    if (this._colors32.length > 0) {
      ec = 1;
      vertexData.set(this._colors32, VertexBuffer.ColorKind);
    }
    const mesh = new Mesh(this.name, this._scene);
    vertexData.applyToMesh(mesh, this._updatable);
    this.mesh = mesh;
    this._positions = null;
    this._uvs = null;
    this._colors = null;
    if (!this._updatable) {
      this.particles.length = 0;
    }
    let mat = material;
    if (!mat) {
      mat = new StandardMaterial("point cloud material", this._scene);
      mat.emissiveColor = new Color3(ec, ec, ec);
      mat.disableLighting = true;
      mat.pointsCloud = true;
      mat.pointSize = this._size;
    }
    mesh.material = mat;
    return mesh;
  }
  // adds a new particle object in the particles array
  _addParticle(idx, group, groupId, idxInGroup) {
    const cp = new CloudPoint(idx, group, groupId, idxInGroup, this);
    this.particles.push(cp);
    return cp;
  }
  _randomUnitVector(particle) {
    particle.position = new Vector3(Math.random(), Math.random(), Math.random());
    particle.color = new Color4(1, 1, 1, 1);
  }
  _getColorIndicesForCoord(pointsGroup, x, y, width) {
    const imageData = pointsGroup._groupImageData;
    const color = y * (width * 4) + x * 4;
    const colorIndices = [color, color + 1, color + 2, color + 3];
    const redIndex = colorIndices[0];
    const greenIndex = colorIndices[1];
    const blueIndex = colorIndices[2];
    const alphaIndex = colorIndices[3];
    const redForCoord = imageData[redIndex];
    const greenForCoord = imageData[greenIndex];
    const blueForCoord = imageData[blueIndex];
    const alphaForCoord = imageData[alphaIndex];
    return new Color4(redForCoord / 255, greenForCoord / 255, blueForCoord / 255, alphaForCoord);
  }
  _setPointsColorOrUV(mesh, pointsGroup, isVolume, colorFromTexture, hasTexture, color, range, uvSetIndex) {
    uvSetIndex = uvSetIndex ?? 0;
    if (isVolume) {
      mesh.updateFacetData();
    }
    const boundInfo = mesh.getBoundingInfo();
    const diameter = 2 * boundInfo.boundingSphere.radius;
    let meshPos = mesh.getVerticesData(VertexBuffer.PositionKind);
    const meshInd = mesh.getIndices();
    const meshUV = mesh.getVerticesData(VertexBuffer.UVKind + (uvSetIndex ? uvSetIndex + 1 : ""));
    const meshCol = mesh.getVerticesData(VertexBuffer.ColorKind);
    const place = Vector3.Zero();
    mesh.computeWorldMatrix();
    const meshMatrix = mesh.getWorldMatrix();
    if (!meshMatrix.isIdentity()) {
      meshPos = meshPos.slice(0);
      for (let p = 0; p < meshPos.length / 3; p++) {
        Vector3.TransformCoordinatesFromFloatsToRef(meshPos[3 * p], meshPos[3 * p + 1], meshPos[3 * p + 2], meshMatrix, place);
        meshPos[3 * p] = place.x;
        meshPos[3 * p + 1] = place.y;
        meshPos[3 * p + 2] = place.z;
      }
    }
    let idxPoints = 0;
    let id0 = 0;
    let id1 = 0;
    let id2 = 0;
    let v0X = 0;
    let v0Y = 0;
    let v0Z = 0;
    let v1X = 0;
    let v1Y = 0;
    let v1Z = 0;
    let v2X = 0;
    let v2Y = 0;
    let v2Z = 0;
    const vertex0 = Vector3.Zero();
    const vertex1 = Vector3.Zero();
    const vertex2 = Vector3.Zero();
    const vec0 = Vector3.Zero();
    const vec1 = Vector3.Zero();
    let uv0X = 0;
    let uv0Y = 0;
    let uv1X = 0;
    let uv1Y = 0;
    let uv2X = 0;
    let uv2Y = 0;
    const uv0 = Vector2.Zero();
    const uv1 = Vector2.Zero();
    const uv2 = Vector2.Zero();
    const uvec0 = Vector2.Zero();
    const uvec1 = Vector2.Zero();
    let col0X = 0;
    let col0Y = 0;
    let col0Z = 0;
    let col0A = 0;
    let col1X = 0;
    let col1Y = 0;
    let col1Z = 0;
    let col1A = 0;
    let col2X = 0;
    let col2Y = 0;
    let col2Z = 0;
    let col2A = 0;
    const col0 = Vector4.Zero();
    const col1 = Vector4.Zero();
    const col2 = Vector4.Zero();
    const colvec0 = Vector4.Zero();
    const colvec1 = Vector4.Zero();
    let lamda = 0;
    let mu = 0;
    range = range ? range : 0;
    let facetPoint;
    let uvPoint;
    let colPoint = new Vector4(0, 0, 0, 0);
    let norm = Vector3.Zero();
    let tang = Vector3.Zero();
    let biNorm = Vector3.Zero();
    let angle = 0;
    let facetPlaneVec = Vector3.Zero();
    let gap = 0;
    let distance = 0;
    const ray = new Ray(Vector3.Zero(), new Vector3(1, 0, 0));
    let pickInfo;
    let direction = Vector3.Zero();
    for (let index = 0; index < meshInd.length / 3; index++) {
      id0 = meshInd[3 * index];
      id1 = meshInd[3 * index + 1];
      id2 = meshInd[3 * index + 2];
      v0X = meshPos[3 * id0];
      v0Y = meshPos[3 * id0 + 1];
      v0Z = meshPos[3 * id0 + 2];
      v1X = meshPos[3 * id1];
      v1Y = meshPos[3 * id1 + 1];
      v1Z = meshPos[3 * id1 + 2];
      v2X = meshPos[3 * id2];
      v2Y = meshPos[3 * id2 + 1];
      v2Z = meshPos[3 * id2 + 2];
      vertex0.set(v0X, v0Y, v0Z);
      vertex1.set(v1X, v1Y, v1Z);
      vertex2.set(v2X, v2Y, v2Z);
      vertex1.subtractToRef(vertex0, vec0);
      vertex2.subtractToRef(vertex1, vec1);
      if (meshUV) {
        uv0X = meshUV[2 * id0];
        uv0Y = meshUV[2 * id0 + 1];
        uv1X = meshUV[2 * id1];
        uv1Y = meshUV[2 * id1 + 1];
        uv2X = meshUV[2 * id2];
        uv2Y = meshUV[2 * id2 + 1];
        uv0.set(uv0X, uv0Y);
        uv1.set(uv1X, uv1Y);
        uv2.set(uv2X, uv2Y);
        uv1.subtractToRef(uv0, uvec0);
        uv2.subtractToRef(uv1, uvec1);
      }
      if (meshCol && colorFromTexture) {
        col0X = meshCol[4 * id0];
        col0Y = meshCol[4 * id0 + 1];
        col0Z = meshCol[4 * id0 + 2];
        col0A = meshCol[4 * id0 + 3];
        col1X = meshCol[4 * id1];
        col1Y = meshCol[4 * id1 + 1];
        col1Z = meshCol[4 * id1 + 2];
        col1A = meshCol[4 * id1 + 3];
        col2X = meshCol[4 * id2];
        col2Y = meshCol[4 * id2 + 1];
        col2Z = meshCol[4 * id2 + 2];
        col2A = meshCol[4 * id2 + 3];
        col0.set(col0X, col0Y, col0Z, col0A);
        col1.set(col1X, col1Y, col1Z, col1A);
        col2.set(col2X, col2Y, col2Z, col2A);
        col1.subtractToRef(col0, colvec0);
        col2.subtractToRef(col1, colvec1);
      }
      let width;
      let height;
      let deltaS;
      let deltaV;
      let h;
      let s;
      let v;
      let hsvCol;
      const statedColor = new Color3(0, 0, 0);
      const colPoint3 = new Color3(0, 0, 0);
      let pointColors;
      let particle;
      for (let i = 0; i < pointsGroup._groupDensity[index]; i++) {
        idxPoints = this.particles.length;
        this._addParticle(idxPoints, pointsGroup, this._groupCounter, index + i);
        particle = this.particles[idxPoints];
        lamda = Math.sqrt(RandomRange(0, 1));
        mu = RandomRange(0, 1);
        facetPoint = vertex0.add(vec0.scale(lamda)).add(vec1.scale(lamda * mu));
        if (isVolume) {
          norm = mesh.getFacetNormal(index).normalize().scale(-1);
          tang = vec0.clone().normalize();
          biNorm = Vector3.Cross(norm, tang);
          angle = RandomRange(0, 2 * Math.PI);
          facetPlaneVec = tang.scale(Math.cos(angle)).add(biNorm.scale(Math.sin(angle)));
          angle = RandomRange(0.1, Math.PI / 2);
          direction = facetPlaneVec.scale(Math.cos(angle)).add(norm.scale(Math.sin(angle)));
          ray.origin = facetPoint.add(direction.scale(1e-5));
          ray.direction = direction;
          ray.length = diameter;
          pickInfo = ray.intersectsMesh(mesh);
          if (pickInfo.hit) {
            distance = pickInfo.pickedPoint.subtract(facetPoint).length();
            gap = RandomRange(0, 1) * distance;
            facetPoint.addInPlace(direction.scale(gap));
          }
        }
        particle.position = facetPoint.clone();
        this._positions.push(particle.position.x, particle.position.y, particle.position.z);
        if (colorFromTexture !== void 0) {
          if (meshUV) {
            uvPoint = uv0.add(uvec0.scale(lamda)).add(uvec1.scale(lamda * mu));
            if (colorFromTexture) {
              if (hasTexture && pointsGroup._groupImageData !== null) {
                width = pointsGroup._groupImgWidth;
                height = pointsGroup._groupImgHeight;
                pointColors = this._getColorIndicesForCoord(pointsGroup, Math.round(uvPoint.x * width), Math.round(uvPoint.y * height), width);
                particle.color = pointColors;
                this._colors.push(pointColors.r, pointColors.g, pointColors.b, pointColors.a);
              } else {
                if (meshCol) {
                  colPoint = col0.add(colvec0.scale(lamda)).add(colvec1.scale(lamda * mu));
                  particle.color = new Color4(colPoint.x, colPoint.y, colPoint.z, colPoint.w);
                  this._colors.push(colPoint.x, colPoint.y, colPoint.z, colPoint.w);
                } else {
                  colPoint = col0.set(Math.random(), Math.random(), Math.random(), 1);
                  particle.color = new Color4(colPoint.x, colPoint.y, colPoint.z, colPoint.w);
                  this._colors.push(colPoint.x, colPoint.y, colPoint.z, colPoint.w);
                }
              }
            } else {
              particle.uv = uvPoint.clone();
              this._uvs.push(particle.uv.x, particle.uv.y);
            }
          }
        } else {
          if (color) {
            statedColor.set(color.r, color.g, color.b);
            deltaS = RandomRange(-range, range);
            deltaV = RandomRange(-range, range);
            hsvCol = statedColor.toHSV();
            h = hsvCol.r;
            s = hsvCol.g + deltaS;
            v = hsvCol.b + deltaV;
            if (s < 0) {
              s = 0;
            }
            if (s > 1) {
              s = 1;
            }
            if (v < 0) {
              v = 0;
            }
            if (v > 1) {
              v = 1;
            }
            Color3.HSVtoRGBToRef(h, s, v, colPoint3);
            colPoint.set(colPoint3.r, colPoint3.g, colPoint3.b, 1);
          } else {
            colPoint = col0.set(Math.random(), Math.random(), Math.random(), 1);
          }
          particle.color = new Color4(colPoint.x, colPoint.y, colPoint.z, colPoint.w);
          this._colors.push(colPoint.x, colPoint.y, colPoint.z, colPoint.w);
        }
      }
    }
  }
  // stores mesh texture in dynamic texture for color pixel retrieval
  // when pointColor type is color for surface points
  _colorFromTexture(mesh, pointsGroup, isVolume) {
    if (mesh.material === null) {
      Logger.Warn(mesh.name + "has no material.");
      pointsGroup._groupImageData = null;
      this._setPointsColorOrUV(mesh, pointsGroup, isVolume, true, false);
      return;
    }
    const mat = mesh.material;
    const textureList = mat.getActiveTextures();
    if (textureList.length === 0) {
      Logger.Warn(mesh.name + "has no usable texture.");
      pointsGroup._groupImageData = null;
      this._setPointsColorOrUV(mesh, pointsGroup, isVolume, true, false);
      return;
    }
    const clone = mesh.clone();
    clone.setEnabled(false);
    this._promises.push(new Promise((resolve) => {
      BaseTexture.WhenAllReady(textureList, () => {
        let n = pointsGroup._textureNb;
        if (n < 0) {
          n = 0;
        }
        if (n > textureList.length - 1) {
          n = textureList.length - 1;
        }
        const finalize = () => {
          pointsGroup._groupImgWidth = textureList[n].getSize().width;
          pointsGroup._groupImgHeight = textureList[n].getSize().height;
          this._setPointsColorOrUV(clone, pointsGroup, isVolume, true, true, void 0, void 0, textureList[n].coordinatesIndex);
          clone.dispose();
          resolve();
        };
        pointsGroup._groupImageData = null;
        const dataPromise = textureList[n].readPixels();
        if (!dataPromise) {
          finalize();
        } else {
          dataPromise.then((data) => {
            pointsGroup._groupImageData = data;
            finalize();
          });
        }
      });
    }));
  }
  // calculates the point density per facet of a mesh for surface points
  _calculateDensity(nbPoints, positions, indices) {
    let id0;
    let id1;
    let id2;
    let v0X;
    let v0Y;
    let v0Z;
    let v1X;
    let v1Y;
    let v1Z;
    let v2X;
    let v2Y;
    let v2Z;
    const vertex0 = Vector3.Zero();
    const vertex1 = Vector3.Zero();
    const vertex2 = Vector3.Zero();
    const vec0 = Vector3.Zero();
    const vec1 = Vector3.Zero();
    const normal = Vector3.Zero();
    let area;
    const cumulativeAreas = [];
    let surfaceArea = 0;
    const nbFacets = indices.length / 3;
    for (let index = 0; index < nbFacets; index++) {
      id0 = indices[3 * index];
      id1 = indices[3 * index + 1];
      id2 = indices[3 * index + 2];
      v0X = positions[3 * id0];
      v0Y = positions[3 * id0 + 1];
      v0Z = positions[3 * id0 + 2];
      v1X = positions[3 * id1];
      v1Y = positions[3 * id1 + 1];
      v1Z = positions[3 * id1 + 2];
      v2X = positions[3 * id2];
      v2Y = positions[3 * id2 + 1];
      v2Z = positions[3 * id2 + 2];
      vertex0.set(v0X, v0Y, v0Z);
      vertex1.set(v1X, v1Y, v1Z);
      vertex2.set(v2X, v2Y, v2Z);
      vertex1.subtractToRef(vertex0, vec0);
      vertex2.subtractToRef(vertex1, vec1);
      Vector3.CrossToRef(vec0, vec1, normal);
      area = 0.5 * normal.length();
      surfaceArea += area;
      cumulativeAreas[index] = surfaceArea;
    }
    const density = new Array(nbFacets);
    let remainingPoints = nbPoints;
    for (let index = nbFacets - 1; index > 0; index--) {
      const cumulativeArea = cumulativeAreas[index];
      if (cumulativeArea === 0) {
        density[index] = 0;
      } else {
        const area2 = cumulativeArea - cumulativeAreas[index - 1];
        const facetPointsWithFraction = area2 / cumulativeArea * remainingPoints;
        const floored = Math.floor(facetPointsWithFraction);
        const fraction = facetPointsWithFraction - floored;
        const extraPoint = Number(Math.random() < fraction);
        const facetPoints = floored + extraPoint;
        density[index] = facetPoints;
        remainingPoints -= facetPoints;
      }
    }
    density[0] = remainingPoints;
    return density;
  }
  /**
   * Adds points to the PCS in random positions within a unit sphere
   * @param nb (positive integer) the number of particles to be created from this model
   * @param pointFunction is an optional javascript function to be called for each particle on PCS creation
   * @returns the number of groups in the system
   */
  addPoints(nb, pointFunction = this._randomUnitVector) {
    const pointsGroup = new PointsGroup(this._groupCounter, pointFunction);
    let cp;
    let idx = this.nbParticles;
    for (let i = 0; i < nb; i++) {
      cp = this._addParticle(idx, pointsGroup, this._groupCounter, i);
      if (pointsGroup && pointsGroup._positionFunction) {
        pointsGroup._positionFunction(cp, idx, i);
      }
      this._positions.push(cp.position.x, cp.position.y, cp.position.z);
      if (cp.color) {
        this._colors.push(cp.color.r, cp.color.g, cp.color.b, cp.color.a);
      }
      if (cp.uv) {
        this._uvs.push(cp.uv.x, cp.uv.y);
      }
      idx++;
    }
    this.nbParticles += nb;
    this._groupCounter++;
    return this._groupCounter;
  }
  /**
   * Adds points to the PCS from the surface of the model shape
   * @param mesh is any Mesh object that will be used as a surface model for the points
   * @param nb (positive integer) the number of particles to be created from this model
   * @param colorWith determines whether a point is colored using color (default), uv, random, stated or none (invisible)
   * @param color (color4) to be used when colorWith is stated or color (number) when used to specify texture position
   * @param range (number from 0 to 1) to determine the variation in shape and tone for a stated color
   * @returns the number of groups in the system
   */
  addSurfacePoints(mesh, nb, colorWith, color, range) {
    let colored = colorWith ? colorWith : 0;
    if (isNaN(colored) || colored < 0 || colored > 3) {
      colored = 0;
    }
    const meshPos = mesh.getVerticesData(VertexBuffer.PositionKind);
    const meshInd = mesh.getIndices();
    this._groups.push(this._groupCounter);
    const pointsGroup = new PointsGroup(this._groupCounter, null);
    pointsGroup._groupDensity = this._calculateDensity(nb, meshPos, meshInd);
    if (colored === 2) {
      pointsGroup._textureNb = color ? color : 0;
    } else {
      color = color ? color : new Color4(1, 1, 1, 1);
    }
    switch (colored) {
      case 2:
        this._colorFromTexture(mesh, pointsGroup, false);
        break;
      case 1:
        this._setPointsColorOrUV(mesh, pointsGroup, false, false, false);
        break;
      case 0:
        this._setPointsColorOrUV(mesh, pointsGroup, false);
        break;
      case 3:
        this._setPointsColorOrUV(mesh, pointsGroup, false, void 0, void 0, color, range);
        break;
    }
    this.nbParticles += nb;
    this._groupCounter++;
    return this._groupCounter - 1;
  }
  /**
   * Adds points to the PCS inside the model shape
   * @param mesh is any Mesh object that will be used as a surface model for the points
   * @param nb (positive integer) the number of particles to be created from this model
   * @param colorWith determines whether a point is colored using color (default), uv, random, stated or none (invisible)
   * @param color (color4) to be used when colorWith is stated or color (number) when used to specify texture position
   * @param range (number from 0 to 1) to determine the variation in shape and tone for a stated color
   * @returns the number of groups in the system
   */
  addVolumePoints(mesh, nb, colorWith, color, range) {
    let colored = colorWith ? colorWith : 0;
    if (isNaN(colored) || colored < 0 || colored > 3) {
      colored = 0;
    }
    const meshPos = mesh.getVerticesData(VertexBuffer.PositionKind);
    const meshInd = mesh.getIndices();
    this._groups.push(this._groupCounter);
    const pointsGroup = new PointsGroup(this._groupCounter, null);
    pointsGroup._groupDensity = this._calculateDensity(nb, meshPos, meshInd);
    if (colored === 2) {
      pointsGroup._textureNb = color ? color : 0;
    } else {
      color = color ? color : new Color4(1, 1, 1, 1);
    }
    switch (colored) {
      case 2:
        this._colorFromTexture(mesh, pointsGroup, true);
        break;
      case 1:
        this._setPointsColorOrUV(mesh, pointsGroup, true, false, false);
        break;
      case 0:
        this._setPointsColorOrUV(mesh, pointsGroup, true);
        break;
      case 3:
        this._setPointsColorOrUV(mesh, pointsGroup, true, void 0, void 0, color, range);
        break;
    }
    this.nbParticles += nb;
    this._groupCounter++;
    return this._groupCounter - 1;
  }
  /**
   *  Sets all the particles : this method actually really updates the mesh according to the particle positions, rotations, colors, textures, etc.
   *  This method calls `updateParticle()` for each particle of the SPS.
   *  For an animated SPS, it is usually called within the render loop.
   * @param start The particle index in the particle array where to start to compute the particle property values _(default 0)_
   * @param end The particle index in the particle array where to stop to compute the particle property values _(default nbParticle - 1)_
   * @param update If the mesh must be finally updated on this call after all the particle computations _(default true)_
   * @returns the PCS.
   */
  setParticles(start = 0, end = this.nbParticles - 1, update = true) {
    if (!this._updatable || !this._isReady) {
      return this;
    }
    this.beforeUpdateParticles(start, end, update);
    const rotMatrix = TmpVectors.Matrix[0];
    const mesh = this.mesh;
    const colors32 = this._colors32;
    const positions32 = this._positions32;
    const uvs32 = this._uvs32;
    const tempVectors = TmpVectors.Vector3;
    const camAxisX = tempVectors[5].copyFromFloats(1, 0, 0);
    const camAxisY = tempVectors[6].copyFromFloats(0, 1, 0);
    const camAxisZ = tempVectors[7].copyFromFloats(0, 0, 1);
    const minimum = tempVectors[8].setAll(Number.MAX_VALUE);
    const maximum = tempVectors[9].setAll(-Number.MAX_VALUE);
    Matrix.IdentityToRef(rotMatrix);
    let idx = 0;
    if (this.mesh?.isFacetDataEnabled) {
      this._computeBoundingBox = true;
    }
    end = end >= this.nbParticles ? this.nbParticles - 1 : end;
    if (this._computeBoundingBox) {
      if (start != 0 || end != this.nbParticles - 1) {
        const boundingInfo = this.mesh?.getBoundingInfo();
        if (boundingInfo) {
          minimum.copyFrom(boundingInfo.minimum);
          maximum.copyFrom(boundingInfo.maximum);
        }
      }
    }
    idx = 0;
    let pindex = 0;
    let cindex = 0;
    let uindex = 0;
    for (let p = start; p <= end; p++) {
      const particle = this.particles[p];
      idx = particle.idx;
      pindex = 3 * idx;
      cindex = 4 * idx;
      uindex = 2 * idx;
      this.updateParticle(particle);
      const particleRotationMatrix = particle._rotationMatrix;
      const particlePosition = particle.position;
      const particleGlobalPosition = particle._globalPosition;
      if (this._computeParticleRotation) {
        particle.getRotationMatrix(rotMatrix);
      }
      const particleHasParent = particle.parentId !== null;
      if (particleHasParent) {
        const parent = this.particles[particle.parentId];
        const parentRotationMatrix = parent._rotationMatrix;
        const parentGlobalPosition = parent._globalPosition;
        const rotatedY2 = particlePosition.x * parentRotationMatrix[1] + particlePosition.y * parentRotationMatrix[4] + particlePosition.z * parentRotationMatrix[7];
        const rotatedX2 = particlePosition.x * parentRotationMatrix[0] + particlePosition.y * parentRotationMatrix[3] + particlePosition.z * parentRotationMatrix[6];
        const rotatedZ2 = particlePosition.x * parentRotationMatrix[2] + particlePosition.y * parentRotationMatrix[5] + particlePosition.z * parentRotationMatrix[8];
        particleGlobalPosition.x = parentGlobalPosition.x + rotatedX2;
        particleGlobalPosition.y = parentGlobalPosition.y + rotatedY2;
        particleGlobalPosition.z = parentGlobalPosition.z + rotatedZ2;
        if (this._computeParticleRotation) {
          const rotMatrixValues = rotMatrix.m;
          particleRotationMatrix[0] = rotMatrixValues[0] * parentRotationMatrix[0] + rotMatrixValues[1] * parentRotationMatrix[3] + rotMatrixValues[2] * parentRotationMatrix[6];
          particleRotationMatrix[1] = rotMatrixValues[0] * parentRotationMatrix[1] + rotMatrixValues[1] * parentRotationMatrix[4] + rotMatrixValues[2] * parentRotationMatrix[7];
          particleRotationMatrix[2] = rotMatrixValues[0] * parentRotationMatrix[2] + rotMatrixValues[1] * parentRotationMatrix[5] + rotMatrixValues[2] * parentRotationMatrix[8];
          particleRotationMatrix[3] = rotMatrixValues[4] * parentRotationMatrix[0] + rotMatrixValues[5] * parentRotationMatrix[3] + rotMatrixValues[6] * parentRotationMatrix[6];
          particleRotationMatrix[4] = rotMatrixValues[4] * parentRotationMatrix[1] + rotMatrixValues[5] * parentRotationMatrix[4] + rotMatrixValues[6] * parentRotationMatrix[7];
          particleRotationMatrix[5] = rotMatrixValues[4] * parentRotationMatrix[2] + rotMatrixValues[5] * parentRotationMatrix[5] + rotMatrixValues[6] * parentRotationMatrix[8];
          particleRotationMatrix[6] = rotMatrixValues[8] * parentRotationMatrix[0] + rotMatrixValues[9] * parentRotationMatrix[3] + rotMatrixValues[10] * parentRotationMatrix[6];
          particleRotationMatrix[7] = rotMatrixValues[8] * parentRotationMatrix[1] + rotMatrixValues[9] * parentRotationMatrix[4] + rotMatrixValues[10] * parentRotationMatrix[7];
          particleRotationMatrix[8] = rotMatrixValues[8] * parentRotationMatrix[2] + rotMatrixValues[9] * parentRotationMatrix[5] + rotMatrixValues[10] * parentRotationMatrix[8];
        }
      } else {
        particleGlobalPosition.x = 0;
        particleGlobalPosition.y = 0;
        particleGlobalPosition.z = 0;
        if (this._computeParticleRotation) {
          const rotMatrixValues = rotMatrix.m;
          particleRotationMatrix[0] = rotMatrixValues[0];
          particleRotationMatrix[1] = rotMatrixValues[1];
          particleRotationMatrix[2] = rotMatrixValues[2];
          particleRotationMatrix[3] = rotMatrixValues[4];
          particleRotationMatrix[4] = rotMatrixValues[5];
          particleRotationMatrix[5] = rotMatrixValues[6];
          particleRotationMatrix[6] = rotMatrixValues[8];
          particleRotationMatrix[7] = rotMatrixValues[9];
          particleRotationMatrix[8] = rotMatrixValues[10];
        }
      }
      const pivotBackTranslation = tempVectors[11];
      if (particle.translateFromPivot) {
        pivotBackTranslation.setAll(0);
      } else {
        pivotBackTranslation.copyFrom(particle.pivot);
      }
      const tmpVertex = tempVectors[0];
      tmpVertex.copyFrom(particle.position);
      const vertexX = tmpVertex.x - particle.pivot.x;
      const vertexY = tmpVertex.y - particle.pivot.y;
      const vertexZ = tmpVertex.z - particle.pivot.z;
      let rotatedX = vertexX * particleRotationMatrix[0] + vertexY * particleRotationMatrix[3] + vertexZ * particleRotationMatrix[6];
      let rotatedY = vertexX * particleRotationMatrix[1] + vertexY * particleRotationMatrix[4] + vertexZ * particleRotationMatrix[7];
      let rotatedZ = vertexX * particleRotationMatrix[2] + vertexY * particleRotationMatrix[5] + vertexZ * particleRotationMatrix[8];
      rotatedX += pivotBackTranslation.x;
      rotatedY += pivotBackTranslation.y;
      rotatedZ += pivotBackTranslation.z;
      const px = positions32[pindex] = particleGlobalPosition.x + camAxisX.x * rotatedX + camAxisY.x * rotatedY + camAxisZ.x * rotatedZ;
      const py = positions32[pindex + 1] = particleGlobalPosition.y + camAxisX.y * rotatedX + camAxisY.y * rotatedY + camAxisZ.y * rotatedZ;
      const pz = positions32[pindex + 2] = particleGlobalPosition.z + camAxisX.z * rotatedX + camAxisY.z * rotatedY + camAxisZ.z * rotatedZ;
      if (this._computeBoundingBox) {
        minimum.minimizeInPlaceFromFloats(px, py, pz);
        maximum.maximizeInPlaceFromFloats(px, py, pz);
      }
      if (this._computeParticleColor && particle.color) {
        const color = particle.color;
        const colors322 = this._colors32;
        colors322[cindex] = color.r;
        colors322[cindex + 1] = color.g;
        colors322[cindex + 2] = color.b;
        colors322[cindex + 3] = color.a;
      }
      if (this._computeParticleTexture && particle.uv) {
        const uv = particle.uv;
        const uvs322 = this._uvs32;
        uvs322[uindex] = uv.x;
        uvs322[uindex + 1] = uv.y;
      }
    }
    if (mesh) {
      if (update) {
        if (this._computeParticleColor) {
          mesh.updateVerticesData(VertexBuffer.ColorKind, colors32, false, false);
        }
        if (this._computeParticleTexture) {
          mesh.updateVerticesData(VertexBuffer.UVKind, uvs32, false, false);
        }
        mesh.updateVerticesData(VertexBuffer.PositionKind, positions32, false, false);
      }
      if (this._computeBoundingBox) {
        if (mesh.hasBoundingInfo) {
          mesh.getBoundingInfo().reConstruct(minimum, maximum, mesh._worldMatrix);
        } else {
          mesh.buildBoundingInfo(minimum, maximum, mesh._worldMatrix);
        }
      }
    }
    this.afterUpdateParticles(start, end, update);
    return this;
  }
  /**
   * Disposes the PCS.
   */
  dispose() {
    this.mesh?.dispose();
    this.vars = null;
    this._positions = null;
    this._indices = null;
    this._normals = null;
    this._uvs = null;
    this._colors = null;
    this._indices32 = null;
    this._positions32 = null;
    this._uvs32 = null;
    this._colors32 = null;
  }
  /**
   * Visibility helper : Recomputes the visible size according to the mesh bounding box
   * doc :
   * @returns the PCS.
   */
  refreshVisibleSize() {
    if (!this._isVisibilityBoxLocked) {
      this.mesh?.refreshBoundingInfo();
    }
    return this;
  }
  /**
   * Visibility helper : Sets the size of a visibility box, this sets the underlying mesh bounding box.
   * @param size the size (float) of the visibility box
   * note : this doesn't lock the PCS mesh bounding box.
   * doc :
   */
  setVisibilityBox(size) {
    if (!this.mesh) {
      return;
    }
    const vis = size / 2;
    this.mesh.buildBoundingInfo(new Vector3(-vis, -vis, -vis), new Vector3(vis, vis, vis));
  }
  /**
   * Gets whether the PCS is always visible or not
   * doc :
   */
  get isAlwaysVisible() {
    return this._alwaysVisible;
  }
  /**
   * Sets the PCS as always visible or not
   * doc :
   */
  set isAlwaysVisible(val) {
    if (!this.mesh) {
      return;
    }
    this._alwaysVisible = val;
    this.mesh.alwaysSelectAsActiveMesh = val;
  }
  /**
   * Tells to `setParticles()` to compute the particle rotations or not
   * Default value : false. The PCS is faster when it's set to false
   * Note : particle rotations are only applied to parent particles
   * Note : the particle rotations aren't stored values, so setting `computeParticleRotation` to false will prevents the particle to rotate
   */
  set computeParticleRotation(val) {
    this._computeParticleRotation = val;
  }
  /**
   * Tells to `setParticles()` to compute the particle colors or not.
   * Default value : true. The PCS is faster when it's set to false.
   * Note : the particle colors are stored values, so setting `computeParticleColor` to false will keep yet the last colors set.
   */
  set computeParticleColor(val) {
    this._computeParticleColor = val;
  }
  set computeParticleTexture(val) {
    this._computeParticleTexture = val;
  }
  /**
   * Gets if `setParticles()` computes the particle colors or not.
   * Default value : false. The PCS is faster when it's set to false.
   * Note : the particle colors are stored values, so setting `computeParticleColor` to false will keep yet the last colors set.
   */
  get computeParticleColor() {
    return this._computeParticleColor;
  }
  /**
   * Gets if `setParticles()` computes the particle textures or not.
   * Default value : false. The PCS is faster when it's set to false.
   * Note : the particle textures are stored values, so setting `computeParticleTexture` to false will keep yet the last colors set.
   */
  get computeParticleTexture() {
    return this._computeParticleTexture;
  }
  /**
   * Tells to `setParticles()` to compute or not the mesh bounding box when computing the particle positions.
   */
  set computeBoundingBox(val) {
    this._computeBoundingBox = val;
  }
  /**
   * Gets if `setParticles()` computes or not the mesh bounding box when computing the particle positions.
   */
  get computeBoundingBox() {
    return this._computeBoundingBox;
  }
  // =======================================================================
  // Particle behavior logic
  // these following methods may be overwritten by users to fit their needs
  /**
   * This function does nothing. It may be overwritten to set all the particle first values.
   * The PCS doesn't call this function, you may have to call it by your own.
   * doc :
   */
  initParticles() {
  }
  /**
   * This function does nothing. It may be overwritten to recycle a particle
   * The PCS doesn't call this function, you can to call it
   * doc :
   * @param particle The particle to recycle
   * @returns the recycled particle
   */
  recycleParticle(particle) {
    return particle;
  }
  /**
   * Updates a particle : this function should  be overwritten by the user.
   * It is called on each particle by `setParticles()`. This is the place to code each particle behavior.
   * doc :
   * @example : just set a particle position or velocity and recycle conditions
   * @param particle The particle to update
   * @returns the updated particle
   */
  updateParticle(particle) {
    return particle;
  }
  /**
   * This will be called before any other treatment by `setParticles()` and will be passed three parameters.
   * This does nothing and may be overwritten by the user.
   * @param start the particle index in the particle array where to start to iterate, same than the value passed to setParticle()
   * @param stop the particle index in the particle array where to stop to iterate, same than the value passed to setParticle()
   * @param update the boolean update value actually passed to setParticles()
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  beforeUpdateParticles(start, stop, update) {
  }
  /**
   * This will be called  by `setParticles()` after all the other treatments and just before the actual mesh update.
   * This will be passed three parameters.
   * This does nothing and may be overwritten by the user.
   * @param start the particle index in the particle array where to start to iterate, same than the value passed to setParticle()
   * @param stop the particle index in the particle array where to stop to iterate, same than the value passed to setParticle()
   * @param update the boolean update value actually passed to setParticles()
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  afterUpdateParticles(start, stop, update) {
  }
};

export {
  AnimationEvent,
  LastCreatedAudioEngine,
  AudioEngineV2,
  _GetAudioEngine,
  CreateAudioBusAsync,
  CreateMainAudioBusAsync,
  CreateMicrophoneSoundSourceAsync,
  CreateSoundAsync,
  CreateSoundBufferAsync,
  CreateSoundSourceAsync,
  CreateStreamingSoundAsync,
  _SpatialAudioListenerDefaults,
  _HasSpatialAudioListenerOptions,
  AbstractSpatialAudioListener,
  CreateAudioEngineAsync,
  _WebAudioEngine,
  AudioEngine,
  Sound,
  SoundTrack,
  AddParser,
  GetParser,
  AddIndividualParser,
  GetIndividualParser,
  Parse,
  AudioSceneComponent,
  WeightedSound,
  Skeleton,
  PickingCustomization,
  Ray,
  CreatePickingRay,
  CreatePickingRayToRef,
  CreatePickingRayInCameraSpace,
  CreatePickingRayInCameraSpaceToRef,
  PickWithBoundingInfo,
  Pick,
  PickWithRay,
  MultiPick,
  MultiPickWithRay,
  GetForwardRay,
  GetForwardRayToRef,
  AddRayExtensions,
  BaseCameraMouseWheelInput,
  CameraInputTypes,
  CameraInputsManager,
  FreeCameraKeyboardMoveInput,
  FreeCameraMouseInput,
  FreeCameraMouseWheelInput,
  FreeCameraTouchInput,
  FreeCameraInputsManager,
  FreeCamera,
  HemisphericLight,
  addToBlockFactory,
  blockFactory,
  GetDataOutConnectionByUniqueId,
  GetSignalInConnectionByUniqueId,
  ParseCoordinatorAsync,
  ParseFlowGraphAsync,
  ParseFlowGraph,
  ParseFlowGraphContext,
  ParseBlockAsync,
  ParseFlowGraphBlockWithClassType,
  ParseGraphConnectionWithClassType,
  ParseGraphDataConnection,
  CubeTexture,
  PointLight,
  AreaLight,
  RectAreaLight,
  RawTexture2DArray,
  MorphTargetManager,
  RawCubeTexture,
  GaussianSplattingMaterial,
  DracoDecoder,
  MeshoptCompression,
  GaussianSplattingMesh,
  Deferred,
  DataReader,
  Lazy,
  CloudPoint,
  PointsGroup,
  PointColor,
  PointsCloudSystem
};
//# sourceMappingURL=chunk-2NZ3PI6Y.js.map
