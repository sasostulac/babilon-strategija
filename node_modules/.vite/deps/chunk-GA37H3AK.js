import {
  Observable
} from "./chunk-2YUEJ7I2.js";

// node_modules/@babylonjs/core/AudioV2/audioUtils.js
var _FileExtensionRegex = new RegExp("\\.(\\w{3,4})($|\\?)");
var CurveLength = 100;
var TmpLineValues = new Float32Array([0, 0]);
var TmpCurveValues = null;
var ExpCurve = null;
var LogCurve = null;
function GetExpCurve() {
  if (!ExpCurve) {
    ExpCurve = new Float32Array(CurveLength);
    const increment = 1 / (CurveLength - 1);
    let x = increment;
    for (let i = 1; i < CurveLength; i++) {
      ExpCurve[i] = Math.exp(-11.512925464970227 * (1 - x));
      x += increment;
    }
  }
  return ExpCurve;
}
function GetLogCurve() {
  if (!LogCurve) {
    LogCurve = new Float32Array(CurveLength);
    const increment = 1 / CurveLength;
    let x = increment;
    for (let i = 0; i < CurveLength; i++) {
      LogCurve[i] = 1 + Math.log10(x) / Math.log10(CurveLength);
      x += increment;
    }
  }
  return LogCurve;
}
function _GetAudioParamCurveValues(shape, from, to) {
  if (!TmpCurveValues) {
    TmpCurveValues = new Float32Array(CurveLength);
  }
  let normalizedCurve;
  if (shape === "linear") {
    TmpLineValues[0] = from;
    TmpLineValues[1] = to;
    return TmpLineValues;
  } else if (shape === "exponential") {
    normalizedCurve = GetExpCurve();
  } else if (shape === "logarithmic") {
    normalizedCurve = GetLogCurve();
  } else {
    throw new Error(`Unknown ramp shape: ${shape}`);
  }
  const direction = Math.sign(to - from);
  const range = Math.abs(to - from);
  if (direction === 1) {
    for (let i = 0; i < normalizedCurve.length; i++) {
      TmpCurveValues[i] = from + range * normalizedCurve[i];
    }
  } else {
    let j = CurveLength - 1;
    for (let i = 0; i < normalizedCurve.length; i++, j--) {
      TmpCurveValues[i] = from - range * (1 - normalizedCurve[j]);
    }
  }
  return TmpCurveValues;
}
function _CleanUrl(url) {
  return url.replace(/#/gm, "%23");
}

// node_modules/@babylonjs/core/AudioV2/webAudio/components/webAudioParameterComponent.js
var MaxWaitTime = 0.011;
var MinRampDuration = 1e-6;
var _WebAudioParameterComponent = class {
  /** @internal */
  constructor(engine, param) {
    this._deferredRampOptions = {
      duration: 0,
      shape: "linear"
    };
    this._deferredTargetValue = -1;
    this._isObservingUpdates = false;
    this._rampEndTime = 0;
    this._applyDeferredRamp = () => {
      if (0 < this._deferredRampOptions.duration && this._rampEndTime < this._engine.currentTime) {
        this.setTargetValue(this._deferredTargetValue, this._deferredRampOptions);
      }
    };
    this._engine = engine;
    this._param = param;
    this._targetValue = param.value;
  }
  /** @internal */
  get isRamping() {
    return this._engine.currentTime < this._rampEndTime;
  }
  /** @internal */
  get targetValue() {
    return this._targetValue;
  }
  set targetValue(value) {
    this.setTargetValue(value);
  }
  /** @internal */
  get value() {
    return this._param.value;
  }
  /** @internal */
  dispose() {
    this._clearDeferredRamp();
    this._param = null;
    this._engine = null;
  }
  /**
   * Sets the target value of the audio parameter with an optional ramping duration and shape.
   *
   * If a ramp is close to finishing, it will wait for the ramp to finish before setting the new value; otherwise it
   * will throw an error because of a bug in Firefox that prevents active ramps from being cancelled with
   * `cancelScheduledValues`. See https://bugzilla.mozilla.org/show_bug.cgi?id=1752775. Other browsers do not have
   * this issue, but we throw an error in all browsers to ensure consistent behavior.
   *
   * There are other similar WebAudio APIs for ramping parameters, (e.g. `linearRampToValueAtTime` and
   * `exponentialRampToValueAtTime`) but they don't work in Firefox and Meta Quest Chrome.
   *
   * It may be better in the long run to implement our own ramping logic with a WASM audio worklet instead of using
   * `setValueCurveAtTime`. Another alternative is to use `setValueAtTime` wtih a custom shape, but that will
   * probably be a performance hit to maintain quality at audio rates.
   *
   * @internal
   */
  setTargetValue(value, options = null) {
    if (this._targetValue === value) {
      return;
    }
    const shape = typeof options?.shape === "string" ? options.shape : "linear";
    let duration = typeof options?.duration === "number" ? Math.max(options.duration, this._engine.parameterRampDuration) : this._engine.parameterRampDuration;
    const startTime = this._engine.currentTime;
    if (startTime < this._rampEndTime) {
      const timeLeft = this._rampEndTime - startTime;
      if (MaxWaitTime < timeLeft) {
        throw new Error("Audio parameter not set. Wait for current ramp to finish.");
      } else {
        this._deferRamp(value, duration, shape);
        return;
      }
    }
    if ((duration = Math.max(this._engine.parameterRampDuration, duration)) < MinRampDuration) {
      this._param.setValueAtTime(this._targetValue = value, startTime);
      return;
    }
    this._param.cancelScheduledValues(startTime);
    this._param.setValueCurveAtTime(_GetAudioParamCurveValues(shape, this._targetValue, this._targetValue = value), startTime, duration);
    this._clearDeferredRamp();
    this._rampEndTime = startTime + duration;
  }
  _deferRamp(value, duration, shape) {
    this._deferredRampOptions.duration = duration;
    this._deferredRampOptions.shape = shape;
    this._deferredTargetValue = value;
    if (!this._isObservingUpdates) {
      this._engine._addUpdateObserver(this._applyDeferredRamp);
      this._isObservingUpdates = true;
    }
  }
  _clearDeferredRamp() {
    this._deferredRampOptions.duration = 0;
    if (this._isObservingUpdates) {
      this._engine._removeUpdateObserver(this._applyDeferredRamp);
      this._isObservingUpdates = false;
    }
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/abstractAudioNode.js
var AudioNodeType;
(function(AudioNodeType2) {
  AudioNodeType2[AudioNodeType2["HAS_INPUTS"] = 1] = "HAS_INPUTS";
  AudioNodeType2[AudioNodeType2["HAS_OUTPUTS"] = 2] = "HAS_OUTPUTS";
  AudioNodeType2[AudioNodeType2["HAS_INPUTS_AND_OUTPUTS"] = 3] = "HAS_INPUTS_AND_OUTPUTS";
})(AudioNodeType || (AudioNodeType = {}));
var AbstractAudioNode = class {
  constructor(engine, nodeType) {
    this.onDisposeObservable = new Observable();
    this.engine = engine;
    if (nodeType & 1) {
      this._upstreamNodes = /* @__PURE__ */ new Set();
    }
    if (nodeType & 2) {
      this._downstreamNodes = /* @__PURE__ */ new Set();
    }
  }
  /**
   * Releases associated resources.
   * - Triggers `onDisposeObservable`.
   * @see {@link onDisposeObservable}
   */
  dispose() {
    if (this._downstreamNodes) {
      for (const node of Array.from(this._downstreamNodes)) {
        if (!this._disconnect(node)) {
          throw new Error("Disconnect failed");
        }
      }
      this._downstreamNodes.clear();
    }
    if (this._upstreamNodes) {
      for (const node of Array.from(this._upstreamNodes)) {
        if (!node._disconnect(this)) {
          throw new Error("Disconnect failed");
        }
      }
      this._upstreamNodes.clear();
    }
    this.onDisposeObservable.notifyObservers(this);
    this.onDisposeObservable.clear();
  }
  /**
   * Connect to a downstream audio input node.
   * @param node - The downstream audio input node to connect
   * @returns `true` if the node is successfully connected; otherwise `false`
   */
  _connect(node) {
    if (!this._downstreamNodes) {
      return false;
    }
    if (this._downstreamNodes.has(node)) {
      return false;
    }
    if (!node._onConnect(this)) {
      return false;
    }
    this._downstreamNodes.add(node);
    return true;
  }
  /**
   * Disconnects a downstream audio input node.
   * @param node - The downstream audio input node to disconnect
   * @returns `true` if the node is successfully disconnected; otherwise `false`
   */
  _disconnect(node) {
    if (!this._downstreamNodes) {
      return false;
    }
    if (!this._downstreamNodes.delete(node)) {
      return false;
    }
    return node._onDisconnect(this);
  }
  /**
   * Called when an upstream audio output node is connecting.
   * @param node - The connecting upstream audio node
   * @returns `true` if the node is successfully connected; otherwise `false`
   */
  _onConnect(node) {
    if (!this._upstreamNodes) {
      return false;
    }
    if (this._upstreamNodes.has(node)) {
      return false;
    }
    this._upstreamNodes.add(node);
    return true;
  }
  /**
   * Called when an upstream audio output node disconnects.
   * @param node - The disconnecting upstream audio node
   * @returns `true` if node is sucessfully disconnected; otherwise `false`
   */
  _onDisconnect(node) {
    return this._upstreamNodes?.delete(node) ?? false;
  }
};
var AbstractNamedAudioNode = class extends AbstractAudioNode {
  constructor(name, engine, nodeType) {
    super(engine, nodeType);
    this.onNameChangedObservable = new Observable();
    this._name = name;
  }
  /**
   * The name of the audio node.
   * - Triggers `onNameChangedObservable` when changed.
   * @see {@link onNameChangedObservable}
   */
  get name() {
    return this._name;
  }
  set name(newName) {
    if (this._name === newName) {
      return;
    }
    const oldName = this._name;
    this._name = newName;
    this.onNameChangedObservable.notifyObservers({ newName, oldName, node: this });
  }
  dispose() {
    super.dispose();
    this.onNameChangedObservable.clear();
  }
};

export {
  _FileExtensionRegex,
  _CleanUrl,
  _WebAudioParameterComponent,
  AudioNodeType,
  AbstractAudioNode,
  AbstractNamedAudioNode
};
//# sourceMappingURL=chunk-GA37H3AK.js.map
